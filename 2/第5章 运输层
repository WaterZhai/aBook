第5章   运输层

运输层是整个网络体系结构中的关键层次之一。本章讨论TCP/IP体系中运输层最重要的两种协议：UDP和TCP。TCP比UDP复杂得多，必须弄清TCP的各种机制（如面向连接的可靠服务、流量控制、拥塞控制等），以及TCP连接管理的状态图的概念。

5.1运输层协议概述
    5.1.1进程之间的通信
        从通信和信息处理的角度看，运输层向它上面的应用层提供通信服务，它属于面向通信部分的最高层，同时也是用户功能中的最底层。当网络的边缘部分中的两个主机使用网络的核心部分的功能进行端到端的通信时，只有主机的协议栈才有运输层，而网络核心部分中的路由器在转发分组时都只用到下三层的功能。
        运输层的作用。设局域网1上的主机A和局域网2上的主机B通过互连的广域网进行通信。既然IP协议能够把源主机发送出的分组按照首部中的目的地址送交给目的主机，那么，为什么还需要再设置一个运输层呢？
        从IP层来说，通信的两端是两个主机。IP数据报的首部明确地标志了这两个主机的IP地址。但“两个主机之间的通信”这种说法还不够清楚。这是因为，真正进行通信的实体是在主机中的进程，是这个主机中的一个进程和另一个主机中的一个进程在交换数据（即通信）。因此严格地讲，两个主机进行通信就是两个主机中的应用进程互相通信。IP协议虽然能把分组送到目的主机，但是这个分组还停留在主机的网络层而没有交付主机中的应用进程。从运输层的角度看，通信的真正端点并不是主机而是主机中的进程。也就是说，端到端的通信是应用进程之间的通信。在一个主机中经常有多个应用进程同时分别和另一个主机中的多个应用进程通信。例如，某用户在使用浏览器查找某网站的信息时，其主机的应用层运行浏览器客户进程。如果在浏览网页的同时，还要用电子邮件给网站发送反馈意见，那么主机的应用层AP3通信，而与此同时，应用进程AP2也和对方的应用进程AP4通信。这表明运输层有一个很重要的功能--复用（multiplexing）和分用（demultiplexing）。这里的“复用”是指在发送方不同的应用进程都可以使用同一个运输层协议传送数据（当然需要加上适当的首部），而“分用”是指接收方的运输层在剥去报文的首部后能够把这些数据正确交付到目的应用进程。“运输层提供应用进程间的逻辑通信”。“逻辑通信”的意思是：运输层之间的通信好像是沿水平方向传送数据。但事实上这两个运输层之间并没有一条水平方向的物理连接。要传送的数据是沿着图中的虚线方向（经过多个层次）传送的。
        从这里可以看出网络层和运输层有明显的区别。网络层是为主机之间提供逻辑通信，而运输层为应用进程之间提供端到端的逻辑通信。然而正如后面还要讨论的运输层还具有网络层无法代替的许多其他重要功能。
        运输层还要对收到的报文进行差错检测。大家应当还记得，在网络层，IP数据报首部中的检验和字段，只检验首部是否出现差错而不检查数据部分。
        根据应用程序的不同需求，运输层需要有两种不同的运输协议，即面向连接的TCP和无连接的UDP，这两种协议就是本章要讨论的主要内容。
        我们还应指出，运输层向高层用户屏蔽了下面网络核心的细节（如网络拓扑、所采用的路由选择协议等），它使应用进程看见的就是好像在两个运输层实体之间有一条端到端的逻辑通信信道，但这条逻辑通信信道对上层的表现却因运输层使用的不同协议而有很大的差别。当运输层采用面向连接的TCP协议时，尽管下面的网络是不可靠的（值提供尽最大努力服务），但这种逻辑通信信道就相当于一条全双工的可靠信道。但当运输层采用无连接的UDP协议时，这种逻辑通信信道仍然是一条不可靠信道。
    5.1.2运输层的两个主要协议
        TCP/IP运输层的两个主要协议都是因特网的正式标准，即：
        1）用户数据报协议UDP（UserDatagramProtocol）
        2）传输控制协议TCP（TransmissionControlProtocol）
            这两种协议在协议栈中的位置
                |应用层       |
                |UDP   |TCP  |
                |IP           |
                |与各种网络接口|
        按照OSI的术语，这两个对等运输实体在通信时传送的数据单位叫做运输协议数据单元TPDU（TransportProtocolDataUnit）。但在TCP/IP体系中，则根据所使用的协议是TCP或UDP，分别称之为TCP报文段（segment）或UDP用户数据报。
        UDP在传送数据之前不需要先建立连接。远地主机的运输层在收到UDP报文后，不需要给出任何确认。虽然UDP不提供可靠交付，但在某些情况下UDP却是一种最有效的工作方式。
        TCP则提供面向连接的服务。在传送数据之前必须先建立连接，数据传送结束后要释放连接。TCP不提供广播或多播服务。由于TCP要提供可靠的、面向连接的运输服务，因此不可避免地增加了许多的开销。如确认、流量控制、计时器以及连接管理等。这不仅使协议数据单元的首部增大许多，还要占用许多的处理机资源。
            |应用        |应用层协议  |运输层协议|
            |名字转换    |DNS         |UDP      |
            |文件传送     |TFTP       |UDP      |
            |路由选择协议 |RIP        |UDP       |
            |IP地址配置   |BOOTP，DHCP|UDP       |
            |网络管理     |SNMP       |UDP       |
            |远程文件服务器|NFS        |UDP      |
            |IP电话       |专用协议    |UDP      |
            |流式多媒体通信|专用协议    |UDP      |
            |多播         |IGMP        |UDP      |
            |电子邮件      |SMTP       |TCP      |
            |远程终端接入  |TELNET      |TCP      |
            |万维网        |HTTP       |TCP      |
            |文件传送      |FTP         |TCP     |
    5.1.3运输层的端口
        前面已经提到过运输层的复用和分用功能。其实在日常生活中也有很多复用和分用的例子。假定一个机关的所有部门向外单位发出的公文都由收发室负责寄出，这相当于各部门都“复用”这个收发室。当收发室收到从外单位寄来的公文时，则要完成“分用”功能，即按照信封上写明的本机关的部门地址把公文正确进行交付。
        运输层的复用和分用也是类似的。应用层所有的应用进程都可以通过运输层再传送到IP层，这就是复用。运输层从IP层收到数据后必须交付给指明的应用进程。这就是分用。显然，给应用层的每个应用进程赋予一个非常明确的标志是至关重要的。
        我们知道，在单个计算机中进程是用进程标识符（一个不大的整数）来标志的。但是在云特网环境下，用计算机操作系统指派的这种进程标识符来标志运行在应用层的各种应用进程则是不行的。这是因为在因特网上使用的计算机的操作系统种类很多，而不同的操作系统有使用不同格式的进程标识符。为了使运行不同操作系统的计算机的应用进程能够互相通信，就必须用统一的方法（而这种方法必须与特定操作系统无关）对TCP/IP体系的应用进程进行标志。
        但是，把一个特定机器上运行的特定进程指明为因特网上通信最后的重点还是不可行的。这是因为进程的创建和撤销都是动态的，通信的一方几乎无法识别对方机器上的进程。另外，我们往往需要利用目的主机提供的功能来识别重点，而不需要知道具体的实现这个功能的进程是哪一个（例如，要和因特网上的某个邮件服务器联系，并不一定要知道这个服务器功能是由目的主机上的那个进程实现的）。
        解决这个问题的方法就是izai运输层使用协议端口号（protocol port number），或通常简称为端口（port）。这就是说，虽然通信的重点是应用进程，但我们只要把要传送的报文交到目的主机的某一个合适的目的端口，剩下的工作（即最后交付给目的进程）就由TCP来完成。
        请注意，这种在协议栈层间的抽象的协议端口是软件端口，和路由器或交换机上的硬件端口是完全不同的概念。硬件端口是不同硬件设备进行交互的接口，而软件端口是应用层的各种协议进程与运输实体进行层间交互的一种地址。不同的系统具体实现端口的方法可以是不同的（取决于系统使用的操作系统）。
        在后面将降到的UDP和TCP的首部格式中，我们将会看到它们都有源端口和目的端口这两个重要字段。当运输层收到IP层交上来的运输层报文时，就能够根据其首部中的目的端口号把数据交付给应用层的目的应用进程。
        TCP/IP的运输层用一个16位端口号来标志一个端口。但请注意，端口号只具有本地意义，它只是为了标志本计算机应用层送的各个进程在运输层交互时的层间接口。在因特网不同计算机中，相同的端口号是没有关联的。16位的端口号可允许有65535个不同的端口号，这个数目对一个计算机来说是足够用的。
        由此可见，两个计算机中的进程要互相通信，不仅必须知道对方的IP地址（为了找到对方的计算机），而且还要知道对方的端口号（为了找到对方计算机中的应用进程）。这和我们寄信的过程类似。当我们要和某人写信时，就必须知道他的通信地址。在新风尚会写明自己的地址。当收信人回信时，很容易在信封上看到发信人的地址。因特网上的计算机通信是采用客户-服务器方式。客户在发起通信请求时，必须先知道对方服务器的IP地址和端口号。因此运输层的端口号共分为下面的两大类。
        1）服务器端使用的端口号    这理由分为两类，最重要的一类叫做熟知端口号（well-know port number）或系统端口号，数值为0~1023。这些数值可在网址www.iana.org查到。IANA把这些端口号指派给了TCP/IP最重要的一些应用程序，让所有的用户都知道。当一种新的应用程序出现后，IANA必须为它指派一个熟知端口，否则因特网上的其他应用进程就无法和它进行通信。
            |应用程序 |FTP|TELNET|SMTP|DNS|TFTP|HTTP|SNMP|SNMP（trap）|
            |熟知端口号|21|23    |25  |53  |69 |80  |161 |162         |
            另一类叫做登记端口号，数值为1024~49151.这类端口号是为没有熟知端口号的应用程序使用的。使用这类端口号必须在IANA按照规定的手续登记，以防止重复。
        2）客户端使用的端口号   数值为49152~65535.由于这类端口号仅在客户进程运行时才动态选择，因此又叫做短暂端口号。这类端口号是留给客户进程选择暂时使用。当服务器进程收到客户进程的报文时，就知道了客户进程所使用的端口号，因而可以把数据发送给客户进程。通信结束后，刚才已使用过的客户端口号就不复存在。这个端口号就可以供其他客户进程以后使用。
        下面将分别讨论UDP和TCP。UDP比较简单，本章主要的篇幅是讨论TCP。
5.2用户数据报协议UDP
    5.2.1UDP概述
        用户数据报协议UDP只在IP的数据报服务之上增加了很少一点的功能，这就是复用和分用的功能以及差错检测的功能。UDP的主要特点是：
        1）UDP是无连接的，即发送数据之前不需要建立连接（当然发送数据结束时也没有连接可释放），因此减少了开销和发送数据之前的时延。
        2）UDP使用尽最大努力交付，即不保证可靠交付，因此主机不需要维持复杂的连接状态表（这里面有许多参数）。
        3）UDP是面向报文的。发送方的UDP对应程序交下来的报文，在添加首部后就向下交付给IP层。UDP对应用层交下来的报文，即不合并，也不拆分，而是保留这些报文的边界。这就是说，应用层交给UDP多长的报文，UDP就照样发送，即一次发送一个报文。在接收方的UDP，对IP层交上来的UDP用户数据报，在去除首部后就原封不动地交付给上层的应用进程。也就是说，UDP一次交付一个完整的报文。因此，应用程序必须选择合适大小的报文。若报文太长，UDP把它交给IP层后，IP层在传送时可能要进行分片，这会降低IP层的效率。反之，若报文太短，UDP把它交给IP层后，会使IP数据报的首部的相对长度太大，这也降低了IP层的效率。
                               |应用层报文            |应用层
                       |UDP首部|UDP用户数据报的数据部分|运输层
                |IP首部|IP数据报的数据部分             |IP层
        1）UDP没有拥塞控制，因此网络出现的拥塞不会使源主机的发送速率降低。这些某些实时应用是很重要的。很多的实时应用（如IP电话、实时视频会议等）要求源主机以恒定的速率发送数据，并且允许在网络发生拥塞时丢失一些数据，但却不允许有太大的时延。UDP正好适合这种要求。
        2）UDP支持一对一、一对多、多对一和多对多的交互通信。
        3）UDP的首部开销小，只有8个字节，比TCP的20个字节的首部要短。
        虽然某些实时应用需要使用没有拥塞控制的UDP，但当很多的源主机同时都向网络发送高速率的实时视频流时，网络就有可能发生拥塞，结果大家都无法正常接收。因此，不使用拥塞控制功能的UDP有可能会引起网络产生严重的拥塞问题。
        还有一些使用UDP的实时应用，需要对UDP的不可靠的传输进行适当的改进，以减少数据的丢失。在这种情况下，应用进程本身可以在不影响应用的实时性的前提下，增加一些提高可靠性的措施，如采用前向纠错或重传已丢失的报文。
    5.2.2UDP的首部格式
        用户数据报UDP有两个字段：数据字段和首部字段。首部字段很简单，只有8个字节，由四个字段组成，每个字段的长度都是两个字节。各字段意义如下：
            1）源端口   源端口号。在需要对方回信时选用。不需要时可用全0。
            2）目的地址    目的端口号。这在终点交付报文时必须要使用到。
            3）长度    UDP用户数据报的长度，其最小值是8（仅有首部）。
            4）检验和   检测UDP用户数据报在传输中是否有错。有错就丢弃。
        当运输层从IP层收到UDP数据报时，就根据首部中的目的端口，把UDP数据报通过相应的端口，上交最后的终点--应用进程。
        如果接收方UDP发现收到的报文中的目的端口号不正确（即不存在对应于该端口号的应用进程），就丢弃该报文，并由ICMP发送“端口不可达”差错报文给发送方。我们在上一章4.4.2节讨论traceroute时，就是让发送的UDP用户数据报故意使用一个非法的UDP端口，结果ICMP就返回“端口不可达”差错报文，因而达到了测试的目的。
        UDP用户数据报首部中检验和的计算方法有些特殊。在计算检验和时，要在UDP用户数据报之前增加12个字节的伪首部。所谓“伪首部”是因为这种伪首部并不是UDP用户数据真正的首部。只是在计算检验和时，临时添加在 UDP用户数据报前面，得到一个临时的UDP用户数据报。检验和就是按照这个临时的UDP用户数据报来计算的。伪首部既不向下传送也不向上递交，而仅仅是为了计算检验和。
        UDP计算检验和的方法和计算IP数据报首部检验和方法相似。但不同的是：IP数据报的检验和只检验IP数据报的首部，但UDP的检验和是把首部和数据部分一起都检验。在发送方，首先是先把全零放入检验和字段。再把伪首部以及UDP用户数据报看成是由许多16位的字串接起来。若UDP用户数据报的数据部分不是偶数个字节，则要填入一个全零字节（但此字节不发送）。然后按二进制反码计算出这些16位字的和。将此和的二进制反码写入检验和字段后，就发送这样的UDP用户数据报。在接收方，把收到的UDP用户数据报连同伪首部（以及可能的填充全零字节）一起，按二进制反码求这些16位字的和。当无差错时其结果应为全1。否则就表明有差错出现，接收方就应丢弃这个UDP用户数据报（也可以上交给应用层，但附上出现了差错的警告）。一个计算UDP检验和的例子。这里假定用户数据报的长度是15字节，因此要添加一个全0的字节。读者可以自己检验一下在接收端是怎样对检验和进行检验的。不难看出，这种简单的差错检验方法的检错能力并不强，但它的好处是简单，处理起来较快。
        伪首部的第3字段是全零，第4个字段是IP首部中的协议字段的值。以前已讲过，对于UDP，此协议字段值为17.第5字段是UDP用户数据报的长度。因此，这样的检验和，既检查了UDP用户数据报的源端口号和目的端口号以及 UDP用户数据报的数据部分，有检查了IP数据报的源IP地址和目的地址。
5.3传输控制协议TCP概述
    由于TCP协议比较复杂，因此本节先对TCP协议进行一般的介绍，然后再逐步深入讨论TCP的可靠传输、流量控制和拥塞控制等问题。
    5.3.1TCP最主要的特点
        TCP是TCP/IP体系中非常复杂的一个协议。下面介绍TCP最主要的特点。
        1）TCP是面向连接的运输层协议。这就是说，应用程序在使用TCP协议之前，必须先建立TCP连接。在传送数据完毕后，必须释放已经建立的TCP连接。这就是说，应用进程之间的通信好像在“打电话”：通话前要先拨号建立连接，通话结束后要挂机释放链接。
        2）每一条TCP连接只能有两个端点（endpoint），每一条TCP连接只能是点对点的（一对一）。这个问题后面还要讨论。
        3）TCP提供可靠交付的服务。也就是说，通过TCP连接传送的数据，无差错、不丢失、不重复、并且按序到达。
        4）TCP提供全双工通信。TCP允许通信双方的应用进程在任何时候都能发送数据。TCP连接的两端都设有发送缓存和接受缓存，用来临时存放双向通信的数据。在发送时，应用程序在把数据传送给TCP的缓存后，就可以做自己的事，而TCP在合适的时候把数据发送出去。在接收时，TCP把收到的数据放入缓存，上层的应用进程在合适的时候读取缓存中的数据。
        5）面向字节流。TCP中的“流”（stream）指的是流入到进程或从进程流出的字节序列。“面向字节流”的含义是：虽然应用程序和TCP的交互时一次一个数据块（大小不等），但TCP把应用程序交下来的数据看成仅仅是一连串的无结构的字节流。TCP并不知道所传送的字节流的含义。TCP不保证接收方应用程序所受到的数据块和发送方应用程序所发出的数据块具有对用大小的关系（例如，发送方应用程序交给发送方的TCP共10个数据块，但接收方的TCP可能只用了4个数据块就把收到的字节流交付给了山城的应用程序）。但接收方应用程序受到的字节流必须和发送方应用程序发出的字节流完全一样。当然，接受方的应用程序必须有能力识别收到的字节流，把它还原成有意义的应用层数据。
        为了突出示意图的要点，我们只画出了一个方向的数据流。但请注意，在实际的网络中，一个TCP报文段包含上前个字节是很常见的，而图中的和部分都只画出了几个字节，这仅仅是为了更方便地说明“面向字节流”的概念。另一点很重要的是：TCP连接是一条虚连接而不是一条真正的物理连接。TCP报文段先要传送到IP层，加上IP首部后，再传送到数据链路层。再加上数据链路层的首部和尾部后，才离开主机发送到物理链路。
        TCP和UDP在发送报文时所采用的方式完全不同。TCP对应用进程一次把多长的报文发送到TCP的缓存中是不关心的。TCP根据对方给出的窗口值和当前网络拥塞的程度来决定一个报文段应包含多少个字节（UDP发送的报文长度是应用进程给出的）。如果应用进程传送到TCP缓存的数据块太长，TCP就可以把它划分短一些再传送。如果应用进程一次只发来一个字节，TCP也可以等待积累有足够多的字节后再构成报文段发送出去。关于TCP报文段的长度问题，在后面还要进行讨论。
    5.3.2TCP的连接
        TCP把连接作为最基本的抽象。TCP的许多特性都与TCP是面向连接的这个基本特性有关。因此我们对TCP连接需要有更清楚的了解。
        前面已经讲过，每一条TCP连接有两个端点。那么，TCP连接的端点是什么呢？不是主机，不是主机的IP地址，不是应用进程，也不是运输层的协议端口。TCP连接的端点叫做套接字（socket）或插口。根据RFC 793的定义：端口号拼接到（contatenated with）IP地址即构成了套接字。因此套接字的表示方法是在点分十进制的IP地址后面写上端口号，中间用冒号或逗号隔开。例如若IP地址是192.3.4.5而端口号是80，那么得到的套接字就是（192.3.4.5：80）。总之，我们有：套接字socket=（IP地址：端口号）
            每一条TCP连接唯一地被通信两端的两个端点（即两个套接字）所确定。即：
                TCP连接::={socket1,socket2}={(IP1:port1),(IP2:port2)}
        这里IP1和IP2分别是两个端点主机的IP地址，而port1和port2分别是两个端点主机中的端口号。TCP连接的两个套接字就是socket1和socket2。这里只是初步地给出了套接字的概念，在下一章的6.8节还要对套接字进行更多的介绍。
        总之，TCP连接就是由协议软件所提供的一种抽象。虽然有时为了方便，我们也可以说，在一个应用进程和另一个应用进程之间建立了一条TCP连接，但一定要记住：TCP连接的端点是套接字，即（IP地址：端口号）。也还应记住：同一个IP地址可以有多个不同的TCP连接，而同一个端口号也可以出现在多个不同的TCP连接中。
        值得注意的是，socket这个名词有时容易使人把一些概念弄混淆，因为随着因特网的不断发展，以及网络技术的进步，同一个名词socket却可表示多种不同的意思。例如：
        1）允许应用程序访问连网协议的应用编程接口API（Application Programming Interface），即运输层和应用层之间的一种接口，成为socketAPI，并简称为socket。
        2）在socketAPI中使用的一个函数名也叫做socket。
        3）调用socket函数的端点称为socket，如“创建一个数据报socket”。
        4）调用socket函数时，其返回值称为socket描述符，可简称为socket。
        5）在操作系统内核中连网协议的Berkeley实现，称为socket实现。
        上面的这些socket的意思都和本章引用的RFC 793定义的socket（指端口号拼接到IP地址）不同。请读者加以注意。
5.4可靠传输的工作原理
    我们知道，TCP发送的报文段是交给IP层传送的。但IP层只能提供尽最大努力服务，也就是说，TCP下面的网络锁提供的是不可靠的传输。因此，TCP必须采用适当的措施才能使得两个运输层之间的通信变得可靠。
    理想的传输条件有以下两个特点：
    1）传输信道不产生差错。
    2）不管发送方以多块的速度发送数据，接收方总是来得及处理收到的数据。
    在这样的理想传输条件下，不需要采取任何措施就能够实现可靠传输。
    然而实际的网络都不具备以上两个理想条件。但我们可以使用一些可靠传输协议，当出现差错时让发送方重传差错的数据，同时在接收方来不及处理收到的数据时，及时告诉发送方适当降低发送数据的速度。下面从最简单的停止等待协议讲起。
    5.4.1停止等待协议
        全双工通信的双方既是发送方也是接收方。下面为了讨论问题的方便，我们仅考虑A发送数据而B接收数据并发送确认。因此A叫做发送方，而B叫做接收方。因为这里是讨论可靠传输的原理，因此把传送的数据单元都称为分组，而并不考虑数据是在哪一个层次上传送的。“停止等待”就是每发送完一个分组就停止发送，等待对方的确认。在收到确认后再发送下一个分组。
        1.无差错情况
        停止等待协议。最简单的无差错情况。A发送分组M1，发完就暂停发送，等待B的确认。B收到了M1就向A发送确认。A在收到了对M1的确认后，就再发送下一个分组M2.同样，在收到B对M2的确认后，再发送M3。
        2.出现差错
        分组在传输过程中出现差错的情况。B接收M1时检测出了差错，就丢弃M1，其他什么也不做（不通知A收到有差错的分组）。也可能是M1在传输过程中丢失了，这是B当然什么都不知道。在这种情况下，B都不会发送任何消息。可靠传输协议是这样设计的：A只要超过了一段时间仍然没有收到确认，就认为刚才发送的分组丢失了，因而重传前面发送或的分组。这就叫做超时重传。要实现超时重传，就要在每发送网一个分组设置一个超时计时器。如果在超时计时器到期之前收到了对方的确认，就撤销已设置的超时计时器。其实，A为每一个已发送的分组都设置了一个超时计时器。但A只要在超时计时器到期之前收到了相应的确认，就撤销该超时计时器。为简单起见，这些细节都省略了。
        这里应注意以下三点。
        第一，A在发送完一个分组后，必须暂时保留已发送的分组的副本（为发生超市重传时使用）。只有在收到相应的确认后才能清除暂时保留的分组副本。
        第二，分组和确认分组都必须进行编号。这样才能明确是哪一个发送出去的分组收到了确认，而哪一个分组还没有收到确认。
        第三，超时计时器设置的重传时间应当比数据在分组传输的平均往返时间更长一些。一段虚线表示如果M1正确到达B同时A也正确收到确认的过程。可见重传时间应设定为比平均往返时间更长一些。显然，如果重传时间设定得很长，那么通信的效率就会很低。但如果重传时间设定得太短，以致产生不必要的重传，浪费了网络资源。然而在运输层重传时间的准确设定是非常复杂的，这是因为已发送出的分组到底会经过哪些网络，以及这些网络将会产生多大的时延（这取决于这些网络当时的拥塞情况），这些都是不确定因素。把往返时间当做固定的（这并不符合网络的实际情况），只是为了讲述原理的方便。关于重传时间应如何选择，在后面的5.6.2节还要进一步讨论。
        3.确认丢失和确认迟到
        另一种情况。B所发送的对M2的确认丢失了。A在设定的超时重传时间内没有收到确认，但并无法知道自己发送的分组出错、丢失，或者是B发送的确认丢失了。因此A在超时计时器到期后就要重传M2。现在应注意B的动作。假定B又收到了重传的分组M2.这时应采取两个行动。
            第一，丢弃这个重复的分组M2，不向上层交付。
            第二，向A发送确认。不能认为已经发送过确认就不再发送，因为A之所以重传M2就表示A没有收到对M2的确认。
            一种可能出现的情况。传输过程中没有出现差错，但B对分组M1的确认迟到了。A会收到重复的确认。对重复的确认的处理很简单：收下后就丢弃。B仍然会收到重复的M1，并且同样要丢弃重复的M1，并重传确认分组。
        通常A最终总是可以收到对所有发出的分组的确认。如果A不断重传分组但总是收不到确认，就说明通信线路太差，不能进行通信。
        使用上述的确认和重传机制，我们就可以在不可靠的传输网路上实现可靠的通信。
        像上述的这种可靠传输协议常称为自动重传请求ARQ（Automatic Repeat reQuest）。意思是重传的请求是自动进行的。接收方不需要请求发送方重传某个出错的分组。
        4.信道利用率
        停止等待协议的优点是简单，但缺点是信道利用率太低。为简单起见，就假定在A和B之间有一条直通的信道来传送分组。
        假定A发送分组需要的时间是Td。显然，Td等于分组长度除以数据率。在假定分组正确到达B后，B处理分组的时间可以忽略不计，同时立即发挥确认。假定B发送确认分组需要时间Ta。如果A处理确认分组的时间也可以忽略不计，那么A在经过时间（Td+RTT+Ta）后就可以再发送下一个分组，这里的RTT是往返时间。因为仅仅是在时间Td内才用来送有用的数据（包括分组的首部），因此信道的利用率U可用下式计算：U=Td/(Td+RTT+Ta)
            请注意，更细致的计算还可以在上式分子的时间Td内扣除传送控制信息（如首部）所花费的时间。但在进行粗略计算时，用近似的式子就可以了。
        我们知道，式子中的往返时间RTT取决于所使用的信道。例如，假定1200km的信道的往返时间RTT=20ms。分组长度是1200bit，发送速率是1Mb/s。若忽略处理时间和Ta（Ta一般都远小于Td），则可算出信道的利用率U=5.66%。但若把发送塑料厂提高到10Mb/s，则U=5.71x10^(-4)。信道在绝大多数时间内都是空闲的。
        从中还可以看出，当往返时间RTT远大于分组发送时间Td时，信道的利用率就会非常低。还应注意的是，并没有考虑出现差错后的分组重传。若出现重传，则对传送有用的数据信息来说，信道的利用率就还要降低。
        为了提高传输效率，发送方可以不使用低效率的停止等待协议，而是采用流水线传输。流水线传输就是发送方可连续发送多个分组，不必没发完一个分组就停顿下来等待对方的确认。这样可使信道上一直有数据不间断地在传输。显然，这种传输方式可以获得很高的新到利用率。
        当使用流水线传输时，就要使用下面介绍的连续ARQ协议和滑动窗口协议。
    5.4.2连续ARQ协议
        滑动窗口协议比较复杂，是TCP协议的精髓所在。这里先给出连续ARQ协议最基本的概念，但不涉及到许多细节问题。详细的滑动窗口协议将在后面的5.6节中讨论。
        发送方维持的发送窗口，它的意义是：位于发送窗口内的5个分组都可连续发送出去，而不需要等待对方的确认。这样，信道利用率就提高了。
        连续ARQ协议规定，发送方每收到一个确认，就把发送串口向前滑动一个分组的位置。发送方收到了对第1个分组的确认，于是把发送窗口向前移动一个分组的位置。如果原来已经发送了前5个分组，那么现在就可以发送窗口内的第6个分组了。
        接收方一般都是采用累计确认的方式。这就是说，接收方不必对收到的分组逐个发送确认，而是可以在收到几个分组后，对按序到达的最后一个分组发送确认，这样就表示：到这个分组为止的所有分组都已正确收到了。
        累积确认有优点也有缺点。优点是：容易实现，即使确认丢失也不必重传。但缺点是不能向发送方反映出接收方已经正确收到的所有分组的信息。
        例如，如果发送方发送了前5个分组，而中间的第3个分组丢失了。这是接收方只能对前两个分组发出确认。发送方无法知道后面三个分组的下落，而只好把后面的三个分组都再重传一次。这就叫做Go-back-N（回退 N），表示需要再退回来重传已发送过的N个分组。可见当通信线路质量不好时，连续ARQ协议会带来负面的影响。
        在深入讨论TCP的可靠传输问题之前，必须先了解TCP的报文段首部的格式。
5.5TCP报文段的首部格式
    TCP虽然是面向字节流的，但是 TCP传送的数据单元却是报文段。一个 TCP报文段分为首部和数据两部分，而TCP的全部功能都体现在他首部中个字段的作用。因此，只有弄清TCP首部各字段的作用才能掌握TCP的工作原理。下面就讨论TCP报文段的首部格式。
    TCP报文段首部的前20个字节是固定的，后面有4N字节是根据需要而增加的选项（N是整数）。因此TCP首部的最小长度是20字节。
    首部固定部分个字段的意义如下：
    1）源端口和目的端口    各占2个字节，分别写入源端口号和目的端口号。和前面所示的UDP的分用相似，TCP的分用功能也是通过端口实现的。
    2）序号    占4字节。序号范围是[0,2^32-1]，共2^32（即4284967296）个序号。序号增加到2^32-1后，下一个序号又回到0.也就是说，序号使用mod 2^32运算。TCP是面向字节流的。在一个TCP连接中传送的字节流中的每一个字节都按顺序编号。整个要传送的字节流的起始序号必须在连接建立时设置。首部中的序号字段值则指的是本报文段所要发送的数据的第一个字节的序号。例如，一报文段的序号字段值是301，而携带的数据共有100字节。这就表明：本报文段的数据的第一个字节的序号是301，最后一个字节的序号是400.显然，下一个报文段（如果还有的话）的数据序号应当从401开始，即下一个报文段的序号字段值应为401.这个字段的名称也叫做“报文段序号”。
    3）确认号   占4字节，是期待收到对方下一个报文段的第一个数据字节的序号。例如，B正确收到了A发送过来的一个报文段，其序号字段值是501，而数据长度是200字节（序号501~700），这表明B正确收到了A发送的到序号700为止的数据。因此，B期望收到A的下一个数据序号是701，于是B在发送给A的确认报文段中把确认号置为701.请注意，现在的确认号不是501，也不是700，而是701。
    总之，应当记住：若确认号=N，则表明：到序号N-1为止的所有数据都已正确收到。
    由于序号字段有32位长，可对4Gb（即4千兆字节）的数据进行编号。在一般情况下可保证当序号重复使用时，旧序号的数据早已通过网络到达终点了。
    5）数据偏移    占4位，它指出TCP报文段的数据起始处距离TCP报文段的起始处有多远。这个字段实际上是指出TCP报文段的首部长度。由于首部中还有长度不确定的选项字段，因此数据偏移字段是必要的。但请注意，“数据偏移”的单位是32位字（即以4字节长的字为计算单位）。由于4位二进制数能够表示的最大十进制数字是15，因此数据偏移的最大值是60字节，这也是TCP首部的最大长度（即选项长度不能超过40字节）。
    6）保留    占6位，保留为今后使用，但目前应置为0。
    下面由6个控制位说明本报文段的性质，它们的意义见下面的7）~12）。
    7）紧急URG（URGent）   当URG=1时，表明紧急指针字段有效。它告诉系统此报文段中有紧急数据，应尽快传送（相当于高优先级的数据），而不要按原来的排队顺序来传送。例如，已经发送了很长的一个程序要在远地的主机上运行。但后来发现了一些问题，需要取消改程序的运行。因此用户从键盘发出中断命令（Control+C）。如果不使用紧急数据，那么这两个字符将存储在接收TCP的缓存末尾。只有在所有的数据被处理完毕后这两个字符才被交付到接收方的应用进程。这样做就浪费了许多时间。
    当URG置为1时，发送应用进程就告诉发送方的TCP有紧急数据要传送。于是发送方TCP就把紧急数据插入到本报文段数据的最前面，而在紧急数据后面的数据仍是普通数据。这是要与首部中紧急指针（Urgent Pointer）字段配合使用。
    8）确认ACK（ACKnowlegment）    仅当ACK=1时确认号字段才有效。当ACK=0时，确认号无效。TCP规定，在连接建立后所有传送的报文都必须把ACK置1.
    9）推送PSH（PuSH）   当两个应用进程进行交互式的通信时，有时在一端的应用进程希望在键入一个命令后立即就能够收到对方的响应。在这种情况下，TCP就可以使用推送（push）操作。这时，发送方TCP把PSH置1，并立即创建一个报文段发送出去。接收方TCP收到PSH=1的报文段，就尽快地（即“推送”向前）交付给接收应用进程，而不再等到整个缓存都填满了后再向上交付。
    虽然应用程序可以选择推送操作，但推送操作还很少使用。
    10）复位RST（ReSet）   当RST=1时，表明TCP连接中出现严重差错（如由于主机崩溃或其他原因），必须释放连接，然后再重新建立运输连接。RST置1好用来拒绝一个非法的报文段或拒绝打开一个连接。RST也可称为重建位或重置位。
    11）同步SYN（SYNchronization）   在连接建立时用来同步序号。当SYN=1而ACK=0时，表明这是一个连接请求报文段。对方若同意建立连接，则应在响应的报文段中使SYN=1和ACK=1.因此，SYN置为1就表示这是一个连接请求或连接接受报文。关于连接的建立和释放，在后面的5.9节还要进行详细讨论。
    12）终止FIN（FINis，意思是“完”、“终”）    用来释放一个连接。当FIN=1时，表明此报文段的发送方的数据已发送完毕，并要求释放运输连接。
    13）窗口   占2字节。窗口值是[0,2^16-1]之间的整数。窗口指的是发送本报文段的一方的接收窗口（而不是自己的发送窗口）。窗口值告诉对方：从本报文段首部中的确认号算起，接收方目前允许对方发送的数据量。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。总之，窗口值作为接收方让发送方设置其发送窗口的一句。
    例如，设确认号是701，窗口字段是1000。这就表明，从701号算起，发送此报文段的一方还有接收1000个字节数据（字节序号是701~1700）的接收缓存空间。
    最值，应当记住：窗口字段明确指出了现在允许对方发送的数据量。窗口值是经常在动态变化着。
    14）检验和    占2字节。检验和字段检验的范围包括首部和数据这两部分。和UDP用户数据报一样。在计算检验和时，要在TCP报文段的前面加上12字节的伪首部。伪首部的格式与UDP影虎数据报的伪首部一样。但应把伪首部第4个字段中的17改为6（TCP的协议号是6），把第5字段中的UDP长度改为YCP长度。接收方收到此报文段后，仍要加上这个伪首部来计算检验和。若使用IPv6，则相应的伪首部也要改变。
    15）紧急指针   占2字节。紧急指针仅在URG=1时才有意义，它指出本报文段中的紧急数据字节数（紧急数据结束后就是普通数据）。因此紧急指针指出了紧急数据的末尾在报文段中的位置。当所有紧急数据都处理完时，TCP就告诉应用程序恢复到正常操作。值得注意的是，即使窗口为零时也可发送紧急数据。
    16）选项   长度可变，最长可达40字节。当没有使用选项时，TCP的首部长度是20字节。
    TCP最初只规定了一种选项，即最大报文段长度MSS（Maximum Segment Size）。请注意MSS这个名词的含义。MSS是每一个TCP报文段中的数据字段的最大长度。数据字段加上TCP首部才等于整个的TCP报文段。所以MSS并不是整个TCP报文段的最大长度，而是“TCP报文段长度减去TCP首部长度”。
    为什么要规定一个最大报文段长度MSS呢？这并不是考虑接收方的接收缓存可能放不下TCP报文段中的数据。实际上，MSS与接收窗口值没有关系。我们知道，TCP报文段的数据部分，至少要加上40字节的首部（TCP首部20字节和IP首部20字节，这里都还没有考虑首部中的选项部分），才能组装成一个IP数据报。若选择较小的 MSS长度，网络的利用率就降低。设想在极端的情况下，当TCP报文段只含有1字节的数据时，在IP层传输的数据报的开销至少有40字节（包括TCP报文段的首部和IP数据报的首部）。这样，对网络的利用率就不会超过1/41。到了数据链路层还要加上一些开销。但反过来，若TCP报文段非常长，那么在IP层传输时就有可能要分解成多个短数据报片。在终点要把收到的各个短数据报片装配成原来的TCP报文段。当传输出错时还要进行重传。这些也都会使开销增大。
    因此，MSS应尽可能大些，只要在IP层传输时不需要再分片就行。由于IP数据报所经历的路径是动态变化的，因此在这条路径上确定的不需要分片的MSS，如果改走另一条路径就可能需要进行分片。因此最佳的MSS是很难确定的。在连接建立的过程中，双方都把自己能够支持的MSS写入这一字段，以后就按照这个数值传送数据，两个传送方向可以有不同的MSS值。若主机未填写这一项，则MSS的默认值是536字节长。因此，所有在因特网上的主机都应能接受的报文段长度是536+20（固定首部长度）=556字节。
    随着因特网的发展，又陆续增加了几个选项。如窗口扩大选项、时间戳选项等。以后又层架了有关选择确认选项。
    窗口扩大选项是为了扩大窗口。我们知道，TCP首部中窗口字段长度是16位，因此最大的窗口大小为64K字节（见下一节）。虽然这对早期的网络是足够用的，但对于包含卫星信道的网络，传播时延和带宽都很大，要获得高吞吐率需要更大的窗口大小。
    窗口扩大选项占3字节，其中有一个字节表示位移值S。新的窗口值等于TCP首部中的窗口位数从16增大到（16+S），这相当于把窗口值向左移动S位后获得实际的窗口大小。位移值允许使用的最大值是14，相当于窗口最大值增大到2^(16+14)-1=2^30-1。
    窗口扩大选项可以在双方初始建立TCP连接时进行协商。如果连接的某一端实现了窗口扩大，当它不再需要扩大其窗口时，可发送S=0的选项，使窗口大小回到16。
    时间戳选项占10字节，其中最主要的字段时间戳值字段（4字节）和时间戳回送回答字段（4字节）。时间戳选项有以下两个功能：
        第一，用来计算往返时间RTT（见后面的5.6.2节）。发送方在发送报文段时把当前时钟的时间值放入时间戳字段，接收方在确认该报文段时把时间戳字段值复制到时间戳回送回答字段。因此，发送方在收到确认报文后，可以准确地计算出RTT来。
        第二，用于处理TCP序号超过2^32的情况，这又称为防止序号绕回PAWS（Protect Against Wrapped Sequence numbers）。我们知道，序号只有32位，而每增加2^32个序号很可能会被重复使用。例如，若用1Gb/s的速率发送报文段，则不到4.3秒钟数据字节的序号就会重复。为了使接收方能够把新的报文段和迟到很久的报文段区分开，可以在报文中加上这种时间戳。
    关于选择确认选项，我们将在后面的5.6.3节介绍。
5.6TCP可靠传输的实现
    本节讨论TCP可靠传输的实现。
    我们首先介绍以字节为单位的滑动窗口。为了讲述可靠传输原理的方便，我们假定数据传输只在一个方向进行，即A发送数据，B给出确认。这样的好处是使讨论限于两个窗口，即发送方A的接收窗口和接收方B的接收窗口。如果再考虑B也向A发送数据，那么还要增加A的接受窗口和B的发送窗口，这对讲述可靠传输的原理并没有多少帮助，反而会使问题更加繁琐。
    5.6.1以字节为单位的滑动窗口
        TCP的滑动窗口是以字节为单位的。为了便于说明，我们故意把后面的字节编号都取得很小。先假定A收到了B发来的确认报文段，其中窗口是20（字节），而确认号是31（这表明B期望收到的下一个序号是31，而序号30位置的数据已经收到了）。根据这两个数据，A就构造出自己的发送窗口。
        我们先讨论发送方A的发送窗口。发送窗口表示：在没有收到B的确认的请款下，A可以连续把窗口内的数据都发送出去。凡是已经发送过的数据，在未收到确认之前都必须暂时保留，以便在超时重传时使用。
        发送窗口里面的序号表示允许发送的序号。显然，窗口越大，发送方就可以在收到对方确认之前连续发送更多的数据，因而可能获得更高的传输效率。但接收方必须来得及处理这些收到的数据。
        发送窗口后沿的后面部分表示已发送且已收到了确认。这些数据显然不需要再保留了。而发送窗口前沿的前面部分表示不允许发送的，因为接收方都没有位这部分数据保留临时存放的缓存空间。
        发送窗口的位置由窗口前沿和后沿的位置共同确定。发送串口后沿的变化情况有两种可能，即不动（没有收到新的确认）和前移（收到了新的确认）。发送窗口后沿不可能向后移动，因为不能撤销掉已收到的确认。发送窗口前沿通常是不断向前移动，但也有可能不动。这对于两种情况：一是没有收到新的确认，对方通知的窗口大小也不变；而是收到了新的确认但对方通知的窗口缩小了，使得发送窗口前沿正好不动。
        发送窗口前沿也有可能向后收缩。这发生在对方通知的窗口缩小了。但TCP的标准强烈不赞成这样做。因为很可能发送方在收到这个通知以前已经发送了窗口中的许多数据，现在又要收缩窗口，不让发送这些数据，这样就会产生一些错误。
        现在假定A发送了序号为31~41的数据。这时，发送窗口位置并未改变，但发送窗口内靠后面有11个字节便是已发送但未收到确认。而发送窗口内靠前面的9个字节（42~50）是允许发送但尚未发送的。
        从以上所述可以看出，要描述一个发送窗口的状态需要三个指针：P1，P2和P3。指针都指向字节的序号。这三个指针指向的几个部分的意义如下：
            小于P1的是已发送并已收到确认的部分，而大于P3的是不允许发送的部分。
            P3-P1=A的发送窗口（又称为通知窗口）
            P2-P1=已发送但尚未收到确认的字节数
            P3-P2=允许发送但尚未发送的字节数（又称为可用窗口或有效窗口）
        再看一下B的接收窗口。B的接收窗口大小是20。在接收窗口外面，到30号为止的数据是已经发送过确认，并且已经交付给主机了。因此在B可以不再保留这些数据。接收窗口内的序号是允许接收的。B收到了序号为32和33的数据。这些数据没有按序到达，因为序号为31的数据没有收到（也许丢失了，隭滞留在网络中的某处）。请注意，B只能对按序收到的数据中的最高序号给出确认，因此B发送的去人报文段中的去人好仍然是31（即期望收到的序号），而不是32或33。
        现在假定B收到了序号为31的数据，并把序号为31~33的数据交付给主机，然后B删除这些数据。接着把接收窗口向前移动3个序号，同时给A发送去人，其中窗口值仍为20，但确认号是34。这表明B已经收到了到序号33位置的数据。我们注意到，B还收到了序号为37，38和40的数据，但这些都没有按序到达，只能先暂存在接收窗口中。A收到B的确认后，就可以把发送窗口向前滑动3个序号，但指针P2不动。可以看出，现在A的可用窗口增大了，可发送的序号范围是42~53。
        A在继续发送完序号42~53的数据后，指针P2向前移动和P3重合。发送窗口内的序号都已用完，但还没有再收到确认。由于A的发送窗口已满，可用窗口已减小到零，因此必须停止发送。请注意，存在下面这种可能性，就是发送窗口内所有的数据都已正确到达B，B也早已发出了去人。但不幸的是，所有这些确认都滞留在网络中。在没有收到B的确认时，A不能猜测：“或许B收到了吧！”为了保证可靠传输，A只能认为B还没有收到这些数据。于是，A在经过一点时间后（由超时计时器控制）就重传这部分数据，重新设置超时计时器，知道收到B的去人为止。如果A收到确认号落在发送窗口内，那么A就可以使发送窗口继续向前滑动，并发送新的数据。
        我们在前面曾给出了这些的概念：发送方的应用进程把字节流写入TCP的发送缓存，接收方得应用进程从TCP的接收缓存中读取字节流。下面我们就进一步讨论前面讲的窗口和缓存的关系。发送方维持的发送缓存和发送窗口，以及接收方维持的接收缓存和接收窗口。这里首先要明确两点。第一，缓存空间和序号空间都是有限的，并且都是循环使用的。最好是把它们画成圆环状的。但这里为了画图的方便，我们还是把它们画成长条状的，同时也不考虑循环使用缓存空间和序号空间的问题。第二，由于实际上缓存或窗口中的字节数是非常大的，因此无法在图中一个个字节的位置标注清楚。这样，图中的一些指针也无法准确画成指向某一字节的位置。但这并不妨碍用这种表示来说明缓存和窗口的关系。
        我们先看一下发送方的情况。
        发送缓存用来暂时存放：
        1）发送应用程序传送给发送方TCP准备发送的数据；
        2） TCP已发送出但尚未收到确认的数据。
        发送窗口通常只是发送缓存的一部分。已被确认的数据应当从发送缓存中删除，因此发送缓存和发送窗口的后沿是重合的。发送应用程序最后写入发送缓存的字节减去最后被确认的字节，就是还保留在发送缓存中的被写入的字节数。发送应用程序必须控制写入缓存的速率，不能太快，否则发送缓存就会没有存放数据的空间。
        在看一下接收方的情况。
        接收缓存用来暂时存放：
        1）按序到达的、但尚未被接收应用程序读取的数据；
        2）未按序到达的数据。
        如果收到的分组被检测出有差错，则要丢弃。如果接收应用程序来不及读取收到的数据，接收缓存最终就会被填满，使接收矿口减小到零。反之，如果接收应用程序就够及时从接收缓存中读取收到的数据，接收窗口就可以增大，但最大不能超过接收缓存的大小。还指出了下一个期望收到的字节号。这个字节号也就是接收方给发送方的报文段的首部中的确认号。
        根据以上所讨论的，我们还要再强调以下三点。
        第一，虽然A的发送窗口是根据B的接收窗口设置的，但在同一时刻，A的发送窗口并不总是和B的接收窗口一样大。这是因为通过网络传送窗口值需要经历一定的时间滞后（这个时间还是不确定的）。另外，正如后面的5.7节将要讲到，发送方A还可能根据网络当时的拥塞情况适当减小自己的发送窗口数值。
        第二，对于不按序到达的数据应该如何处理，TCP标准并无明确规定。如果接收方把不按序到达的数据一律丢弃，那么接收窗口的管理将会比较简单，但这样做对网络资源的利用不利（因为发送方会重复传送较多的数据。）因此TCP通常对不按序到达的数据是先临时存放在接收窗口中，等到字节流中所缺少的字节收到后，再按序交付上层的应用进程。
        第三，TCP要求接收方必须有累积确认的功能，这样可以减少传输开销。接收方可以在合适的时候发送确认，也可以在自己有数据要发送时把确认信息顺便捎带上。但请注意两点。第一，接收方不应过分推迟发送确认，否则会导致发送方不必要的重传，这反而浪费了网络的资源。TCP标准规定，确认推迟的时间不应超过0.5秒。若收到一连串有最大长度的报文段，则必须每隔一个报文就要发送一个确认。第二，捎带确认实际上并不经常发生，因为大多数应用程序不同时在两个方向上发送数据。
        5.6.2超时重传时间的选择
        上面已经讲到，TCP的发送方在规定的时间内没有收到确认就要重传已发送的报文段。这种重传的概念是很简单的，但重传时间的选择却是TCP最复杂的问题之一。
        由于TCP的下层是互联网环境，发送的报文段可以只经过一个高速率的局域网，也可能经过多个低速率的网络，并且每个IP数据报选择的路由还可能不同。如果把超时重传时间设置得太短，就会引起很多报文段的不必要的重传，使网络负荷增大。但若把超时重传时间设置得过长，则又使网络的空闲时间增大，降低了传输效率。
        那么，运输层的超时计时器的超时重传时间究竟应设置为多大呢？
        TCP采用了一种自适应算法，它记录一个报文段发出的时间，以及收到相应的确认的时间。这两个时间之差就是报文段的往返时间RTT。TCP保留了RTT的一个加权平均往返时间RTTs（这又称为平滑的往返时间，S表示Smoothed。因为进行的是加权平均，因此得出的结果更加平滑）。每当第一次测量到RTT样本时，RTTs样本时，RTTs值就取为所测量到的RTT样本值。但以后没测量到一个新的RTT样本，就按下式重新计算一次RTTs：新的RTTs=（1-a）x（旧的RTTS）+ax（新的RTT样本）
        在上式中，0<=a<1。若a很接近于零，表示新的RTTs值和旧的RTTs值相比变化不大，而对新的RTT样本的影响较大（RTT值更新较快）。RFC 2988推荐的a值为1/8，即0.125。用这种方法得出的加权平均往返时间RTTs就比测量出的RTT值更加平滑。
        显然，超时计时器设置的超时重传时间RTO（RetransmissionTime-Out）应略大于上面得出的甲醛平均往返时间RTTs。RFC 2988建议使用下式计算RTO：RTO= RTTs+4xRTTd
        而RTTd是RTT的偏差的加权平均值，它与RTTs和新的RTT样本之差有关。RFC 2988建议这样计算RTTd。当第一次测量时，RTTd值取为测量到的RTT样本值的一半。在以后的测量中，则使用下式计算加权平均的RTTd：新的RTTd=（1-b）x（旧的RTTd）+bx|RTTs-新的RTT样本|
        这里b是个小于1的系数，它的推荐值是1/4，即0.25。
        上面所说的往返时间的测量，实现起来相当复杂。试看下面的例子。
        发送出一个报文段。设定的重传时间到了，还没有收到确认。于是重传报文段。经过了一段时间后，收到了确认报文段。现在的问题是：如何判定此确认报文段时对先发送的报文段的去人，还是对后来重传的报文段的确认？由于重传的报文段和原来的报文段完全一样，因此源主机在收到确认后，就无法做出正确的判断，而正确的判断对确定加权平均RTTs的值关系很大。
        若收到的确认是对重传报文段的确认，但却被源主机当成是对原来的报文段的确认，则这样计算出的RTTs和超时重传时间RTO就会偏大。若后面再发送的报文段又是经过重传后才收到确认报文段，则按此方法得出的超时重传时间RTO就越来越长。
        同样，若收到的确认是对原来的报文段的确认，但被当成是对重传报文段的确认，则由此计算出的RTTs和RTO都会偏小。这就必然导致报文段过多地重传。这样就有可能使RTO越来越短。
        根据以上所述，Karn提出了一个算法：在计算加权平均RTTs时，只要报文段重传了，就不采用其往返时间样本。这样得出的加权平均RTTs和RTO就较准确。
        但是，这又引起新的问题。设想出现这样的情况：报文段的时延突然增大了很多。因此在原来得出的重传时间内，不会收到确认报文段。于是就重传本文段。但根据Karn算法，不考虑重传的报文段的往返时间样本。这样，超时重传时间就无法更新。
        因此要对Karn算法进行修正。方法是：报文段每重传一次，就把超时重传时间RTO增大一些。典型的做法是取新的重传时间为2倍的旧的重传时间。当不再发生报文段的重传时，才根据上面给出的式子计算超时重传时间。实践证明，这种策略较为合理。
        5.6.3选择确认SACK
        现在还有一个问题没有讨论。这就是若收到的报文段无差错，只是未按序号，中间还缺少一些序号的数据，那么能否只传送缺少的数据而不重传已经正确到达接收方的数据？答案是可以的。选择确认就是一种可行的处理方法。
        我们用一个例子来说明选择确认（Selective ACK） 的工作原理。TCP的接收方在接受对方发送过来的数据字节流的序号不连续，结果就形成了一些不连续的字节块。可以看出，序号1~1000收到了，但序号1001~1500没有收到。接下来的字节流有收到了，可以又缺少了3001~3500.再后面从序号4501起又没有收到。也就是说，接收方收到了和前面的字节流不连续的两个字节块。如果这些字节的序号都在接收窗口之内。那么接收方就先收下这些数据，但要把这些信息准确地告诉发送方，使发送方不要再重复发送这些已收到的数据。
        从中可看出，和前后字节不连续的每一个字节块都有两个边界：左边界和右边界。因此在图中用四个指针标记这些边界。请注意，第一个字节块的左边界L1-1501，但右边界R1=3001而不是3000。这就是说，左边界指出字节块的第一个字节的序号，但右边界减1才是字节块中最后一个序号。同理，第二个字节块的左边界L2=3501，而右边界R2=4501。
        我们知道，TCP的首部没有那个字段能够提供上述这些字节块的边界信息。RFC 2018规定，如果要使用选择确认，那么在建立TCP连接时，就要在TCP首部的选项中加上“允许SACK”的选项，而双方必须都事先商定好。如果使用选择确认，那么原来首部中的“确认号字段”的用法仍然不变。只是以后再TCP报文段的首部中都增加了SACK选项，以便报告收到的不连续的字节块的边界。由于首部选项的长度最多只有40字节，而指明一个边界就要用掉4字节（因为序号又32位，需要使用4个字节表示），因此在选项中最多只能指明4个字节块的边界信息。这是因为4个字节块共有8个边界，因而需要用32个字节来描述。另外还需要两个字节。一个字节用来指明是SACK选项，另一个字节是指明这个选项要占用多少字节。如果要报告五个字节块的边界信息，那么至少需要42个字节。这就超过了选项长度的40字节的上限。RFC 2018还对报告这些边界信息的格式都做出了非常明确的规定，这里从略。
        然而，SACK文档并没有指明发送方应当响应SACK。因此大多数的实现还是重传所有未被确认的数据块。
    5.7TCP的流量控制
        5.7.1利用滑动窗口实现流量控制
        一般说来，我们总是希望数据传输得更快一些。但如果发送方把数据发送的过快，接收方就可能来不及接收，这就会造成数据的丢失。所谓流量控制（flow control）就是让发送方的发送速率不要太快，要让接收方来得及接收。
        利用滑动窗口机制可以很方便地在TCP连接上实现对发送方的流量控制。
        下面通过图中的例子说明如何利用滑动窗口机制进行流量控制。
        设A向B发送数据。在连接建立时，B告诉了A：“我的接收窗口rwnd=400”（这里rwnd表示receiver window）。因此，发送方的发送窗口不能超过接收方给出的接收窗口的数值。请注意，TCP的窗口单位是字节，不是报文段。TCP连接建立时的窗口协商过程在图中没有显示出来。再设每一个报文段为100字节长，而数据报文段序号的初始值设为1（见图中第一个箭头上面的序号seq=1.图中右边的注释可帮助理解整个过程）。请注意，图中箭头上面大写ACK表示首部中的确认位ACK，小写ack表示确认字段的值。
                A                               B
                |         seq=1,DATA            |
                |------------------------------>|A发送了序号1至100，还能发送300字节
                |         seq=101,DATA          |
                |------------------------------>|A发送了序号101至200，还能发送200字节
                |         seq=201,DATA          |
                |-------------------------->丢失|
                |   ACK=1,ack=201，rwnd=300     |
                |<------------------------------|允许A发送了序号201至500共300字节
                |         seq=301,DATA          |
                |------------------------------>|A发送了序号301至400，还能发送100字节新数据
                |         seq=401,DATA          |
                |------------------------------>|A发送了序号401至500，不能再发送新的数据了
                |         seq=201,DATA          |
                |------------------------------>|A超市重发旧的数据，但不能发送新的数据
                |   ACK=1，ack=501，rwnd=100    |
                |<------------------------------|允许A发送了序号5011至600共100字节
                |         seq=501,DATA          |
                |------------------------------>|A发送了序号501至600，不能再发送了
                |   ACK=1，ack=601，rwnd=0      |
                |<------------------------------|不循序A再发送（到序号600为止的数据都收到了）
        我们应注意到，接收方的主机B进行了三次流量控制。第一次把窗口减小到rwnd=300，第二次又减到rwnd=100，最后减到rwnd=0，即不循序发送方再发送数据了。这种使发送方暂停发送的状态将持续到主机B重新发出一个新的窗口值为止。我们还应注意到，B向A发送的三个报文段，都设置了ACK=1，只有在ACK=1时确认号字段才有意义。
        现在我们考虑一种情况。在图中，B向A发送了零窗口报文段后不久，B的接收缓存又有了一些空间。于是B向A发送了rwnd=400的报文段。然而这个报文段在传送过程中丢失了。A一直等待收到B发送的非零窗口的通知，而B也一直等待A发送的数据。如果没有其他措施，这种互相等待的死锁局面将会一直延续下去。
        为了解决这个问题，TCP为每一个连接设有一个持续计时器（persistence timer）。只要TCP连接的一方收到对方的零窗口通知，就启动持续计时器。若持续计时器设置的时间到期，就发送一个零窗口探测报文段（仅携带1字节的数据），而对方就在确认这个探测报文段时给出了现在的窗口值。如果窗口仍然是零，那么收到这个报文段的一方就重新设置持续计时器。如果窗口不是零，那么死锁的僵局就可以打破了。
        5.7.2必须考虑传输效率
        前面已经讲过，应用进程把数据传送到TCP的发送缓存后，剩下的发送任务就由TCP来控制了。可以用不同的机制来控制TCP报文段的发送时机。例如，第一种机制是TCP维持一个变量，它等于最大报文段长度MSS。只要缓存中存放的数据达到MSS字节时，就组装成一个TCP报文段发送出去。第二种机制是由发送方的应用进程指明要求发送报文段，即TCP支持的推送（push）操作。第三种机制是发送方的一个计时器期限到了，这是就把当前已有的缓存数据装入报文段（但长度不能超过MSS）发送出去。
        但是，如何控制TCP发送白文段的时机仍然是一个较为复杂的问题。
        例如，一个交互式用户使用一条TELNET连接（运输层为TCP协议）。设用户只发一个字符。加上20字节的首部后，得到21字节长的TCP报文段。再加上20字节的IP首部，形成41字节长的IP数据报。在接收方TCP立即发出确认，构成的数据报时40字节长（假定没有数据发送）。若用户要求远地主机回送这一字符，则又要发回41字节长的IP数据报和40字节长的确认IP数据报。这样，用户仅发一个字符时线路上就需传送总长度为162字节共4个报文段。当线路带宽并不富裕时，这种传送方法的效率的确不高。因此应适当推迟发回确认报文，并尽量使用捎带确认的方法。
        在TCP的实现中广泛使用Nagle算法。算法如下：若发送应用进程把要发送的数据逐个字节地送到TCP的发送缓存，则发送方就把第一个数据字节先发送出去，把后面到达的数据字节都缓存起来。当发送方收到对第一个数据字符的确认后，再把发送缓存中的所有数据组装成一个报文段发送出去，同时继续对随后到达的数据进行缓存。只有在收到对前一个报文段的确认后才继续发送下一个报文段。当数据到达较快而网络速率较慢时，用这样的而方法可明显地减少所用的网络带宽。Nagle算法还规定，当到达的数据已达到发送窗口大小的一半或已达到报文段的最大长度时，就立即发送一个报文段。
        另一个问题叫做糊涂窗口综合征（silly window syndrome），有时也会使TCP的性能变坏。设想一种情况：TCP接收方的缓存已满，而交互式的应用进程一次只从接受缓存中读取1个字节（这样就使接收缓存空间仅腾出1个字节），然后向发送方发送确认，并把窗口设置为1个字节（但发送的数据报时40字节长）。接着，发送方又发来1个字节的数据（请注意，发送方发送的IP数据报时41字节长）。接收方发回确认，仍然将窗口设置为1个字节。这样进行下去，使网络的效率很低。
        要解决这个问题，可以让接收方等待一段时间，使得或者接收缓存已有足够空间容纳一个最长的报文段，或者等待接收缓存已有一半空闲的空间。只要出现这两种情况之一，接收方就发出确认报文，并向发送方通知当前的窗口大小。此外，发送方也不要发送太小的报文段，而是把数据积累长足够大的报文段，或达到接收方缓存的空间的一半大小。
        上述两种方法可配合使用。使得在发送方不发送很小的报文段的同时，接收方也不要在缓存刚刚有了一点小的空间就急忙把这个很小的窗口大小信息通知给发送方。
    5.8 TCP的拥塞控制
      5.8.1拥塞控制的一般原理
        在计算机网络中的链路容量（即带宽）、交换结点中的缓存和处理机等，都是网络的资源。在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的心梗就要变坏。这种情况就叫做拥塞（congestion）。可以把出现网络拥塞的条件写成如下的关系式：∑对资源的需求>可用资源
        若网络中有许多资源同时呈现供应不足，网络的性能就要明显变坏，整个网络的吞吐量将随输入负荷的增大而下降。
        有人可能会说：“只要任意增加一些资源，例如，把结点缓存的存储空间扩大，或把链路更换为更高速率的链路，或把结点处理机的运算速度提高，就可以解决网络拥塞的问题。”其实不然。这是因为网络拥塞是一个非常复杂的问题。简单地采用上述做法，在许多情况下，不但不能解决拥塞问题，而且还可能使网络的性能更坏。
        网络拥塞往往是由许多因素引起的。例如，当某个结点缓存的容量太小时，到达该结点的分组因无存储空间暂存而不得不被丢弃。现在设想将该结点缓存的容量扩展到非常大。于是凡到达该结点的分组均可在结点的缓存队列中排队，不受任何限制。由于输出链路的容量和处理机的速度并未提高，因此在这队列中的绝大多数分组的排队等待时间将会大大增加，结果上层软件只好把它们进行重传（因为早就超时了）。由此可见，简单地扩大缓存的存储空间同样会造成网络资源的严重浪费，因而解决不了网络拥塞的问题。
        又如，处理机处理的速率太慢可能引起网络的拥塞。简单地将处理机的速率提高，可能会使上述情况缓解一些，但往往又会将瓶颈转移到其他地方。问题的实质往往是整个系统的各个部分不匹配。只有所有的部分都平衡了，问题才会的到解决。
        拥塞常常趋于恶化。如果一个路由器没有足够的缓存空间，它就会丢弃一些新到的分组。但当分组被丢弃时，发送这一分组的源点就会重传这一分组，甚至可能还要重传多次。这样会引起更多的分组流入网络和被网络中的路由器丢弃。可见拥塞引起的重传并不会缓解网络的拥塞，反而会加剧网络的拥塞。
        拥塞控制与流量控制的关系密切，它们之间也存在着一些差别。所谓拥塞控制就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有主机、所有的路由器，以及与降低网络传输性能有关的所有因素。但TCP连接的端点只要迟迟不能收到对方的确认信息，就猜想在当前网络中的某处很可能发生了拥塞，但这时却无法知道拥塞到底发生在网络的何处，也无法知道发生拥塞的具体原因（是访问某个服务器的通信量过大？还是在某个地区出现自然灾害？）。
        相反，流量控制往往指点对点通信量的控制，是个端到端的问题（接收端控制发送端）。流量控制所要做的就是抑制发送端的发送数据的速率，以便使接收端来得及接收。
        可以用个简单例子说明这种区别。设某个光纤网络的链路传输速率为1000Gb/s。有一个巨型计算机向一个PC机以1Gb/s的速率传送文件。显然，网络本身的带宽是足够大的，因而不存在产生拥塞的问题。但流量控制却是必须的，因为巨型计算机必须经常停下来，以便使PC机来得及接收。
        但如果有另一个网络，其链路传输速率为1Mb/s，而有1000台大型计算机连接在这个网络上。假定其中的500台计算机分别向其余的500台计算机以100kb/s的速率发送文件。那么现在的问题已不是接收端的大型计算机是否来得及接收，而是整个网络的输入负载是否超过网络所能承受的。
        拥塞控制和流量控制之所以常常被弄混，是因为这些拥塞控制算法是发送端发送控制报文，并告诉发送端，网络已出现麻烦，必须放慢发送速率。这点又和流量控制是很相似的。
        进行拥塞控制需要付出代价。这首先需要获得网络内部流量分布的信息。在实施拥塞控制时，还需要在结点之间交换信息和各种命令，以便选择控制的策略和实施控制。这样就产生了额外开销。拥塞控制有时需要将一些资源（如缓存、带宽等）分配给个别用户（或一些类别的用户）单独使用，这样就使得网络资源不能更好地实现共享。十分明显，在设计拥塞控制策略时，必须全面衡量得失。
        在图中的横坐标是提供的负载（offered load），代表单位时间内输入给网络的分组数目。因此提供的负载也称为输入负载或网络负载。纵坐标是吞吐量（throughput），代表单位时间内从网络输出的分组数目。具有理想拥塞控制的网络，在吞吐量饱和之前，网络吞吐量应等于提供的负载，故吞吐量曲线是45°的斜线。但当提供的负载超过某一限度时，由于网络资源受限，吞吐量不再增长而保持为水平线，即吞吐量达到饱和。这就表明提供的负载中有一部分损失掉了（例如，输入到网络的某些分组被某个结点丢弃了）。虽然如此，在这种理想的拥塞控制作用下，网络的吞吐量仍然维持在其所能达到的最大值。
        但是，实际网络的情况就很不相同了。从图中可看出，随着提供的负载的增大，网络吞吐量的增长速率逐渐减小。也就是说，在网络吞吐量还未达到饱和时，就已经有一部分的输入分组被丢弃了。当网络的吞吐量明显地小于理想的吞吐量时，网络就进入了轻度拥塞的状态。更值得注意的是，当提供的负载达到某一数值时，网络的吞吐量反而岁提供的负载的增大而下降，这是网络就进入了拥塞状态。当提供的负载继续增大到某一数值时，网络的吞吐量就下降到零，网络已无法工作。这就是所谓的死锁（deadload）。
        从原理上讲，寻找拥塞控制的方案无非是寻找使不等式不再成立的条件。这或者是增大网络的某些可用资源（如业务繁忙时增加一些链路，增大链路的带宽，或使额外的通信量从另外的通路分流），或减少一些用户对某些资源的需求（如拒绝接受新的建立连接的请求，或要求用户减轻其负荷，这属于降低服务质量）。但正如上面所讲过的，在采用某种措施时，还必须考虑到该措施所带来的其他影响。
        实践证明，拥塞控制是很难设计的额，因为它是一个动态的（而不是静态的）问题。当前网络正朝着高速化的方向发展，这很容易出现缓存不够大而造成分组的丢失。但分组的丢失是网络发生拥塞的征兆而不是原因。在许多情况下，甚至正是拥塞控制机制本身成为引起网络性能恶化甚至发生死锁的原因。这点应特别引起重视。
        由于计算机网络是一个很复杂的系统，因此可以从控制理论的角度来看拥塞控制这个问题。这样，从大的方面看，可以分为开环控制和闭环控制两种方法。开环控制方法就是在设计网络时事先将有关发生拥塞的因素考虑周到，力求网络在工作时不产生拥塞。但一旦整个系统运行起来，就不再中途进行改正了。
        闭环控制是基于反馈环路的概念。属于闭环控制的有以下几种措施：
        （1）监测网络系统以便检测到拥塞在何时、何处发生。
        （2）把拥塞发生的信息传送到可采取行动的地方。
        （3）调整网络系统的运行以解决出现的问题。
        有很多的方法可用来监测网络的拥塞。主要的一些指标是：由于缺少缓存空间而被丢弃的分组的百分数；平均队列长度；超时重传的分组数；平均分组时延；分组时延的标准差，等等。上述这些指标的上升都标志着拥塞的增长。
        一般在监测到拥塞发生时，要将拥塞发生的信息传送到产生分组的源站。当然，通知拥塞发生的分组同样会使网络更加拥塞。
        另一种方法是在路由器转发的分组中保留一个比特或字段，用该比特或字段的值表示网络没有拥塞或产生了拥塞。也可以由一些主机或路由器周期性地发出探测分组，以询问拥塞是否发生。
        此外，过于频繁地采取行动以缓和网络的拥塞，会使系统产生不稳定的震荡。但过于迟缓地采取行动又不具有任何使用价值。因此，要采用某种折中的方法。但选择正确的时间常数是相当困难的。
        一些更加具体的防止网络拥塞的方法将在后面的5.8.2节介绍。
      5.8.2 集中拥塞控制方法
      1999年公布的因特网建议标准 RFC 2581定义了进行拥塞控制的四种算法，即慢开始（slow-start）、拥塞避免（congestion avoidance）、快重传（fast retransmit）和快恢复（fast recovery）。以后RFC 2582和RFC 3390又对这些算法进行了一些改进。下面就介绍这些算法的原理。
      为了集中精力讨论拥塞控制，我们假定：
      （1）数据是单方向传送，而另一个方向只传送确认。
      （2）接收方总是有足够大的缓存空间，因而发送窗口的大小由网络的拥塞程度来决定。
      1.慢开始和拥塞避免
      发送方维持一个叫做拥塞窗口cwnd（congestion window）的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口。以后我们就知道，如果再考虑到接收方的接受能力，那么发送窗口还可能小于拥塞窗口。
      发送方控制拥塞窗口的原则是：只要网络没有出现拥塞，拥塞窗口就再增大一些，以便把更多的分组发送出去。但只要网络出现拥塞，拥塞窗口就减小一些，以减少注入到网络中的分组数。
      发送方又是如何知道网络发生了拥塞呢？我们知道，当网络发生拥塞时，路由器就要丢弃分组。因此只要发送方没有按时收到应到达的确认报文，就可以猜想网络可能出现了拥塞。现在通信线路的传输质量一般都很好，因传输出差错而丢弃分组的概率是很小的（远小于1%）。
      下面将讨论拥塞窗口cwnd的大小是怎样变化的。我们从慢开始算法讲起。
      慢开始算法的思路是这样的。当主机开始发送数据时，如果立即把大量数据字节注入到网络，那么就有可能引起网络拥塞，因为现在并不清楚网络的负荷情况。经验证明，较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是说，由小到大逐渐增大拥塞窗口数值。通常在刚刚开始发送报文段时，先把拥塞窗口cwnd设置为一个最大报文段MSS的数值。而在每收到一个对新的报文段的确认后，把拥塞窗口增加至多一个MSS的数值。用这样的方法逐步增大发送方的拥塞窗口cwnd，可以使分组注入到网络的速率更加合理。
      下面用例子说明慢开始算法的原理。为方便起见，我们用报文段的个数作为窗口大小的单位（请注意，实际上TCP是用字节作为窗口的单位），这样可以使用较小的数字来说明拥塞控制的原理。
      在一开始发送方先设置cwnd=1，发送第一个报文段M1，接收方收到后确认M1.发送方收到对M1的确认后，把cwnd从1增大到2，于是发送方接着发送M2和M3两个报文段。接收方收到后发回对M2和M3的确认。发送方每收到一个对新报文段的确认（重传的不算在内）就使发送方的拥塞窗口加1，因此发送方在收到两个确认后，cwnd就从2增大到4，并可以发送M4~M7共四个报文段。因此使用慢开始算法后，每经过一个传输轮次（transmission round），拥塞窗口cwnd就加倍。
      这里我们使用了一个名词--传输伦次。一个传输伦次所经历的时间其实就是往返时间RTT。不过使用“传输轮次”更加强调：把拥塞窗口cwnd所允许发送的报文段都连续发送出去，并收到了对已发送的最后一个字节的确认。例如，拥塞窗口cwnd的大小是4个报文段，那么这时的往返时间RTT就是发送方连续发送4个报文段，并收到这4个报文段的确认，总共经历的时间。
      我们还要指出，慢开始的“慢”并不是指cwnd的增长速率慢，而是指在TCP开始发送报文段时先设置cwnd=1，使得发送方在开始时只发送一个报文段（目的是试探一下网络的拥塞情况），然后再逐渐增大cwnd。这当然比按照大的cwnd一下子把报文段突然注入到网络中要“慢得多”。这对防止网络出现拥塞时一个非常有力的措施。
      为了防止拥塞窗口cwnd增长过大引起网络拥塞，还需要设置一个慢开始门限ssthresh状态变量（如何设置ssthresh，后面还要讲）。慢开始门限ssthresh的用法如下：
          当cwnd<ssthresh时，使用上述的慢开始算法。
          当cwnd>ssthresh时，停止使用慢开始算法而改用拥塞避免算法。
          当cwnd=ssthresh时，既可以使用慢开始算法，也可使用拥塞避免算法。
      拥塞避免算法的思路是让拥塞窗口cwnd缓慢地增大，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍。这样，拥塞窗口cwnd按线性规律缓慢增长，比慢开始算法的拥塞窗口增长速率缓慢得多。
      无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有按时收到确认），就要把慢开始门限ssthresh设置为出现拥塞时的发送方窗口值的一半（但不能小于2）。然后把拥塞窗口cwnd重新设置为1，执行慢开始算法。这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生拥塞的路由器有足够时间把队列中积压的分组处理完毕。
      图用具体的数值说明了上述拥塞控制的过程。现在发送窗口的大小和拥塞窗口一样大。
      （1）当TCP连接进行初始化时，把拥塞窗口cwnd置为1。前面已说过，为了便于理解，图中的窗口单位不使用字节而使用报文段的个数。慢开始门限的初始值设置为16个报文段，即ssthresh=16。
      （2）在执行慢开始算法时，拥塞窗口cwnd的初始值为1.以后发送方每收到一个对新报文段的去人ACK，就把拥塞窗口值加1，然后开始开始下一轮的传输（请注意，图中的横坐标是传输轮次）。因此拥塞窗口cwnd随着传输轮次按指数规律增长。当拥塞窗口cwnd增长到慢开始门限值ssthresh时（即当cwnd=16时），就改为执行拥塞避免算法，拥塞窗口按线性规律增长。
      （3）假定拥塞窗口的数值增长到24时，网络出现超时（这很可能就是网络发生拥塞了）。更新后的ssthresh值变为12（即变为出现超时时的拥塞窗口数值24的一半），拥塞窗口再重新设置为1，并执行慢开始算法。当cwnd=ssthresh=12时改为执行拥塞避免算法，拥塞窗口按线性规律增长，每经过一个往返时间增加一个MSS的大小。
      在TCP拥塞控制的文件中经常可看见“乘法减小”（Multiplicative Decrease）和“加法增大”（Additive Increase）这样的想法。“乘法减小”是指不论在慢开始阶段还是拥塞避免阶段，只要出现超时（即很可能出现了网络拥塞），就把慢开始门限ssthresh减半，即设置为当前的拥塞窗口的一半（与此同时，执行慢开始算法）。当网络频繁出现拥塞时，ssthresh值就下降得很快，以大大减少注入到网络中的分组数。而“加法增大”是执行拥塞避免算法后，是拥塞窗口缓慢增大，以防止网络过早出现拥塞。上面两种算法合起来常称为AIMD算法（加法增大乘法减小）。对这种算法进行适当修改后，又出现了其他一些改进的算法。但使用最广泛的还是AIMD算法。
      这里要再强调一下，“拥塞避免”并非指完全能避免了拥塞。利用以上的措施要完全避免网络拥塞还是不可能的。“拥塞避免”是说在拥塞避免阶段将拥塞窗口控制为按线性规律增长，使网络比较不容易出现拥塞。
      2.快重传和快恢复
      上面讲的慢开始和拥塞避免算法是1988年提出的TCP拥塞控制算法。1990年又增加了两个新的拥塞控制算法。这就是快重传和快恢复。
      提出这两个算法是基于如下的考虑：
      如果发送方设置的超时计时器时限已到但还没有收到确认，那么很可能是网络出现了拥塞，致使报文段在网络中的某处被丢弃。在这种情况下，TCP马上把拥塞窗口cwnd减小到1，并执行慢开始算法，同时把慢开始门限值ssthresh减半，如前面的图所示。这是不使用快重传的情况。
      再看使用快重传的情况。快重传算法首先要求接收方每收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方）而不要等待自己发送数据时才进行捎带确认。在图所示的例子中，接收方收到了M1和M2后都分别发出了确认。现假定接收方没有收到M3但接着收到了M4。显然，接收方不能确认M4，因为M4是收到的失序报文段（按照顺序的M3还没有收到）。根据可靠传输原理，接收方可以什么都不做，也可以在适当时机发送一次对M2的确认。但按照快重传算法的规定，接收方应及时发送对M2的重复确认，这样做可以让发送方及早知道报文段M3没有到达接收方。发送方接着发送M5和M6.接收方收到后，也还要再次发出对M2的重复确认。这样，发送方共收到了接收方的四个对M2的确认，其中后三个都是重复确认。快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段M3，而不必继续等待M2设置的重传计时器到期。由于发送方尽早重传未被确认的报文段，因此采用快重传后可以使整个网络的吞吐量提高约20%。
      与快重传配合使用的还有快恢复算法，其过程有以下两个要点：
      （1）当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把慢开始门限ssthresh减半。这是为了预防网络发生拥塞。请注意，接下去不执行慢开始算法。
      （2）由于发送方现在认为网络很可能没有发生拥塞（如果网络发生了严重的用四个，就不会一连有好几个报文段连续到达接收方，就不会导致接收方连续发送重复确认），因此与慢开始不同之处是现在不执行慢开始算法（即拥塞窗口cwnd现在不设置为1），而是把cwnd值设置为慢开始门限ssthresh减半后的数值，然后开始执行拥塞避免算法（加法增大），使拥塞窗口缓慢地线性增大。
      图给出了快重传和快恢复的示意图，并标明了“TCP Reno版本”，这是目前使用得很广泛的版本。图中还画出了已经废弃不用的虚线部分（TCP Tahoe版本）。请注意他们的区别就是：新的TCP Reno版本在快重传之后采用快恢复算法而不是采用慢开始算法。
      请注意，也有的快重传实现是把开始时的拥塞窗口cwnd值再增大一些（增大3个报文段的长度），即等于ssthresh+3xMSS。这样做的理由是：既然发送方收到三个重复的确认，就表明有三个分组已经离开了网络。这三个分组不再消耗网络的资源而是停留在接收方的缓存中（接收方发送出三个重复的确认就证明了这个事实）。可见现在网络中并不是堆积了分组而是减少了三个分组。因此可适当把拥塞窗口扩大写。
      在采用快恢复算法时，慢开始算法只是在TCP连接建立时和网络出现超时时才使用。
      采用这样的拥塞控制方法使得TCP的性能有明显的改进。
      在这一节的开始我们就假定了接收方总是有足够大的缓存空间，因而发送窗口的大小由网络的拥塞程度来决定。但实际上接收方的缓存空间总是有限的。接收方根据自己的接受能力设定了接收窗口rwnd，并把这个窗口值写入TCP首部中的窗口字段，传送给发送方。因此，接收窗口又称为通知窗口（advertised window）。因此，从接收方对发送方的流量控制的角度考虑，发送方的发送窗口一定不能超过对方给出的接受窗口值rwnd。
      如果把本节所讨论的拥塞控制和接收方对发送方的流量控制一起考虑，那么很显然，发送方的窗口的山新概念值应当取为接收方窗口rwnd和拥塞窗口cwnd这两个变量中较小的一个也就是说：发送方窗口的上限值=Min【rwnd，cwnd】
          式指出：
          当rwnd<cwnd时，是接收方的接受能力限制发送方窗口的最大值。
          反之，当cwnd<rwnd时，则是网络的拥塞限制发送方窗口的最大值。
          也就是说，rwnd和cwnd中较小的一个控制发送方发送数据的速率。
      5.8.3 随机早期检测RED
      上一节讨论的TCP拥塞控制并没有和网络层采取的策略联系起来。其实，它们之间是有着密切的关系。
      假如，假定一个路由器对某些分组的处理时间特别长，那么这就可能使这些分组中的数据部分（即TCP报文段）经过很长时间才能到达终点，结果引起发送方对这些报文段的重传。根据前面所讲的，重传会使TCP连接的发送端认为在网络中发生了拥塞。于是在TCP的发送端就采取了拥塞控制措施，但实际上网络并没有发生拥塞。
      网络层的策略对TCP拥塞控制影响最大的就是路由器的分组丢失策略。在最简单的情况下，路由器的队列通常都是按照“先进先出”FIFO（First In First Out）的规则处理到来的分组。由于队列长度总是有限的，因此当队列已满时，以后再到达的所有分组（如果能够继续排队，这些分组都将排在队列的尾部）将都被丢弃。这就叫做尾部丢弃策略（tail-drop polocy）。
      路由器的尾部丢弃往往会导致一连串分组的丢失，这就使发送方出现超时重传，使TCP进入拥塞控制的慢开始状态，结果使TCP连接的发送方突然把数据的发送速率降低到很小的数值。更为严重的是，在网络中通常有很多的TCP连接（他们有不同的源点和终点），这些连接中的报文段通常是复用在网络层的IP数据报中传送。在这种情况下，若发生了路由器中的尾部丢弃，就可能会用是影响到很多条TCP连接，结果使这许多TCP连接在同一时间突然都进入到慢开始状态。这在TCP的术语中称为全局同步（global syncronization）。全局同步使得全网的通信量突然下降了很多，而在网络恢复正常后，其通信量又突然增大很多。
      为了避免发生网络中的全局同步现象，可以在路由器采用随机早期检测RED（Random Early Detection）的措施。RED还有几个不同的名称，如Random Early Drop或Random Early Discard（随机早起丢弃）。实现RED的要点如下：
      使路由器的队列维持两个参数，即队列长度最小门限THmin和最大门限THmax。当每一个分组到达是RED组都先计算平均队列长度Lav（后年要讲如何计算）。RED的算法是：
      （1）若平均队列长度小于最小门限THmin，则把新到达的分组放入队列进行排队。
      （2）若平均队列长度超过最大门限THmax，则把新到达的分组丢弃。
      （3）若平均队列长度在最小门限THmin和最大门限THmax之间，则按照某一概率p将新到达的分组丢弃。
      图说明了以上参数的意义。在途中，RED把路由器的分组到达队列划分为三个区域，即正常排队、以概率p丢弃和必须丢弃的区域。
      随机早起检测RED中的“随机”就体现在RED算法中的（3）。也就是说，RED不是等到已经发生网络拥塞后才把所有在队列尾部的分组全部丢弃，而是在检测到网络拥塞的早期征兆时（即路由器的平均队列长度超过一定的门限值时），就先以概率p随机丢弃个别的分组，让拥塞控制只在个别的TCP连接上进行，因而避免发生全局性的拥塞控制。
      这样，是RED正常工作的关键就是要选择好三个参数：最先门限THmin、最大门限THmax和概率p。
      最小门限THmin必须足够大，以保证连接路由器的输出链路有较高的利用率。而最大门限THmax和最小门限THmin之差也应当足够大，使得在一个TCP往返时间RTT中队列的正常增长仍在最大门限THmax之内。经验证明，使最大门限THmax等于最小门限THmin值的两倍是合适的。如果门限值设定得不合适，则RED也可能会引起类似于尾部丢弃那样的全局震荡。
      在RED的操作中最复杂的就是丢弃概率p的选择，因为概率p不是常数。对每一个到达的分组，都必须计算丢弃概率p的数值。概率p的数值取决于当前的平均队列长度Lav和所设定的两个门限值THmin和THmax。更具体些就是根据下面三条原则来确定：
      （1）当平均队列长度Lav小于最小门限THmin时，分组丢弃概率p=0。
      （2）当平均队列长度Lav超过最大门限THmax时，分组丢弃概率p=1。
      （3）当平均队列长度Lav在THmin和THmax之间时，分组丢弃概率p应在0到1之间，例如，可以按照线性规律变化，从0变到pmax。
      为什么要使用“平均队列长度”呢？我们知道，计算机数据具有突发性的特点，因此路由器中的队列长度经常会出现很快的起伏变化。如果丢弃概率p是按照瞬时队列长度来计算，那就可能会出现一些不合理的现象。例如，很短的突发数据不太可能使杜烈溢出，因此对于这类数据，如果仅因为瞬时队列长度超过了门限值THmin就将其丢弃就会产生不必要的拥塞控制。图是瞬时队列长度和平均队列长度的区别的示意图。
      为此，RED采用了和计算平均往返时间RTT类似的加权平均的方法来计算平均队列长度Lav，并根据这个平均队列长度Lav求出分组丢弃概率p。公式给出了平均队列长度Lav的计算方法。
          平均队列长度Lav=（1-δ）x（旧的Lav）+δx（当前的队列长度样本）
      公式中的δ是在0到1之间的数。若δ足够小，则平均队列长度Lav取决于队列长度的长期变化趋势，而不受持续时间短的数据突发的影响。
      具体的做法是先按照下面的公式计算出分组丢弃概率p：p=ptemp/（1-countxPtemp）
      式中，count是一个变量，它代表新到达的分组有多少个已经进入了队列（没有被丢弃）；Ptemp是过度的分组丢弃概率：Ptemp=Pmax  x （Lav - THmin）/（THmax - THmin）
      下面用个具体的例子来说明这点。设Pmax=0.02，而变量count的初始值为0。再假定平均队列长度正好在两个门限之间，计算出过度的分组丢弃概率Ptemp=0.01。由于在开始时变量count=0，因此算出p=Ptemp=0.01。也就是说，现在到达的分组进入路由器的队列的概率是0.99。但随着分组的不断进入队列，变量count的值不断增大，由式算出的分组丢弃概率也逐渐增大。假定一连有50个分组进入了队列而没有被丢弃，这就使得分组丢弃概率增大到一倍，即P=0.02。再假定一连99个分组都没有被丢弃。那么这是由式算出丢弃概率p=1（设平均队列长度一致保持不变），表明下一个分组肯定要被丢弃。从这里可以看出，使分组丢弃概率p不仅与平均队列长度有关，而且还随着队列中不被丢弃的分组数目的增多而逐渐增大，就可以避免分组的丢弃过于集中。
      总之，随机早起检测RED好处就是当平均队列长度超过门限值THmin时，就会有哦少量的分组被丢弃，这就使得有少量的TCP连接会减小其窗口值，是的到达路由器的分组的数量减小。结果，队列平局长度就见笑了，从而避免了网络拥塞的发生。应当注意到，网络的吞吐量仍然保持在较高的数值，因此丢弃的分组的数量是很少的。
      我们还应注意到，路由器在某一时刻的瞬时队列长度完全可能远远超过平均队列长度。如果按照式算出的丢弃概率很小，单路由器的队列已经没有空间可接纳新到达的分组，那么这时RED的操作和“尾部丢弃”方式是一样的。RED只是在可能的条件下尽量使“尾部丢弃”不要发生。
      我们还可看出，RED机制使得路由器可以更好地管理其队列长度。但多长的队列是最佳长度仍然有待于进一步的研究。
      RED工作得很有效，IETF已经推荐在因特网中的路由器使用RED机制。
  5.9 TCP的运输连接管理
      TCP是面向连接的协议。运输连接是用来传送TCP报文的。TCP运输连接的建立和释放是每一次面向连接的通信中必不可少的过程。因此，运输连接就有三个阶段，即：连接建立、数据传送和连接释放。运输连接的管理就是使运输连接的建立和释放都能正常地进行。
      在TCP连接建立过程中要解决一下三个问题：
      （1）要使每一方能够确知对方的存在。
      （2）要循序双方写协商一些参数（如最大窗口值、是否使用窗口扩大选项的时间戳选项以及服务质量等）。
      （3）能够对运输实体资源（如缓存大小、连接表中的项目等）进行分配。
      TCP连接的建立采用客户服务器方式。主动发起连接建立的应用进程叫做客户（client），而被动等待连接建立的应用进程叫做服务器（Server）。
      5.9.1 TCP的连接建立
      图画出了TCP的建立连接的过程。假定主机A运行的是TCP客户程序，而B运行TCP服务器程序。最初两端的TCP进程都处于CLOSED（关闭）状态。图中在主机下面的方框分别是TCP进程所处的状态。请注意，A主动打开连接，而B被动打开连接。
      B的TCP服务器进程先创建传输控制块TCB，准备接受客户进程的连接请求。然后服务器进程就处于LISTEN（收听）状态，等待客户的连接请求。如有，即作出响应。
      A的TCP客户进程也是首先创建传输控制模块TCB，然后向B发出连接请求报文段，这是首部中的同步位SYN=1，同时选择一个初始序号seq=x。TCP规定，SYN报文段（即SYN=1的报文段）不能携带数据，但要消耗一个序号。这是TCP客户进程进入SYN-SENT（同步已发送）状态。
      B收到连接请求报文段后，如同意建立连接，则向A发送确认。在确认报文段中应把SYN位和ACK位都置1，确认号是ack=x+1，同时也为自己选择一个初始序号seq=y。请注意，这个报文段也不能携带数据，但同样要消耗掉一个序号。这是TCP服务器进程进入SYN-RCVD（同步收到）状态。
      TCP客户进程收到B的确认后，还要向B给出确认。确认报文段的ACK置1，确认号ack=y+1，而自己的序号seq=x+1.TCP的标准规定，ACK报文段可以携带数据。但如果不携带数据则不消耗序号，在这种情况下，下一个数据报文段的序号仍是seq=x+1。这时，TCP连接已经建立，A进入ESTABLISHED（已建立连接）状态。
      当B收到A的确认后，也进入ESTABLISHED状态。
      上面给出的练级建立过程叫做三次握手（three-way handhake），或三次联络。
      为什么A还要发送一次确认呢？这主要是为了防止已失效的连接请求报文段突然有传送到了B，因而产生错误。
      所谓“已失效的连接请求报文段”时这样产生的。考虑一种正常情况。A发出连接请求，但因连接请求报文丢失而未收到确认。于是A再重传一次连接请求。后来收到了确认，建立了连接，数据传输完毕后，就是放了连接。A共发送了两个连接请求报文段，其中第一个丢失，第二个到达了B。没有“已失效的连接请求报文段”。
      现假定出现一种异常情况，即A发出的第一个连接请求报文段并没有丢失，而是在某些网络结点长时间滞留了，以致延误到连接释放以后的某个时间才到达B。本来这是一个早已失效的报文段。但B收到此失效的连接请求报文段后，就误认为是A又发出一次新的连接请求。于是就向A发出确认报文段，同意建立连接。假定不采用三次握手，那么只要B发出确认，新的连接就建立了。
      由于现在A并没有发出建立连接的请求，因此不会理睬B的确认，也不会向B发送数据。但B却以为新的运输连接已经建立了，并一直等待A发来数据。B的许多资源就这样白白浪费了。采用三次握手的办法可以防止上述现象的发生。例如在刚才的情况下，A不会向B的确认发出确认。B由于收不到确认，就知道A并没有建立连接。
      5.9.2 TCP的连接释放
      TCP连接释放过程比较复杂，我们仍结合双方状态的改变来阐明连接释放的过程。
      数据传输结束后，通信的双方都可以释放连接。现在A和B都处于ESTABLISHED状态。A的应用进程先向其TCP发出连接释放报文段，并停止再发送数据，主动关闭TCP连接。A把连接释放报文段首部的FIN置1，其序号seq=u，它等于前面已传送过的数据的最后一个字节的序号加1.这是A进入FIN-WAIT-1（终止等待1）状态，等待B的确认。请注意，TCP规定，FIN报文段即使不携带数据，它也消耗掉一个序号。
      B收到连接释放报文段后发出确认，确认号是ack=u+1，而这个报文段自己的序号是v，等于B前面已传送过的数据的最后一个字节的序号加1.然后B就进入CLOSE-WAIT（关闭等待）状态。TCP服务器进程这是应通知高层应用进程，因而从A到B这个方向的连接就释放了，这是的TCP连接处于半关闭（half-close）状态，即A已经没有数据要发送了，但B若发送数据，A仍要接收。也就是说，从B到A这个方向的连接并未关闭。这个状态可能会持续一些时间。
      A收到来自B的确认后，就进入FIN-WAIT-2（终止等待2）状态，等待B发出的连接释放报文段。
      若B已经没有要向A发送的数据，其应用进程就通知TCP释放连接。这是B发出的连接释放报文段碧玺使FIN=1.先假定B的序号为w（在半关闭状态B可能又发送了一些数据）。B还必须重复上次已发送过的确认号ack=u+1.这是B就进入LAST-ACK（最后确认）状态，等待A的确认。
      A在收到B的连接释放报文段后，必须对此发出确认。在确认报文段中把ACK置1，确认号ack=w+1，而自己的序号是seq=u+1（根据TCP标准，前面发送过的FIN报文段要消耗一个序号）。然后进入到TIME-WAIT（时间等待）状态。请注意，现在TCP连接还没有释放掉。必须经过时间等待计时器（TIME-WAIT timer）设置的时间2MSL后，A才进入到CLOSED状态。时间MSL叫做最长报文段寿命（Maximum Segment Lifetime），RFC 793建议设为2分钟。但这完全是从工程上来考虑，对于现在的网络，MSL=2分钟可能太长了一些。因此TCP允许不同的实现可根据具体情况使用更小的MSL值。因此，从A进入到TIME-WAIT状态后，要经过4分钟才能进入到CLOSED状态，才能开始建立下一个新的连接。当A撤销响应的传输控制块TCB后，就结束了这次的TCP连接。
      为什么A在TIME-WAIT状态必须等待2MSL的时间呢？这有两个理由。
      第一，为了保证A发送的最后一个ACK报文段能够到达B。这个ACK报文段有可能丢失，因为使处在LAST-ACK状态的B收不到对已发送的FIN+ACK报文段的确认。B会超时重传这个FIN+ACK报文段，而A就能在2MSL时间内收到这个重传的FIN+ACK报文段。接着A重传一次确认，重新启动2MSL计时器。最后，A和B都正常进入到CLOSED状态。如果A在TIME-WAIT状态不等待一段时间，而是在发送完ACK报文段后立即释放连接，那么就无法收到B重传的FIN+ACK报文段，因而也不会再发送一次确认报文段。这样，B就无法按照正常步骤进入CLOSED状态。
      第二，防止上一节提到的“已失效的连接请求报文段”出现在本连接中。A在发送完最后一个ACK报文段后，再经过时间2MSL，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样就可以使下一个新的连接中不会出现这种旧的连接请求报文段。
      B只要收到了A发出的确认，就进入CLOSED状态。同样，B在撤销相应的传输控制块TCB后，就结束了这次的TCP连接。我们注意到，B结束TCP连接的时间要比A早一些。
      上述的TCP连接释放过程是四次握手，但也可以看成是两个二次握手。
      除时间等待计时器外，TCP还设有一个保活计时器（keepalive timer）。设想有这样的情况：客户已主动与服务器建立了TCP连接。但后来客户端的主机突然出故障。显然，服务器以后就不能再收到客户发来的数据。因此，应当有措施使服务器不要再白白等待下午。这就是使用保活计时器。服务器每收到一些客户的数据，就重新设置保活计时器，时间的设置通产是两小时。若两小时没有收到客户的数据，服务器就发送一个探测报文段，以后则每隔75分钟发送一次。若一连发送10个探测报文段后仍无客户的响应，服务器就认为客户端出了故障，接着就关闭这个连接。
      5.9.3 TCP的有限状态机
      为了更清晰地看出TCP连接的各种状态之间的关系，图给出了TCP的有限状态机。图中每一个方框即TCP可能具有的状态。每个方框中的大写英文字符串是TCP标准所使用的TCP连接状态名。状态之间用箭头表示可能发生的状态变迁。箭头旁边的字，表明引起这种变迁的原因，或表明发生状态变迁后又出现什么动作。请注意图中有三种不同的箭头。粗实线箭头表示对客户进程的正常变迁。粗虚线箭头表示对服务器进程的正常变迁。另一种细线箭头表示异常变迁。
          TCP的有限状态机
      我们可以把图和前面的图对照起来看。在图中左边客户进程从上到下的状态变迁，就是图中粗实线箭头的状态变迁。而在图右边服务器进程从上到下的状态变迁，就是图中粗虚线箭头所指的状态变迁。
      还有一些状态变迁，例如连接建立过程中的从LISTEN到SYN-SENT和从SYN-SENT到SYN-RCVD。读者可分析在什么情况下会出现这样的变迁。





习题
5-01    试说明运输层在协议栈中的地位和作用。运势层的通信和网络层的通信有什么重要的区别？为什么运输层是必不可少的？
5-02    网络层提供数据报或虚电路服务对上面的运输层有何影响？
5-03    当应用程序使用面向连接的TCP和无连接的IP时，这种传输是面向连接的还是无连接的？
5-04    试用画图解释运输层的复用。画图说明许多和运输用户复用到一条运输连接上，而这条运输连接又复用到IP数据报上。
5-05    试举例说明有些应用程序愿意采用不可靠的UDP，而不愿采用可靠的TCP。
5-06    接收方收到有差错的UDP用户数据报时如何处理？
5-07    如果应用程序愿意使用UDP完成可靠传输，这可能吗？请说明理由。
5-08    为什么说UDP是面向报文的，而TCP是面向字节流的？
5-09    端口的作用是什么？为什么端口号要划分为三种？
5-10    试说明运输层中伪首部的作用。
5-11    某个应用进程使用运输层的用户数据报UDP，然后继续向下交给IP层后，又封装成IP数据报。既然都是数据报，是否可以跳过UDP而直接交给IP层？哪些功能UDP提供了但IP没有提供？
5-12    一个应用程序用UDP，到了IP层把数据报再划分为4个数据报片发送出去。结果前两个数据报片丢失，后两个到达目的站。过了一段时间应用程序重传UDP，而IP层仍然划分为4个数据报片来传送。结果这次前两个到达目的站而后两个丢失。试问：在目的站能否将这两次传输的4个数据报片组装成为完整的数据报》假定目的站第一次收到的后两个数据报片仍然保存在目的站的缓存中。
5-13    一个UDP用户数据报的数据字段为8192字节。在链路层要使用以太网来传送。试问应当划分为几个IP数据报片？说明每一个IP数据报片的数据字段长度和片偏移字段的值。
5-14    一UDP用户数据报的首部的十六进制表示是：06 32 00 45 00 1c e2 17。试求源端口、目的端口、用户数据报的总长度、数据部分长度。这个用户数据报是从客户端发送给服务器还是从服务器发送给客户？使用UDP的这个服务器程序是什么？
5-15    使用TCP对实时话音数据的传输有没有什么问题？使用UDP在传送数据文件时会有什么问题？
5-16    在停止等待协议中如果不使用编号是否可行？为什么？
5-17    在停止等待协议中，如果收到重复的报文段时不予理睬（即悄悄地丢弃而其他什么也不错）是否可行？试举出具体例子说明理由。
5-18    假定在运输层使用停止等待协议。发送方在发送报文段M0后在设定的时间内未收到确认，于是重传M0，但M0又迟迟不能到达接收方。不久，发送方收到了迟到的对M0的确认，于是发送下一个报文段M1，不久就收到了对M1的确认。接着发送方发送新的报文段M0，但这个新的M0在传送过程中丢失了。正巧，一开始就滞留在网络中的M0现在叨叨接收方。接收方无法分辨M0是旧的。于是收下M0，并发送确认。显然，接收方后来收到的M0是重复的，协议失败了。试画出类似于图所示的双方交换报文段的过程。
5-19    试证明：当用n比特进行分组的编号时，若接收窗口等于1（即只能按需接收分组），则仅在发送窗口不超过2^n-1时，连续ARQ协议才能正确运行。窗口单位是分组。
5-20    在连续ARQ协议中，若发送窗口等于7，则发送端再开始可连续发送7个分组。因此，在每一分组发出后，都要置一个超时计时器。现在计算机里只有一个硬时钟。设这7个分组发出的时间分别为t0,t1,...,t6，且tout都一样大。试问如何实现这7个超时计时器（这叫软时钟法）？
5-21    假定使用连续ARQ协议，发送窗口大小事3，而序号范围是【0，15】，而传输媒体保证在接收方能够按需收到分组。在某一时刻，在接收方，下一个期望收到的序号是5.试问：（1）在发送方的发送窗口中可能有出现的序号组合有哪些种？（2）接收方已经发送出的、但在网络中（即还未到达发送方）的确认分组可能有哪些？说明这些确认分组是用来确认哪些序号的分组。
5-22    主机A向主机B发送一个很长的文件，其长度为L字节。假定TCP使用的MSS为1460字节。（1）在YCP的序号补充度使用的条件下，L的最大值是多少？（2）假定使用上面计算出的文件长度，而运输层、网络层和数据链路层所用的首部开销共66字节，链路的数据率为10Mb/s，是求这个文件所需的最短发送时间。
5-23    主机A向主机B连续发送了两个TCP报文段，其序号分别是70和100.试问：（1）第一个报文段懈怠了多少字节的数据？（2）主机B收到第一个报文段后发回的确认中的确认号应当是多少？（3）如果B收到第二个报文段后发回的确认中的确认号是180，试问A发送的第二个报文段中的数据有多少字节？（4）如果A发送的第一个报文段丢失了，但第二个报文段到达了B。B在第二个报文段到达后向A发送确认。试问这个确认号应为多少？
5-24    一个TCP连接下面使用256kb/s的链路，其端到端时延为128ms。经测试，发现吞吐量只有120kb/s。试问发送窗口W是多少？（提示：可以有两种答案，取决于接收等发出确认的时机）。
5-25    为什么在TCP首部中的要把TCP的端口号放入最开始的4个字节？
5-26    为什么在TCP首部中有一个首部长度字段，而UDP的首部中就没有这个字段？
5-27    一个TCP报文段的数据部分最多为多少个字节？为什么？如果用户要传送的数据的字节长度超过TCP报文段中的序号字段可能编出的最大序号，问还能否用TCP来传送？
5-28    主机A向主机B发送TCP报文段，首部中的源端口是m而目的端口是n。当B向A发送回信时，其TCP报文段的首部中的源端口和目的端口分别是什么？
5-29    在使用TCP传送数据时，如果有一个确认报文段丢失了，也不一定会引起与该确认报文段对应的数据的重传。试说明理由。
5-30    设TCP使用的最大窗口为65535字节，而传输信道不产生差错，带宽也不受限制。若报文段的平均往返时间为20ms，问所能得到的最大吞量是多少？
5-31    通信信道带宽为1Gb/s，端到端传播时延为10ms。TCP的发送窗口为65535字节。试问：可能达到的最大吞吐量时多少？信道的利用率是多少？
5-32    什么是Karn算法？在TCP的重传机制中，若不采用Karn算法，而是在收到确认时都认为是对重传报文段的确认，那么由此得出的往返时间样本和重传时间都会偏小。试问：重传时间最后会减小到什么程度？
5-33    假定TCP在开始建立连接时，发送方设定超时重传时间RTO=6秒。（1）当发送方收到对方的连接确认报文段时，测量出RTT样本值为1.5秒。试计算现在的RTO的值。（2）当发送方发送数据报文段并收到确认时，测量出RTT样本值为2.5秒。试计算现在的RTO值。
5-34    已知第一次测得TCP的往返时间RTT是30ms。接着收到了三个确认报文段，用它们测量出的往返时间样本RTT分别是：26ms，32ms和24ms。设a=0.1。试计算每一次的新的加权平均往返时间值RTTs。讨论所得出的结果。
5-35    试计算一个包括五段链路的运输连接的单程端到端时延。五段链路程中有两段是卫星链路，有三段是广域网链路。每条卫星链路又由上行链路和下行链路两部分组成。可以取这两部分的传播时延之和为250ms。每一个广域网的范围为1500km，其传播时延可按150000kn/s来计算。各数据链路速率为48kb/s，帧长为960位。
5-36    重复5-35题，但假定其中的一个陆地上的广域网的传输时延为150ms。
5-37    在TCP的拥塞控制中，什么是慢开始、拥塞避免、快重传和快恢复算法？这里每一种算法各起什么作用？“乘法减小”和“加法增大”各用在什么情况下？
5-38    设TCP的ssthresh的初始值为8（单位为报文段）。当拥塞窗口上升到12时网络发生了超时，TCP使用慢开始和拥塞避免。试分别求第1轮次到第15轮次传输的各拥塞窗口大小。你能说明拥塞窗口每一次变化的原因吗？
5-39    TCP的拥塞窗口cwnd大小与传输轮次n的关系如下所示：
            cwnd|1 |2 |4 |8 |16|32|33|34|35|36|37|38|39
               n|1 |2 |3 |4 |5 |6 |7 |8 |9 |10|11|12|13
            ----------------------------------------
            cwnd|40|41|42|21|22|23|24|25|26|1 |2 |4 |8
               n|14|15|16|17|18|19|20|21|22|23|24|25|26
            （1）试画出如图5-25所示的拥塞窗口与传输轮次的关系曲线。
            （2）指明TCP工作在慢开始阶段的时间间隔。
            （3）指明TCP工作在拥塞避免阶段的时间间隔。
            （4）在第16轮次和第22轮次之后发送方是通过收到三个重复的确认还是通过超时检测丢失了报文段？
            （5）在第1轮次、第18轮次和第24轮次发送时，门限ssthresh分别被设置为多大？
            （6）在第几轮次发送出第70个报文段？
            （7）假定在第26轮次之后收到了三个重复的确认，因而检测出了报文段的丢失，那么拥塞窗口cwnd和门限ssthresh应设置为多大？
5-40    TCP在进行流量控制时是以分组的丢失作为产生拥塞的标志。有没有不是因拥塞而引起的分组丢失的情况？如有，请举出三种情况。
5-41    用TCP传送512字节的数据。设窗口为100字节，而TCP报文段每次也是传送100字节的数据。再设发送方和接收方的起始序号分别选为100和200，试画出类似于图5-31的工作示意图。从连接建立阶段到连接释放都要画上。
5-42    在图5-32中所示的连接释放过程中，在ESTABLISHED状态下，服务器进程能否先不发送ack=x+1的确认？（因为后面要发送的连接释放报文段中仍有ack=x+1）这一信息
5-43    在图5-33中，在什么情况下会发生从状态SYN-SENT到状态SYN-RCVD的变迁？
5-44    试以具体例子说明为什么一个运输连接可以有多种方式释放。可以设两个互相通信的用户分贝连接在网络的两结点上。
5-45    解释为什么突然释放运输连接就可能会丢失用户数据，而使用TCP的连接释放方法就可保证不丢失数据。
5-46    试用具体例子说明为什么在运输连接建立时要使用三次握手。说明如不这样做可能会出现什么情况。
5-47    一客户向服务器请求建立TCP连接。客户在TCP连接建立的三次握手中的最后一个报文段中捎带上一些数据，请求服务器发送一个长度为L字节的文件。假定：
            （1）客户和服务器之间的数据传送速率是R字节/秒，客户与服务器之间的往返时间是RTT（固定值）。
            （2）服务器发送的TCP报文段的长度都是M字节，而发送窗口大小是nM字节。
            （3）所有传送的报文段都不会出现差错（无重传），客户收到服务器发来的报文段后就即使发送确认。
            （4）所有的协议首部开销都可忽略，所有确认白文段和连接建立阶段的报文段的长度都可忽略（即忽略这些报文段的发送时间）。
            试证明，从客户开始发起连接建立到接受服务器发送的整个文件所需的时间T是：
                T=2RTT+L/R        当nM>R（RTT）+M
            或   T=2RTT+L/R+（K-1）[M/R+RTT-nM/R]        当nM<R（RTT）+M
            其中，K=[L/nM]，符号[x]表示若x不是整数，则把x的整数部分加1.
            （提示：求证的第一个等式发生在发送窗口较大的情况，可以连续把文件发送完。求证的第二个等式发生在发送窗口较小的情况，发送几个报文段后就必须停顿下来，等收到确认后再继续发送。建议先画出双方交互的时间图，然后再进行推导）。
