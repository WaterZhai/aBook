第3章   数据链路层
    数据链路层属于计算机网络的低层。数据链路层使用的信道主要有以下两种类型：
    1）点对点信道。这种信道使用一对一的点对点通信方式。
    2）广播信道。这种信道使用一对多的广播通信方式，因此过程比较复杂。广播信道上连接的主机很多，因此必须使用专用的共享信道协议来协调这些主机的数据发送。
    在这一章，我们首先介绍点对点信道和在这种信道上最常用 的点对点协议PPP。然后再用较大的篇幅讨论共享信道的局域网和有关协议。
    下面看一下两个主机通过互联网进行通信时数据链路层所处的地位。
        主机H1----路由器R1----路由器R2----路由器R3----主机H2

        ---------

        H1                                      R1                                  R2                                    R3                                     H2
        应用层--运输层--网络层--链路层--物理层-->物理层--链路层--网络层--链路层--物理层-->物理层--链路层--网络层--链路层--物理层-->物理层--链路层--网络层--链路层--物理层-->物理层--链路层--网络层--运输层--应用层

    主机H1通过电话线上网，中间经过三个路由器（R1，R2和R3）连接到远程主机H2。所经过的网络可以是多种的。如电话网、局域网和广域网。当主机H1向H2发送数据时，从协议的层次上看。主机H1和H2都有完整的五层协议栈，但路由器在转发分组时使用的协议栈只有下面的三层。数据进入路由器后要先从物理层上到网络层，在转发表中找到下一跳的地址后，再下到物理层转发出去。因此，数据从主机H1传送到主机H2需要在路径中的各结点的协议栈向上和向下流动多次。

        H1的链路层-->R1的链路层-->R2的链路层-->R3的链路层--H2的链路层

    然而当我们专门研究数据链路层的问题时，在许多情况下我们可以只关心在协议栈中水平方向的各数据链路层。于是，当主机H1向主机H2发送数据时，我们可以想象数据就是在数据链路层从左向右沿水平方向传送。
    从数据链路层来看，H1到H2的通信可以看成是由四段不同的链路层通信组成，即H1-->R1，R1-->R2，R2-->R3，R3-->H2。这四段不同的链路层可能采用不同的数据链路层协议。
3.1实用点对点信道的数据链路层
    本节讨论使用点对点信道的数据链路层的一些基本问题。其中的某些概念对广播信道也是适用的。
    3.1.1数据链路和帧
        我们在这里要明确一下，“链路”和“数据链路”并不是一回事。
        所谓链路（link）就是从一个结点到相邻结点的一段物理线路，而中间没有任何其他的交换结点。在进行数据通信时，两个计算机之间的通信路径往往要经过许多这样的链路。可见链路只是一条路径的组成部分。
        数据链路（data link）则是另一个概念。这是因为当需要在一条线路上传送数据时，除了必须有一条物理线路外，还必须有一些必要的通信协议来控制这些数据的传输（这将在后面几节讨论）。若把视线这些协议的硬件和软件加到链路上，就构成了数据链路。现在最常用的方法是使用网络适配器（如拨号上网使用拨号适配器，以及通过以太网上网使用局域网适配器）来实现这些协议的硬件和软件。一般的适配器都包括了数据链路层和物理层这两层的功能。
        也有人采用另外的术语。这就是把链路分为物理链路和逻辑链路。物理链路就是上面所说的链路，而逻辑链路就是上面的数据链路，是物理链路加上必要的通信协议。
        早期的数据通信协议曾叫做通信规程（procedure）。因此在数据链路层，规程和协议是同义语。
        下面再介绍点对点信道的数据链路层的协议数据单元--帧。
        数据链路层把网络层交下来的数据构成帧发送到链路上，以及把接收到的帧中的数据取出并上交给网络层。在因特网中，网络层协议数据单元就是IP数据报（或简称为数据报、分组或包）。
        为了把主要精力放在点对点信道的数据链路层协议上，可以采用三层模型。在这种三层模型中，不管在哪一段链路上的通信（主机和路由器之间或两个路由器之间），我们都看成是结点和结点的通信，而每个结点只有下三层--网络层、数据链路层和物理层。
            结点A                                           结点B
            网络层：IP数据报（↓装入）                        网络层：IP数据报
            数据链路层：帧                                  数据链路层：帧（↑取出）
            物理层--------------------链路------------------物理层
            ------------
            结点A                                              结点B
            数据链路层：帧（发送）------------链路-------------->数据链路层：帧(接收)

            点对点信道的数据链路层在进行通信时的主要步骤如下：
            1）结点A的数据链路层把网络层交下来的IP数据报添加首部和尾部封装成帧。
            2）结点B把封装好的帧发送给结点B的数据链路层
            3）若结点B的数据链路层收到的帧无差错，则从收到的帧中提取出IP数据报上交给上面的网络层，否则丢弃这个帧。
        数据链路层不必考虑物理层如何实现比特传输的细节。我们甚至还可以更简单地设想好像是沿着两个数据链路层之间的水平方向把帧直接发送到对方。
    3.1.2三个基本问题
        数据链路层协议有许多种，但有三个基本问题则是共同的。这三个基本问题是：封装成帧、透明传输和差错检测。下面分别讨论着三个基本问题。
        1.封装成帧
            封装成帧（framing）就是在一段数据的前后分别添加首部和尾部，这样就构成了一个帧。接收端在收到物理层上交的比特流后，就能根据首部和尾部的标记，从收到的比特流中识别帧的开始和结束。我们知道，分组交换的一个重要概念就是：所有在因特网上传送的数据都是以分组（即IP数据报）为传送单位。网络层的IP数据报传送到数据链路层就成为帧的数据部分。在帧的数据部分的前面和后面分别添加上首部和尾部，构成了一个完整的帧。因此，帧长等于数据部分的长度加上帧首部和帧尾部的长度，而首部和尾部的一个重要作用就是进行帧定界（即确定帧的界限）。此外，首部和尾部还包括许多必要的控制信息。在发送帧时，是从帧首部开始发送。各种数据链路层协议都要对帧首部和帧尾部的格式有明确的规定。显然，为了提高帧的传输效率，应当使帧的数据部分长度尽可能地大于首部和尾部的长度。但是，每一种链路层协议都规定了帧的数据部分的长度上限--最大传送单元MTU（MaximumTransferUnit）。
            当数据是由可打印的ASCII码组成的文本文件时，帧定界可以使用特殊的帧定界符。我们知道，ASCII码是7位编码，一共可组合成128个不同的ASCII码，其中可打印的有95个，而不可打印的控制字符有33个。
                帧开始符                                              帧结束符
                |SOH|           装在帧中的数据部分                     |EOT|
            控制字符SOH（StartOfHeader）放在一帧的最前面，表示帧的首部开始。另一个控制字符EOT（EndOfTransmission）表示帧的结束。请注意，SOH和 EOT都是控制字符的名称。它们的十六进制编码分别是01（二进制是00000001）和04（二进制是00000100）。SOH（或EOT）并不是S，O，H（或E，O，T）三个字符。
            当数据在传输中出现差错时，帧定界符的作用更加明显。假定发送端在尚未发送完一个帧时突然出故障，中断了发送。但随后很快又恢复正常，于是重新从开头开始发送刚才未发送完的帧。由于使用了帧定界符，在接收端就知道前面收到的数据是个不完整的帧（只有首部开始符SOH而没有传输结束符EOT），必须丢弃。而后面收到的数据有明确的帧定界符（SOH和EOT），因此这是一个完整的帧，应当收下。
        2.透明传输
            由于帧的开始和结束的标记是使用专门指明的控制字符，因此，所传输的数据中的任何8比特的组合一定不允许和用作帧定界的控制字符和比特编码一样。否则就会出现帧定界的错误。
            当传送的帧是用文本文件组成的帧时（文本文件中的字符都是从键盘上输入的），其数据部分显然不会出现想SOH或EOT这样的帧定界控制字符。可见不管从键盘上输入什么字符都可以放在这样的帧中传输过去，因此这样的传输就是透明传输。
            但当数据部分是非ASCII码的文本文件时（如二进制代码的计算机程序的计算机程序或图像等），情况就不同了。如果数据中的某个字节的二进制代码恰好和SOH或EOT这种控制字符一样，数据链路层就会错误地“找到帧的边界”，把部分帧收下（误认为是个完整的帧），而把剩下的那部分数据丢弃（这部分找不到帧定界控制字符SOH）。
            为了解决透明传输问题，就必须设法使数据中可能出现的控制字符“SOH”和“EOT”在接收端不被解释为控制字符。具体的方法是：发送端的数据链路层在数据中出现控制字符“SOH”或“EOT”的前面插入一个转义字符“ESC”（其十六进制编码是1B）。而在接收端的数据链路层在将数据送往网络层之间删除这个插入的转义字符。这种方法称为字节填充（byte stuffing）或字符填充（character stuffing）。如果转义字符也出现数据当中，那么结局方法仍然是在转义字符的前面插入一个转义字符。因此当接收端收到连续的两个转义字符时，就删除其中前面的一个。
        3.错检测
            现实的通信链路都不会是理想的。这就是说，比特在传输过程中可能会产生差错：1可能会变成0，而0也可能变成1.这就叫做比特差错。比特差错是传输差错中的一种。本小节所说的“差错”，如无特殊说明，就是指“比特差错”。在一段时间内，传输错误的比特占所传输比特总数的比率肠胃误码率BER（BitErrorRate）。例如，误码率为10^-10时，表示平均每传送10^10个比特就会出现的差错。误码率与信噪比有很大的关系。如果设法提高信噪比，就可以使误码率减小。实际的通信链路并非理想的，它不可能使误码率下降到零。因此为了保证数据传输的可靠性，在计算机网络传输数据时，必须采用各种差错检测措施。目前在数据链路层广泛使用了循环冗余检测CRC（Cyclic Redundancy Check）的检错技术。
            下面我们通过一个简单的例子来说明循环冗余检验的原理。
                在发送端，先把数据划分为组，假定每组k个比特。现假定待发送的数据M=101001（k=6）。CRC运算就是在数据M的后面添加供差错检测用的n为冗余码，然后构成一个帧发送出去，一共发送（k+n）位。在所要发送的数据后面增加n位冗余码，虽然增大了数据传输的开销，但却可以进行差错检测。当传输可能出现差错时，付出这种代价往往是很值得的。
                这n位冗余码可用以下方法得出。用二进制的模2运算进行2^n乘M的运算，这相当于在M后面添加n个0。得到的（k+n）位的数除以收发双方事先商定的长度为（n+1）位的除数P，得出商是Q而余数是R（n位，比P少一位）。关于除数P下面还要介绍。在例子中，M=101001（即k=6）。假定除数P=1101（即n=3）。经模2除法运算后的结果是：商Q=110101（这个商并没有什么用处），而余数R=001.这个余数R就作为冗余码拼接在数据M的后面发送出去。这种为了进行检错而添加的冗余码常称为帧检验序列FCS（FrameCHecjSequence）。因此加上FCS后发送的帧是101001001（即2^nM+FCS），共有（k+n）位。
                顺片说一下，循环冗余检验CRC和帧检验序列FCS并不是同一个概念。CRC是一种检错方法，而FCS是添加在数据后面的冗余码，在检错方法上可以选用CRC，也可不选用CRC。
                在接收端把接收到的数据以帧为单位进行CRC检验：把收到的每一个帧都除以同样的除数P（模2运算），然后检查得到的余数R。
                如果在传输过程中无差错，那么经过CRC检验后得出的余数R肯定是0。
                但如果出现误码，那么袁术R仍然等于零的概率非常非常小的。
                总之，在接收端对收到的每一帧经过CRC检验后，
                1）若得出的余数R=0，则判定这个帧没有差错，就接受（accept）。
                2）若余数R！=0，则判定这个帧有差错（但无法确定究竟是哪一位或哪几位出现了差错），就丢弃。
                一种较方便的方法是用多项式来表示循环冗余检验过程。在上面的例子中，用多项式P（X）=X^3+X^2+1表示上面的除数P=1101（最高位对应于X^3，最低位对应于X^0）。多项式P（X）称为生成多项式。现在广泛使用的生成多项式P（X）有以下几种：
                    CRC-16=X^16+X^15+X^2+1
                    CRC-CCITT=X^16+X^12+X^5+1
                    CRC-32=X^32+X^26+X^23+X^22+X^16+X^12+X^11+X^10+X^8+X^7+X^5+X^4+X^2+X+1
                在数据链路层，发送端帧检测序列FCS的生成和接收端的CRC检验都是用硬件完成的，处理很迅速，因此并不会延误数据的传输。
                从以上的讨论不难看出，如果我们在传送数据时不以帧为单位来传送，那么就无法加入冗余码以进行差错检验。因此，如果要在数据链路层进行差错检验，就必须把数据划分为帧，每一帧都加上冗余码，一帧接一帧地传送，然后在接收方逐渐进行差错检验。
                最后再强调一下，在数据链路层若仅仅使用循环冗余检验CRC差错检测技术，则只能做到对帧的无差错接受。即“凡是接收端数据链路层接受的帧，我们都能以非常接近于1的概率认为这些帧在传输过程中没有产生差错”。接收端丢弃的帧虽然曾收到了，但最终还是因为有差错被丢弃，即没有被接受。以上所述的可以近似地表述为（通常都是这样认为）：“凡是接收端数据链路层接受的帧均无差错”。
                请注意，我们现在并没有要求数据链路层向网络层提供“可靠传输”的服务。所谓“可靠传输”就是：数据链路层的发送端发送什么，在接收端就收到什么。传输差错可分为两大类：一类就是前面所说的最基本的比特差错，而另一类传输差错则更复杂些，这就是收到的帧并没有出现比特差错，但却出现了帧丢失、镇重复或帧失序。例如。发送方连续传送三个帧【#1】-【#2】-【#3】。假定在接收端收到的却有可能出现下面的情况：
                    帧丢失：收到【#1】-【#3】（丢失【#2】）
                    帧重复：收到【#1】-【#2】-【#2】-【#3】（收到两个【#2】）。
                    帧失序：收到【#1】-【#3】-【#2】
                以上三种情况都属于“出现传输差错”，但都不是这些帧里有“比特差错”。帧丢失很容易理解。但出现帧重复和帧失序的情况则较为复杂，对这些问题我们现在不展开讨论。在学完第5章的5.4节后，我们就会知道什么情况下接收端可能会出现帧重复或帧失序。
                总之，我们应当明确，“无比特差错”与“无传输差错”并不是同样的概念。在数据链路层使用CRC检验，能够实现无比特差错的传输，但这还不是可靠传输。
                我们知道，OSI的观点是必须把数据链路层做成是可靠传输的。因此在CRC检错的基础上，层架了帧编号、确认和重传机制。收到正确的帧就要向发送确认。发送端在一定的期限内若没有收到对方的确认，就认为出现了差错，因而就进行重传，知道收到对方的确认为止。这种方法在历史上曾经起到很好的作用。但现在的通信线路的质量已经大大提高了，有通信链路质量不好引起的差错的概率已经大大降低。因此，因特网广泛使用的数据链路层协议都不使用确认和重传机制，即不要求数据链路层向上提供可靠传输的服务（因为这要付出的代价太高，不合算）。如果在数据链路层传输数据时出现了差错并且需要进行改正，那么改正差错的任务就由上层协议（例如，运输层的TCP协议）来完成。实践证明，这样做可以提高通信的效率。
                本教材的前几个版本中曾采用以前OSI的思路，在数据链路层讲述可靠传输的原理（例如停止等待协议和滑动窗口机制）。但由于现在实际的有线网络的数据链路层已很少采用可靠传输，因此我们就把确认和重传机制改在后面第5章运输层TCP中讨论。这样作比较符合因特网现在的实际情况。
3.2点对点协议PPP
    在通信线路质量较差的年代，在数据链路层使用可靠传输协议曾经是一种好办法。因此，能实现可靠传输的高级数据链路控制HDLC（High-level Data Link Control）就成为当时比较流行的数据链路协议。但现在HDLC已很少使用了。对于点对点的链路，简单得多的点对点协议PPP（Point-to-Point Protocol）则是目前使用得最广泛的数据链路层。
    3.2.1PPP协议的特点
        我们知道，因特网用户通常都要连接到某个ISP才能接入到因特网。PPP协议就是用户计算机和ISP进行通信时所使用的数据链路层协议。
        PPP协议是IETF在1992年制定的。经过1993年和1994年的修订，现在的PPP协议在1994年就已成为因特网的正式标准。
        1.PPP协议应满足的需求
            IETF认为，在设计PPP协议时必须考虑以下多方面的需求：
                1）简单    IETF在设计因特网体系结构时把其中最复杂的部分放在TCP协议中，而网际协议IP则相对比较简单，它提供的是不可靠的数据报服务。在这种情况下，数据链路层没有必要提供比IP协议更多的功能。因此，对数据链路层的帧，不需要纠错，不需要序号，也不需要流量控制。当然，在误码率较高的无线链路上可能会需要更为复杂的链路层协议。因此IETF把“简单”作为首要的需求。
                          简单的设计还可使协议在实现时不容易出错，因而使得不同厂商对协议的不同实现的互操作性提高了。我们知道，协议标准化的一个主要目的就是提高协议的互操作性。
                          总之，这种数据链路层的协议非常简单：接收方每收到一个帧，就进行CRC检验，如CRC检验正确，就收下这个帧，反之，就丢弃这个帧，其他什么也不做。
                2）封装成帧      PPP协议必须规定特殊字符作为帧定界符（即标志一个帧的开始和结束的字符），以便使接收端从收到的比特流中能准确地找出帧的开始和结束的位置。
                3）透明性   PPP协议必须保证数据传输的透明性。这就是说，如果数据中碰巧出现了和帧定界符一样的比特组合时，就要采取有效措施来解决这个问题。
                4）多种网络层协议   PPP协议必须能够在在同一条物理链路上同时支持多种网络层协议（如IP和IPX等）的运行。当点对点链路所连接的是局域网或路由器时，PPP协议必须同时支持在链路所连接的局域网或路由器上运行的各种网络层协议。
                5）多种类型链路    除了要支持多种网络层的协议外，PPP还必须能够在多种类的链路上运行。例如，串行的（一次只发送一个比特）或并行的（一次并行地发送多个比特），同步的或异步的，低俗的或高速的，电的或光的，交换的（动态的）或非交换的（静态的）点对点链路。
                    这里特别要提到的是在1999年公布的在以太网上运行的PPP，即PPP over Ethernet，简称为PPPoE，这是PPP协议能够适应多种类型链路的一个典型例子。PPPoE是为宽带上网的主机使用的链路层协议。这个协议把PPP帧再封装在以太网帧中（当然还要增加一些能后识别各用户的功能）。宽带上网时由于数据传输速率较高，因此可以让多个连接在以太网上的用户共享一条道ISP的宽带链路。现在，即使是只有一个用户利用ADSL进行宽带上网（并不和其他人共享到ISP的宽带链路），也是使用PPPoE协议。
                6）差错检测（error detection）   PPP协议必须能够对接收端收到的帧进行检测，并立即丢弃有差错的帧。若在数据链路层不进行差错检测，那么已出现差错的无用帧就还要在网络中继续向前转发，因而会白白浪费许多的网络资源。
                7）检测连接状态    PPP协议必须具有一种机制能够及时（不超过几分钟）自动检测出链路是否处于正常工作状态。当出现故障的链路隔一段时间后又重新恢复正常工作时，就特别需要有有这种及时检测功能。
                8）最大传送单元    PPP协议必须对每一种类型的点对点链路设置最大传送单元MTU的标准默认值。这样做是为了促进各种实现之间的互操作性。如果高层协议发送的分组过长并超过MTU的数值，PPP就要丢弃这样的帧，并返回差错。需要强调的是，MTU是数据链路层的帧可以载荷的数据部分的最大长度，而不是帧的总长度。
                9）网络层地址协商   PPP协议必须提供一种机制使通信的两个网络层（例如，两个IP层）的实体能够通过协商知道或能够配置彼此的网络层地址。协商的算法应尽可能简单，并且能够在所有的情况下得出协商结果。这对拨号连接的链路特别重要，吟哦日仅仅在链路层建立了连接而不知道对方网络层地址时，则还不能够保证网络层能够传送分组。
                10）数据压缩协商   PPP协议必须提供一种方法来协商使用数据压缩算法。但PPP协议并不要求将数据压缩算法进行标准化。
        2.PPP协议不需要的功能
            在RFC1547中还明确了PPP协议不需要的功能：
                1）纠错（error correction）    在TCP/IP协议族中，可靠传输由运输层的TCP协议负责，而数据链路层的PPP协议只进行检错。这就是说，PPP协议是不可靠传输协议。
                2）流量控制    在TCP/IP协议族中，端到端的流量控制由TCP负责，因而链路级的PPP协议就不需要再重复进行流量控制。
                3）序号    PPP不是可靠传输协议，因此不需要使用帧的序号（许多过去曾经很流行的停止等待协议或连续ARQ协议都是用序号）。在噪声较大的环境下。如无线网络，则可以使用有序号的工作方式，这样就可以提供可靠传输服务。这种工作方式定义在RFC1663中，这里不再讨论。
                4）多点线路    PPP协议不支持多点线路（即一个主站轮流和链路上的多个从站进行通信），而只支持点对点的链路通信。
                5）半双工或单工链路    PPP协议只支持全双工链路。
        3.PPP协议的组成
            PPP协议有三个组成部分：
                1）一个将IP数据报封装到串行链路的方法。PPP既支持异步链路（无奇偶检验的8比特数据），也支持面向比特的同步链路。IP数据报在PPP帧中就是其信息部分。这个信息部分的长度受最大传送单元MTU的限制。
                2）一个用来建立、配置和测试数据链路连接的链路控制协议LCP（Link Control Protocol）。通信的双方可协商一些选项。在RFC1661中定义了11种类型的LCP分组。
                3）一套网络控制协议NCP（NetworkControlProtocol），其中的每一个协议支持不同的网络层协议，如IP、OSI的网络层、DECnet，以及AppleTalk等。
    3.2.2PPP协议的帧格式
        1.字段的意义
            PPP帧的首部和尾部分别为四个字段和两个字段。
            首部的第一个子弹和尾部的第二个字段都是标志字段F（Flag），规定为0x7E（符号“0x”表示它后面的字符是用十六进制表示的。十六进制的7E的二进制表示是01111110）。标志字段表示一个帧的开始或结束。因此标志字段就是PPP帧的定界符。连续两帧之间只需要用一个标志字段。如果出现连续两个标志字段，就表示这是一个空帧，应当丢弃。
            首部中的地址字段A规定为0xFF（即11111111），控制字段C规定为0x03（即00000011）。最初曾考虑以后再对这两个字段的值进行其他定义，但至今也没有给出。可见这两个字段实际上并没有携带PPP帧的信息。
            PPP首部的第四个字段是2字节的协议字段。当协议字段为0x0021时，PPP协议的信息字段就是IP数据报。若为0xC021，则信息字段是PPP链路控制协议LCP的数据，而0x8021表示这是网络层的控制数据。
            信息字段的长度是可变的，不超过1500字节。
            尾部中的第一个字段（2字节）是使用CRC的帧检验序列FCS。
        2.字节填充
            当信息字段中出现和标志字段的比特（0x7E）组合时，就必须采取一些措施使这种形式上和标志字段一样的比特组合不出现在信息字段中。
            当PPP使用异步传输时，它把转义符定义为0x7D，并使用字节填充，RFC1662规定了如下所述的填充方法：
                1）把信息字段中出现的每一个0x7E字节转变为2字节序列（0x7D，0x5E）。
                2）若信息字段中出现一个0x7D的字节（即出现了和转义字符一样的比特组合），则把0x7D转变成为2字节序列（0x7D，0x5D）。
                3）若信息字段中出现ASCII码的控制字符（即数值小于0x20的字符），则在该字符前面要加入一个0x7D字节，同时该字符的编码加以改变。例如，出现0x03（在控制字符中是“传输结束”ETX）就要把它转变为2字节序列（0x7D，0x31）。
            由于在发送端进行了字节填充，因此在链路上传送的信息字节数就超过了原来的信息字节数。但接收端在收到数据后再进行与发送端字节填充相反的变换，就可以正确地恢复出原来的信息。
        3.零比特填充
            PPP协议用在SONET/SDH链路时，是使用同步传输（一连串的比特连续传送）而不是异步传输（逐个字符地传送）。在这种情况下，PPP协议采用零比特填充方法来实现透明传输。
            零比特填充的具体做法是：在发送端，先扫描整个信息字段（通常是用硬件实现，但也可用软件实现，还是会慢些）。只要发现有5个连续1，则立即填入一个0.因此经过这种零比特填充的数据，就可以保证在信息字段中不会出现6个连续1.接收端在收到一个帧时，先找到标志字段F以确定一个帧的边界，接着再用硬件对其中的比特流进行扫描。每当发现5个连续1时，就把这5个连续1后的一个0删除，以还原成原来的信息比特流。这样就保证了透明传输：在所传送的数据比特流中可以传送任意组合的比特流，而不会引起对帧边界的判断错误。
    3.2.3PPP协议的工作状态
        上一节我们通过PPP帧的格式讨论了PPP帧是怎样组成的。但PPP链路一开始是怎样被初始化的？当用户拨号接入ISP后，就建立了一条从用户PC机到ISP的物理连接。这时，用户PC机向ISP发送一系列的LCP分组（封装成多个PPP帧），以便建立LCP连接。这些分组及其响应选择了将要使用的一些PPP参数。接着还要进行网络层配置，NCP给新接入的用户PC机分配一个临时的IP地址。这样，用户PC机就成为因特网上的一个有IP地址的主机了。
        当用户通信完毕时，NCP释放网络层连接，收回原来分配出去的IP地址。接着，LCP释放数据链路层连接。最后释放的是物理层的连接。
        PPP链路的起始和终止状态永远是“链路静止”（LinkDead）状态，这时在用户PC机和ISP的路由器之间并不存在物理层的连接。
        当用户PC机通过调制解调器呼叫路由器时（通常是在屏幕上用鼠标点击一个连接按钮），路由器就能够检测到调制解调器发出的载波信号。在双方建立了物理层连接后， PPP就进入“链路建立”（LinkEstablish）状态，其目的是建立链路层的LCP连接。
        这时LCP开始协商一些配置选项，即发送LCP的配置请求帧（Configure-Request）。这是个PPP帧，其协议字段置为LCP对应的代码，而信息字段包含特定的配置请求。链路的另一端可以发送一下集中响应中的一种：
            1）配置确认帧（Configure-Ack）：所有选项都接受。
            2）配置否认帧（Configure-Nak）：所有选项都理解但不能接受。
            3）配置拒绝帧（Configure-Reject）：选项有的无法识别或不能接受，需要协商。
        LCP配置选项包括链路上的最大帧长、所使用的鉴别协议（authentication protocol）的规约（如果有的话），以及不使用PPP帧中的地址和控制字段（因为这两个字段的值是固定的，没有任何信息量，可以在PPP帧的首部中省略这两个字节）。
        协商结束后双方就建立了LCP链路，接着就进入“鉴别”（“Authenticate”）状态。在这一状态，只允许传送LCP协议的分组。鉴别协议的分组以及检测链路质量的分组。若使用口令鉴别协议PAP（Password Authentication Protocol），则需要发起通信的一方发送身份标识符和口令。系统可允许用户重试若干次。如果需要有更好的安全性，则可食用更加复杂的口令握手鉴别协议CHAP（Challenge-HandshakeAuthenticationProtocol）。若鉴别身份失败，则转到“链路终止”（LinkTerminate）状态。若鉴别成功，则进入“网络层协议”（Network-LayerProtocol）状态。
        当网络层配置完毕后，链路就进入可进行数据通信的“链路打开”（LinkOpen）状态。链路的两个PPP端点可以彼此向对方发送分组。两个PPP端点还可发送回送请求LCP分组（Echo-Request）和回送回答LCP分组（Echo-Reply），以检查链路的状态。
        数据传输结束后，可以由链路的一端发出终止请求LCP分组（Terminate-Request）请求终止链路连接，在收到对方发来的终止确认LCP分组（Terminate-Ack）后，转到“链路终止”转态。如果链路出现故障，也会从“链路打开”状态转到“链路终止”状态。当调制解调器的载波停止后，则回到“链路静止”转态。
        PPP协议的几个转态的说明。从设备之间无链路开始，到先建立物理链路，再建立LCP链路。经过鉴别后再建立NCP链路，然后才能交换数据。由此可见，PPP协议已不是纯粹的数据链路层的协议，它还包含了物理层和网络层的内容。
3.3使用广播信道的数据链路层
    广播信道可以进行一对多的通信。下面要讨论的局域网使用的就是广播信道。局域网是在20世纪70年代末发展起来的。局域网技术计算机网络中占有非常重要的地位。
    3.3.1局域网的数据链路层
        局域网最重要的特点是：网络为一个单位所拥有，且地理范围和站点数目均有限。在局域网往往出现时，局域网比广域网具有较高的数据率、较低的时延和较小的误码率。但随着光纤技术在广域网中普遍使用，现在广域网也具有很高的数据率和很低的误码率。
        局域网具有如下的一些主要优点：
            1)具有广播功能，从一个站点可很方便地访问全网。局域网上的主机可共享连接在局域网上的各种硬件和软件资源。
            2）便于系统的扩展和逐渐地演变，各设备的位置可灵活调整和改变。
            3）提高了系统的可靠性（reliability）、可用性（availability）和生存性（survivability）。
        局域网可按网络拓扑进行分类。由于集线器（hub）的出现和双绞线大量用于局域网中，星型以太网以及多级星形结构的以太网获得了非常广泛的应用。环型网，最典型的是令牌环型网（token ring），简称为令牌环。总线网，各站直接连在总线上。总线两端的匹配电阻吸收在总线上传播的电磁波信号的能量，避免在总线上产生有害的电磁波反射。总线网可使用两种协议。一种是传统以太网使用的CSMA/CD，而另一种是令牌传递总线网，即物理上是总线网而逻辑上是令牌环型网。前一种总线网现在已演进为星型网，而后一种令牌传递总线网早已退出了市场。树形网，它是总线网的变形，都属于使用广播信道的网络，但这主要用于频分复用的宽带局域网。局域网经过了近三十年的发展，尤其是在快速以太网（100Mb/s）和吉比特以太网（1Gb/s）、10吉比特以太网（10Gb/s）进入市场后，以太网已经在局域网市场中占据了绝对优势。现在以太网几乎成为了局域网的同义词，因此本章从本章开始都是讨论以太网技术。
        局域网可使用多种传输媒体。双绞线最便宜，原来只用于低速（1~2Mb/s）基带局域网。现在10Mb/s甚至100Mb/s乃至1Gb/s的局域网也可使用双绞线。双绞线已成为局域网中的主流传输媒体。50Ω同轴电缆可用到10Mb/s，而75Ω同轴电缆可用到几百Mb/s。光纤具有很好的抗电磁干扰特性和很宽的频带，主要用在环型网中，其数据率可达100Mb/s甚至达到10Gb/s。现在技术发展很快，点对点线路使用光纤也已相当普遍。

        必须指出，局域网工作的层次跨越了数据链路层和物理层。由于局域网技术中有关数据链路层的内容比较丰富，因此我们就把局域网的内容放在数据链路层这一章中讨论。但这并不表示局域网仅仅和数据链路层有关。
        共享信道要着重考虑的一个问题就是如何使用众多用户能够合理而方便地共享通信媒体资源。这在技术上有两种方法：
            1）静态划分信道，第二章已经介绍过的频分复用、时分复用、波分复用和码分复用等。用户只要分配到了信道就不会和其他用户发生冲突。但这种划分信道的方法代价较高，不适合局域网使用。
            2）动态媒体接入控制，他又称为多点接入（multiple access），其特点是信道并非在用户通信时固定分配给用户。这里又分为以下两类：
                随机接入    随机接入的特点是所有的用户可随机地发送信息。但如果恰巧有两个或更多的用户在同一时刻发送信息，那么在共享媒体上就要超声碰撞（即发生了冲突），使得这些用户的发送都失败。因此，必须有解决碰撞的网络协议。
                受控接入    受控接入的特点是用户不能随机地发送信息而必须服从一定的控制。这类的典型代表有分散控制的令牌环局域网和集中控制的多点线路探询（polling），或称为轮询。
            属于随机接入的以太网将重点讨论。受控接入则由于目前在局域网中使用得较少，本书不再讨论。
        由于以太网的数据率已演进到每秒百兆比特、吉比特或甚至10吉比特，因此通常就用“传统以太网”来表示最早流行的10Mb/s速率的以太网。下面我们先介绍传统以太网。
            1.以太网的两个标准
                以太网是美国施乐（Xerox）公司的PaloAlto研究中心（简称为PARC）于1975年研制成功的。那时，以太网是一种基带总线局域网，当时的数据率为2.94MB/。以太网用无源电缆作为总线来传送数据帧，并以曾经在历史上表示传播电磁波的以太（Ether）来命名。1976年7月，Metcalfe和Boggs发表他们的以太网里程碑论文。1980年9月，DEC公司、英特尔（Intel）公司和施乐公司联合提出了10Mb/s以太网规约的第一个版本DIX V1（DIX是这三个公司名称的缩写）。1982年又修改为第二版规约（实际上也就是最后的版本），即DIX Ethernet V2，成为世界上第一个局域网产品的规约。
                在此基础上，IEEE802委员会的802.3工作组于1983年制订了第一个IEEE的以太网标准IEEE 802.3，数据率为10MB/s。802.3局域网对以太网标准中的帧格式作了很小的一点更动，但允许基于这两种标准的硬件实现可以在同一个局域网上互操作。以太网的两个标准DIX Ethernet V2与IEEE的802.3标准只有很小的差别，因此很多人也常把802.3局域网简称为“以太网”（本书也经常不严格区分它们，虽然严格说来，“以太网”应当是指符合DIXEthernet V2标准的局域网）。
                出于有关厂商在商业上的激烈竞争，IEEE802委员会未能形成一个统一的、“最佳的”局域网标准，而是被迫指定了几个不同额局域网标准，如802.4令牌总线网、802.5令牌环网等。为了使数据链路层能更好地适应多种局域网标准，IEEE802委员会就把局域网的数据链路层拆成两个子层，即逻辑链路控制LLC（LogicalLinkControl）子层和媒体接入控制MAC（MediumAccessControl）子层。与接入到传输媒体有关的内容都放在MAC子层，而LLC子层则与传输媒体无关，不管采用何种传输媒体和MAC子层的局域网对LLC子层来说都是透明的。
                然而到了20世纪90年代后，激烈竞争的局域网市场逐渐明朗。以太网在局域网市场中已取得了垄断地位，并且几乎成为了局域网的代名词。由于因特网发展很快而TCP/IP体系经常使用的局域网只剩下DIX Ethernet V2 而不是IEEE 802.3标准中的局域网，因此现在IEEE 802委员会制定的逻辑链路控制子层LLC（即IEEE 802.2标准）的作用已经消失了，很多厂商生产的适配器上就仅装有MAC协议而没有LLC协议。本章在介绍以太网时就不再考虑LLC子层。这样对以太网工作原理的讨论会更加简洁。
            2.适配器的作用
                首先我们从一般的概念上讨论一下计算机是怎样连接到局域网上的。
                计算机与外界局域网的连接是通过通信适配器（adapter）。适配器本来是在主机箱内插入的一块网络接口板（或者是在笔记本电脑中插入一块PCMCIA卡）。这种接口板又称为网络接口卡NIC（NetworkInterfaceCard）或简称为“网卡”。由于较新的计算机主板上已经嵌入了这种适配器，不使用单独的网卡了，因此本书使用适配器这个更准确的术语。在适配器上面装有处理器和存储器（包括RAM和ROM）。适配器和局域网之间的通信是通过电缆或双绞线以串行传输方式进行的，而适配器和计算机之间的通信则是通过计算机主板上的I/O总线以并行传输方式进行的。因此，适配器的一个重要功能就是要进行数据串行和并行传输的转换。由于网络上的数据率和计算机总线上的数据率并不相同，因此在适配器中必须装有对数据进行缓存的存储芯片。若在主板上插入适配器时，还必须把管理适配器的设备驱动程序安装在计算机的操作系统中。这个驱动程序以后就会告诉适配器，应当从存储器的什么位置上把多长的数据块发送到局域网，或者应当在存储器的什么位置上把局域网传送过来的数据块存储下来。适配器还要能够实现以太网协议。
                适配器接收和发送各种帧时不实用计算机的CPU。这是CPU可以处理其他任务。当适配器收到有差错的帧时，就把这个帧丢弃而不必通知计算机。当适配器收到正确的帧时，他就使用中断来通知该计算机并交付给协议栈中的网络层。当计算机要发送IP数据报时，就由协议栈把IP数据报向下交给适配器，组装成帧后发送到局域网。我们特别要注意，计算机的硬件地址就在适配器的ROM中，而计算机的软件地址--IP地址，则在计算机的存储器中。
    3.3.2CSMA/CD协议
        CSMA/CD协议是本章所要讲述的最重要的一个协议。
        当初提出以太网的方案是基于下面的思路：要寻找很简单的方法把一些相聚不太远的计算机互相连接起来，使它们可以很方便地进行较高速率的数据通信。
        最早的以太网是将许多计算机都连接到一根总线上。当初认为这种连接方法既简单又可靠，因为在那个时代普遍认为：“有源器件不可靠，而无源的电缆线才是最可靠的”。
        总线的特点是：当一台计算机发送数据时，总线上的所有计算机都能检测到这个数据。这种就是广播通信方式。但我们并不总是要在局域网上进行一对多的广播通信。为了在总线上实现一对一的通信，可以使每一台计算机的适配器拥有一个与其他适配器都不同的地址。在发送数据帧时，在帧的首部写明接收站的地址。现在的电子技术可以很容易做到：仅当数据帧中的目的地址与适配器ROM中存放的硬件地址一致时，该适配器才能接受这个数据帧。适配器对不是发送给自己的数据帧就丢弃。这样，具有广播特性的总线上就实现了一对一的通信。
        人们也常把局域网上的计算机称为“主机”、“工作站”、“站点”或“站”。
        为了通信的简便，以太网采用了以下两种措施：
            第一，采用较为灵活的无连接的工作方式，即不必先建立连接就直接发送数据。适配器对发送的数据帧不进行编号，也不要求对方发回确认。这样做的里有是局域网信道的质量很好，因通信质量不好产生差错的概率是很小的。因此，以太网提供的服务是不可靠的交付。即尽最大努力的交付。当目的站收到有差错的数据帧时（例如，用CRC查出有差错），就把帧丢弃，其他什么也不做。但对有差错帧是否需要重传则由高层来决定。例如，如果高层使用TCP协议，那么TCP就会发现丢失了一些数据。于是经过一定时间后，TCP就把这些数据重新传递给以太网进行重传。但以太网并不知道这是重传帧，而是当做新的数据帧来发送。
            第二，以太网发送的数据都是用曼彻斯特（Manchester）编码的信号。我们知道，二进制基带数字信号通常就是高、低电压交替出现的信号。使用这种信号的最大问题就是当出现一长串的连1或连0时，接收端就无法从收到的比特流中提取位同步（即比特同步）信号。曼彻斯特编码的编码方法是把每一个码元再分成两个相等的间隔。码元1是在前一个间隔为低电压而后一个间隔为高电压。码元0则正好相反，从高电压变到低电压（也可以采用相反的约定，即1是“前高后低”而0是“前低后高”）。这样就保证了在每一个码元的正中间出现一次电压的转换，而接收端就利用这种电业的转换很方便地把位同步信号提取出来。但是从曼彻斯特编码的波形图也不难看出其缺点，这就是它所占的频带宽度比原始的基带信号增加了一倍（因为每秒传送的码元数加倍了）。
        剩下的一个重要问题就是如何协调总线上各计算机的工作。我们知道，总线上只要有一台计算机在发送数据，总线的传输资源就被占用。因此，在同一时间只能允许一台计算机发送信息，否则个计算机之间就会互相干扰，结果大家都无法正常发送数据。
        以太网采用的协调方法是使用一种特殊的协议CSMA/CD，它是载波监听多点接入/碰撞检测（CarrierSenseMultipleAccessWithCollisionDetection）的缩写。下面是CSMA/CD协议的要点。
        “多点接入”就是说明这是总线型网络，许多计算机以多点接入的方式连接在一根总线上。协议的实质是“载波监听”和“碰撞测试”。
        “载波监听”就是“发送前先监听”，即每一个站在发送数据之前检测一下总线上是否有其他站在发送数据，如果有，则暂时不要发送数据，要等待信道变为空闲时再发送。其实总线上并没有什么“载波，“载波监听”就是用电子技术检测总线上有没有其他计算机发送的数据信号。
        “碰撞检测”就是“边发送边监听”，即适配器边发送数据边检测信道上的信号电压的变化情况，以便判断自己在发送数据时其他站是否也发送数据。当几个站同时在总线上发送数据时，总线上的信号电压变化幅度将会增大（互相叠加）。当适配器检测到的信号电压变化幅度超过一定的门限值时，就认为总线上至少有两个站同时在发送数据，表明产生了碰撞。所谓“碰撞”就是发生了冲突。因此“碰撞检测”也称为“冲突检测”。这时，总线上传输的信号产生了严重的失真，无法从中恢复出有用的信息来。因此，每一个正在发送数据的站，一旦发现总线上出现了碰撞，适配器就要立即停止发送，免得继续浪费网络资源，然后等待一段随机时间后再次发送。
        既然每一个站在发送数据之前已经监听到信道为“空闲”，那么为什么还会出现数据在总线上的碰撞呢？这是因为电磁波在总线上总是以有限的速率传播的。因此当某个站监听到总线是空闲时，总线并非一定是空闲的。设局域网两端的站A和B相距1km，用同轴电缆相连。电磁波在1km电缆的传播时延约为5μs（这个数字应当记住）。因此，A向B发出的数据，在约5μs后才能传送到B。换言之，B若在A发送的数据到达B之前发送自己的帧（因为这时B的载波监听检测不到A所发送的信息），则必然要在某个时间和A发送的帧发生碰撞。碰撞的结果是两个帧都变得无用。在局域网的分析中，常把总线上的单程端到端传播时延为τ。发送数据的站希望尽早知道是否发生了碰撞。那么，A发送数据后，最迟要经过多长时间才能知道自己发送的数据和其他站发送的数据有没有发生碰撞？这个时间最多是两倍的总线端到端的传播时延（2τ）。或总线的端到端往返传播时延。由于局域网上任意两个站之间的传播时延有长有短，因此局域网必须按最坏情况设计，即取总线两端的两个站之间的传播时延（这两个站之间的距离最大）为端到端传播时延。
        显然，在使用CSMA/CD协议时，一个站不可能同时进行发送和接收。因此使用CSMA/CD协议的以太网不可能进行全双工通信而只能进行双向交替通信（半双工通信）。
        每一个站在自己发送数据之后的一小段时间内，存在着遭遇碰撞的可能性。这一小段时间是不确定的，它取决于另一个发送数据的站到本站的距离。因此，以太网不能保证某一时间之内一定能够把自己的数据帧成功地发送出去（因为存在产生碰撞的可能）。以太网的这一特点称为发送的不确定性。如果希望在以太网上发生碰撞的机会很小，必须使整个以太网的平均通信量远小于以太网的最高数据率。
        最先发送数据帧的A站，在发送数据帧后至多经过时间2τ就可知道所发送的数据帧是否遭受了碰撞。这就是δ→0的情况。因此以太网的端到端往返时间2τ称为争用期（contention period），它是一个很重要的参数。争用期又称为碰撞窗口（collision window）。这是因为一个站在发送完数据后，只有通过争用期的“考验”，即经过争用期这段时间还没有检测碰撞，才能肯定这次发送不会发生碰撞。
        以太网使用截断二进制指数退避（truncated binary exponential backoff）算法来解决碰撞问题。截断二进制指数退避算法并不复杂。这种算法让发生碰撞的站在发送数据后，不是等待信道变为空闲后就立即在发送数据，而是推迟（这叫作退避）一个随机的时间。这样做是为了使重传时再次发送冲突的概率减小。具体的退避算法如下：
            1）确定基本退避时间，它就是争用期2τ。以太网把争用期定位51.2μs。对于10Mb/s以太网，在争用期内可发送512bit，即64字节。也可以说争用期是512比特时间。1比特时间就是发送1比特所需的时间。所以这种时间单位与数据率密切相关。
            2）从离散的整数集合[0,1,...,(2^k-1)]中随机取出一个数，记为r。重传应推后的时间就是r倍的争用期。上面的参数按下面的公式（3-1）计算：k=Min（重传次数，10）。可见当重传次数不超过10时，参数k等于重传次数；但当重传次数超过10时，k就不再增大而一直等于10。
            3）当重传达16次仍不能成功时（这表明同时打算发送数据的站太多，以致连续发生冲突），则丢弃该帧，并向高层报告。
                例如，在第1次重传时，k=1，随机数r从整数｛0，1｝中选一个数。因此重传的站可选择的重传推迟时间是0或2τ，在这两个时间中随机选择一个。
                若再发生碰撞，则在第2次重传时，k=2，随机数r就从整数｛0，1，2，3｝中选一个数。因此重传推迟的时间是在0，2τ，4τ和6τ这4个时间中随机地选取一个。
                同样，若在发生碰撞，则重传时k=3，随机数r就从整数｛0，1，2，3，4，5，6，7｝中选一个数。以此类推。
                若连续多次发生冲突，就表明可能有较多的站参与争用信道。但使用上述退避算法可使重传需要推迟的平均时间随重传次数而增大（折页称为动态退避），因而减小发生碰撞的概率，有利于整个系统的稳定。
                我们还应注意到，适配器没发送一个新的帧，就要执行一次CSMA/CD算法。适配器对过去发送过的碰撞并无记忆功能。因此，当好几个适配器正在执行指数退避算法时，很可能有某一个适配器发送的新帧能够碰巧立即成功地插入到信道中，得到了发送权。
                我们可以看出，以太网在发送数据时，如果帧的前64字节没有发生冲突，那么后续的数据就不会发生冲突。换句话说，如果发生冲突，就一定是在发送的前64字节之内。由于一检测到冲突就立即中止发送，这时已经发送出去的数据一定小于64字节，因此以太网规定了最短有效帧长为64字节，凡长度小于64字节的帧都是由于冲突而异常终止的无效帧。收到了这种无效帧就应当立即丢弃。
                需要指出，以太网的端到端时延实际上是小于争用期的一半（即25.6μs）。争用期被规定为51.2μs，不仅是考虑了以太网的端到端时延，而且还包括其他的许多因素，如可能存在的转发器所增加的时延，以及下面要讲到的强化碰撞的干扰信号的持续时间等。
                以太网还采取一种叫做强化碰撞的措施。这就是当发送数据的站一旦发现了碰撞时，除了立即停止发送数据外，还要再继续发送32比特或48比特的人为干扰信号（jamming signal），以便让所有用户都知道现在已经发生了碰撞。对于10Mb/s以太网，发送32（或48）比特只需要3.2（或4.8）μs。
                A站从发送数据开始到发现碰撞并停止发送的时间间隔是Tb。A站得知碰撞已经发生时所发送的强化碰撞的干扰信号的持续时间是Tj。B站在得知发生碰撞后，也要发送人为干扰信号。发生碰撞使A浪费时间Tb+Tj。可是整个信道被占用的时间还要增加一个单程端到端的传播时延τ。因此总线被占用的时间是Tb+Tj+τ。
                以太网还规定了帧间最小间隔为9.6μs，相当于96比特时间。这样做是为了使刚刚收到的数据帧的站的接受缓存来得及清理，做好接收下一帧的准备。
                根据以上所讨论，可以把CSMA/CD协议的要点归纳如下：
                    1）适配器从网络层获得一个分组，加上以太网的首部和尾部，组成以太网帧，放入适配器的缓存中，准备发送。
                    2）若适配器检测到信道空闲（即在96比特时间内没有检测到信道上有信号），就发送这个帧。若检测到信道忙，则继续检测并等待信道转为空闲（加上96比特时间），然后发送这个帧。
                    3）在发送过程中继续检测信道，若一直未检测到碰撞，就顺利把这个帧成功发送完毕。若检测到碰撞，则中止数据的发送，并发送人为干扰信号。
                    4）在中止发送后，适配器就执行指数退避算法，等待r倍512比特时间后，返回到步骤（2）。
3.4使用广播信道的以太网
    3.4.1使用集线器的星型拓扑
        传统以太网最初是使用粗同轴电缆，后来演进到使用比较便宜的细同轴电缆，最后发展为使用更便宜和更灵活的双绞线。这种以太网采用星型拓扑，在星型的中心则增加了一种可靠性非常高的设备，叫做集线器（hub）。双绞线以太网总是和集线器配合使用的。每个站需要用两对无屏蔽双绞线，分别用于发送和接收。双绞线的两端使用RJ-45插头。由于集线器使用了大规模集成电路芯片，因此集线器的可靠性就大大提高了。1990年IEEE制定出星星以太网10BASE-T的标准802.3i。“10”代表10Mb/s的数据率，BASE表示连接线上的信号是基带信号，T代表双绞线。实践证明，这比使用具有大量机械接头的无源电缆眼可靠得多。由于使用双绞线电缆的以太网价格便宜和使用方便，因此粗缆和细缆以太网现在都已成为历史，并已从市场上消失了。
        但10BASE-T以太网的通信距离稍短，每个站到集线器得到距离不超过100m。这种性价比很高的10BASE-T双绞线以太网的出现，是局域网发展史上的一个非常重要的里程碑，它为以太网在局域网中的统治地位奠定了牢固的基础。
        使双绞线能够传送高速数据的主要措施是把双绞线的绞合度做得非常精确。这样不仅可使特性阻抗均匀以减少失真，而且大大减少了电磁波辐射和无线电频率的干扰。在多对双绞线的电缆中，还要使用更加复杂的绞合方法。
        集线器的一些特点如下：
            1）从表面上看，使用集线器的局域网在物理上是一个星型网，但由于集线器是使用电子器件来模拟实际电缆线的工作，因此整个系统仍像一个传统以太网那样运行。也就是说，使用集线器的以太网在逻辑上仍是一个总线网，各站共享逻辑上的总线，使用的还是CSMA/CD协议（更具体些，是各站中的适配器执行CSMA/CD协议）。网络中的各站必须竞争对传输媒体的控制，并且在同一时刻至多只允许一个站发送数据。因此这种10BASE-T以太网又称为星型总线（star-shaped bus）或盒中总线（bus in a box）。
            2）一个集线器有许多接口，例如，8至16个，每个接口通过RJ-45插头（与电话机使用的插头RJ-11相似，但略大一些）用两对双绞线与一个工作站上的适配器相连（这种插座可连接4对双绞线，实际上只用2对，即发送和接收各使用一对双绞线）。因此，一个集线器很像一个多接口的转发器。
            3）集线器工作在物理层，它的每个接口仅仅简单地转发比特--收到1就转发1，收到0就转发0，不进行碰撞检测。若两个接口同时有信号输入（即发生碰撞），那么所有的接口都将收不到正确的帧。
            4）集线器采用了专门的芯片，进行自适应串音回波抵消。这样就可使接口转发出去的较强信号不致对该信号接收到的较弱信号产生干扰（这种干扰即近端串音）。每个比特在转发之前还要进行再生整形并重新定时。
        集线器本身必须非常可靠。现在的堆叠式（stackable）集线器由4~8个集线器堆叠起来使用。一般都有少量的容错能力和网络管理功能。例如，假定在以太网中有一个适配器出了故障，不停地发送以太网帧。这时，集线器可以检测到这个问题，在内部断开与出故障的适配器的连线，使整个以太网仍然能够正常工作。模块化的机箱式智能集线器有很高的可靠性。他全部的网络功能都以模块方式实现。各模块均可进行热插拔，出故障时不断电即可更换或增加新模块。集线器上的指示灯还可显示网络上的故障情况，给网络的管理带来了很大的方便。
        IEEE802.3标准还可使用光纤作为传输媒体，相应的标准是10BASE-F系列，F代表光纤。它主要用作集线器之间的远程连接。
    3.4.2以太网的信道利用率
        下面我们讨论一下以太网的信道利用率。
        假定一个10Mb/s以太网同时有10个站在工作，那么每一个站所能发送数据的平均速率似乎应当是总数据率的1/10（即1Mb/s）。其实不然，因为多个站在以太网上同时工作就可能会发生碰撞。当发生碰撞时，信道资源实际上是被浪费了。因此，当扣除碰撞所造成的信道损失后，以太网总的信道利用率并不能达到100%。
        以太网的信道被占用的情况的例子。一个站在发送帧时出现了碰撞。经过一个争用期2τ后（τ是以太网单程端到端传播时延），可能又出现了碰撞。这样经过若干个争用期后，一个站发送成功了。假定发送帧需要的时间是T0。它等于帧长（bit）除以发送速率（10Mb/s）。
        我们应当注意到，成功发送一个帧需要占用信道的时间是T0+τ，比这个帧的发送时间要多一个单程端到端时延τ。这是因为当一个站发送完最后一个比特时，这个比特还要在以太网上传播。在最极端的情况下，发送站在传输媒体的一端，而比特在媒体上传输到另一端所需的时间是τ。因此，必须在经过时间T0+τ后以太网的媒体才完全进入空闲状态，才能允许其他站发送数据。
        要提高以太网的信道利用率，就必须减小τ与T0之比。在以太网中定义了参数a，它是以太网单程端到端时延τ与帧的发送时间T0之比：a=τ/T0 。
        当a→0时，表示只要一发生碰撞，就立即可以检测出来，并立即停止发送，因而信道资源被浪费的时间非常少。反之，参数a越大，表明争用期所占的比例增大，这就使得每发生一次碰撞就浪费了不少的信道资源，使得信道利用率明显降低。因此，以太网的参数a的值应当尽可能小些。从公式可看出，这就要求公式分子τ的数值要小些，而分母T0的数值要大些。这就是说，当数据率一定时，以太网的连线的长度受到限制（否则τ的数值会太大），同时以太网的帧长不能太短（否则T0的值会太小，使a值太大）。
        现在考虑一种理想化的情况。假定以太网上的各站发送数据都不会产生碰撞（这显然已经不是CSMA/CD，而是需要使用一种特殊的调度方法），并且能够非常有效地利用网络的传输资源，即总线一旦空闲就有某一个站立即发送数据。这样，发送一帧占用线路的时间是T0+τ，而帧本身的发送时间是T0.于是我们可计算出极限信道利用率Smax为：Smax=T0/T0+τ=1/1+a。公式的意义是：虽然实际的及台网不可能有这样高的极限信道利用率，但公式指出了只有当参数a远小于1才能得到尽可能高的极限信道利用率。反之，若参数a远大于1（即每发生一次碰撞，就要浪费了相对较多的传输数据的时间），则极限信道利用率就远小于1，而这时实际的信道利用率就更小了。
    3.4.33以太网的MAC层
        1.MAC层的硬件地址
            在局域网中，硬件地址又称为物理地址或MAC地址（因为这种地址用在MAC帧中）。
            大家知道，在所有计算机系统的设计中，标识系统（identification system）都是一个核心问题。在标识系统中，地址就是为识别某个系统的一个非常重要的标识符。在讨论地址问题时，很多人常常引用注明文件[SHOC78]给出的如下定义：
                “名字指出我们所要寻找的那个资源，地址指出那个资源在何处，路由告诉我们如何到达该处。”
            这个非形式的定义固然很简单，但有时却不够准确。严格地讲，名字应当与系统的所在地无关。这就像我们每一个人的名字一样，不随我们所处的地点而改变。但是 IEEE802标准为局域网规定了一种48位的全球地址（一般都简称为“地址”），是指局域网上的每一台计算机中固化在适配器的ROM中的地址。因此，
                1）假定连接在局域网上的一台计算机的适配器坏了而我们更换了一个新的适配器，那么这台计算机的局域网的“地址”也就改变了，虽然这台计算机的地理位置一点儿也没有变化，所接入的局域网也没有任何改变。
                2）假定我们把位于南京的某局域网上的一台笔记本电脑携带到北京，并连接在北京的某局域网上。虽然这台电脑的地理位置改变了，但只要电脑中的适配器不变，那么该电脑在北京的局域网中的“地址”仍然和它在南京的局域网中的“地址”一样。
            由此可见，局域网上的某个主机的“地址”根本不能告诉我们这台我们主机位于什么地方。因此，严格地讲，局域网的“地址”应当是每一个站的“名字”或标识符[PERL00]。不过计算机的名字通常都是比较适合人记忆的不太长的字符串，而这种48位二进制的“地址”却很不像一般计算机的名字。现在人们还是习惯于把这种48位的“名字”称为“地址”。本书也采用这种习惯用法，尽管这种说法并不太严格。
            请注意，如果连接在局域网上的主机或路由器安装有多个适配器，那么这样的主机或路由器就有多个“地址”。更准确些说，这种48位“地址”应当是某个接口的标识符。
            在指定局域网的地址标准时，首先遇到的问题就是应当用多少位来表示一个网络的地址字段。为了减少不必要的开销，地址字段的长度应当尽可能地短些。起初人们觉得应两个字节（共16位）便是地址就够了，因为这一共可表示6万多个地址。但是，由于局域网的迅速发展，而处在不同地点的局域网之间有经常需要交换信息，这就希望在各地的局域网中的站具有互不相同的物理地址。为了使用户在买到适配器并把机器连到局域网后马上就能工作，而不需要等待网络管理员给他先分配一个地址，IEEE802标准规定MAC地址字段可采用6字节（48位）或2字节（16位）这两种中的一种。6字节地址字段对局部范围内使用的局域网的确是太长了，但是由于6字节的地址字段可使全世界所有的局域网适配器都具有不相同的地址，因此现在的局域网适配器实际上使用的都是6字节MAC地址。
            现在IEEE的注册管理机构RA（Registration Authority）是局域网全球地址的法定管理机构[W-IEEERA]，它负责分配地址字段的6个字节中的前三个字节（即高位24位）。世界上凡要生产局域网适配器的厂家都必须向IEEE购买由这三个字节构成的这个号（即地址块），这个号的正式名称是组织唯一标识符OUI（Organizationally Unique Identifier），通常也叫做公司标识符（company_id）。例如，3Com公司生产的适配器的MAC地址的前三个字节是02-60-8C。地址字段中的后三个字节（即低维24位）则是由厂家自行指派，称为扩展标识符（extended identifier），只要保证生产出的适配器没有重复地址即可。可见用一个地址块可以生成2^24个不同的地址。用这种方式得到的48位地址称为MAC-48，他的通用名称是EUI-48，这里EUI表示扩展的唯一标识符（Extended Unique Identifier）。EUI-48的使用范围并不局限于局域网的硬件地址，而是可以用于软件接口。但应注意，24位的OUI不能够单独使用来标志一个公司，因为一个公司可能有几个OUI，也可能有几个小公司合起来购买一个OUI。在生产适配器时，这种6字节的MAC地址已被固化在适配器的ROM中。因此，MAC地址也叫做硬件地址（hardware address）或物理地址。可见“MAC地址”实际上就是适配器地址或适配器标识符EUI-48.当这块适配器插入（或嵌入）到某台计算机后，适配器上的标识符EUI-48就成为这台计算机的MAC地址了。
            IEEE规定地址字段的第一字节的最低位是I/G位。I/G表示Individual/Group。当I/G位为0时，地址字段表示一个单个站地址。当I/G位为1是表示组地址，用来进行多播（以前曾译为组播）。因此IEEE只分配地址字段前三个字节中的23位。当I/G位分别为0和1时，一个地址块可分别生成2^24个单个站地址和2^24个组地址。需要指出，有的书把上述最低位写为“第一位”，但“第一”的定义是含糊不清的。这是因为在地址记法中有两种标准：第一种记法是把每一个字节的最低位写在最左边（最右边的最低位是第一位）。IEEE802.3标准就采用这种记法。第二种记法是把每一字节的最高位写在最左边（最左边的最高位是第一位）。在发送数据时，两种记法都是按照字节的顺序发送，但每一个字节中先发送哪一位则不同：第一种记法先发送最低位，第二种记法先发送最高位。
            IEEE还考虑到可能有人并不愿意向IEEE的RA购买OUI。为此，IEEE把地址字段第1字节的最低第二位规定为G/L位，表示Global/Local。当G/L位为1时是全球管理（保证在全球没有相同的地址），厂商向IEEE购买的OUI都属于全球管理。当地址字段的G/L位为0时是本地管理，这是用户可任意分配网络上的地址。采用2字节地址字段时全都是本地管理。但应当指出，以太网几乎不实用这个G/L位。
            这样，在全球管理时，对每一个站的地址可用46位的二进制数字来表示（最低位为0和最低第2位为1时）。剩下德6位组成的地址空间可以有2^46个地址，已经超过70万亿个，可保证世界上的每一个适配器都可以有一个唯一的地址。
            当路由器通过适配器连接到局域网时，适配器是的硬件地址就用来标志路由器的某个接口。路由器如果同时连接到两个网络上，那么他就需要两个适配器和两个硬件地址。
            我们知道适配器有过滤功能。但适配器从网络上每收到一个MAC帧就先用硬件检查MAC帧中的目的地址。如果是发往本站的帧则收下，然后再进行其他的处理。否则就将此帧丢弃，不在进行其他的处理。这样做就不浪费主机的处理机和内存资源。这里“发往本站的帧”包括一下三种帧：
                1）单播（unicast）帧（一对一），即收到的帧的MAC地址与本站的硬件地址相同。
                2）广播（broadcast）帧（一对全体），即发送给本局域网上所有站点的帧（全1地址）。
                3）多播（multicast）帧（一对多），即发送给本局域网上一部分站点的帧。
            所有的适配器都至少应当能够识别前两种帧，即能够识别单播和广播地址。有的适配器可用编程方法识别多播地址。当操作系统启动时，他就把适配器初始化，使适配器能够识别某些多播地址。显然，只有目的地址才能使用广播地址和多播地址。
            以太网适配器还可设置为一种特殊的工作方式，即混杂方式（promiscuous mode）。工作在混杂方式的适配器只要“听到”有帧在以太网上传输就都悄悄地接收下来，而不管这些帧是发往哪个站。请注意，这样做实际上是“窃听”其他站点的通信而并不中断其他站点的通信。网络上的黑客（hacker或cracker）常利用这种方法非法获取网上用户的口令。因此以太网上的用户不愿意网络上有工作在混杂方式的适配器。
            但混杂方式有时却非常有用。例如，网络维护和管理人员需要用这种方式来监视和分析以太网上的流量，以便找出提高网络性能的具体措施。有一种很有用的网络工具叫做嗅探器（Sniffer）就使用了设置为混杂方式的网络适配器。此外，这种嗅探器还可帮助学习网络的人员更好地理解各种网络协议的工作原理。因此，混杂方式就像一把双刃剑，是利是弊要看你怎样使用它。
        2.MAC帧的格式
            常用的以太网MAC帧格式有两种标准，一种是DIXEthernet V2标准（即以太网V2标准），另一种是IEEE的802.3标准。这里只介绍使用得最多的以太网V2的MAC帧格式。假定网络层使用的是IP协议。实际上使用使用其他的协议也是可以的。
            以太网V2的MAC帧比较为简单，由五个字段组成。前两个字段为6字段长的目的地址和源地址字段。第三个字段是2字节的类型字段，用来标志上一层使用的是什么协议，以便把收到的MAC帧的数据上交给上一层的这个协议。例如，当类型字段的值是0x0800时，就表示上层使用的是IP数据报。若类型字段的值为0x8137，则表示该帧是由Novell IPX发过来的。第四个字段是数据字段，其长度在46到1500字节之间（46字节是这样得出的：最小长度64字节减去18字节的首部和尾部就得出数据字段的最小长度）。最后一个字段是4字节的帧检验序列FCS（使用CRC检验）。当传输媒体的误码率为1x10^-8时，MAC子层可使未检测到的差错小于1x10^-14。
            这里我们要指出，在以太网V2的MAC帧格式中，其首部并没有一个帧长度（或数据长度）字段。那么，MAC子层又怎样知道从接收到的以太网帧中取出多少字节的数据交付给上一层协议呢？我们在前面讲述的曼彻斯特编码时已经讲过，这种曼彻斯特编码的一个重要特点就是：在曼彻斯特编码的每一个码元（不管码元是1或0）的正中间一定有一次电压的转换（从高到低或从低到高）。当发送方把一个以太网帧发送完毕后，就不再发送其他码元了（既不发送，也不发送0）。因此，发送方网络适配器的接口上的电压也就不再变化了。这样，接收方就可以很容易地找到以太网的结束位置。在这个位置往前数4字节（FCS字段长度是4字节），就能确定数据字段的结束位置。
            当数据字段的长度小于46字节时，MAC子层就会在数据字段的后面加入一个整数字节的填充字段，以保证以太网的MAC帧长不小于64字节。我们应当注意到，MAC帧的首部并没有指出数据字段的长度是多少。再有填充字段的情况下，接收端的MAC子层在剥去首部和尾部后就把数据字段和填充字段一起上交上层协议。现在的问题是：上层协议如何知道填充字段的长度呢？（IP层要丢弃没有用处的填充字段）。可见，上层协议必须具有识别有效的数据字段长度的功能。我们知道，当上层使用IP协议时，其首部就有一个“总长度”字段。因此，“总长度”加上填充字段的长度，应当等于MAC帧数据字段的长度。例如，当IP数据报的总长度为42字节时，填充字段共有4字节。当MAC帧把46字节的数据上交给IP层后，IP层就把其中最后4字节的填充字段丢弃。
            在传输媒体上世纪传送的要比MAC帧还多8个字节。这是因为当一个站在刚开始接收MAC帧时，由于适配器的时钟尚未与到达的比特流达成同步，因此MAC帧的最前面的若干位就无法接收，结果使整个的MAC成为无用的帧，为了接收端迅速实现位同步，从MAC子层向下传到物理层时还要在帧的前面插入8字节（由硬件生成），它由两个字段构成。第一个字段是7个字节的前同步码（1和0交易码），它的作用是使接收端的适配器在接收MAC帧时能够迅速调整其时钟频率，使它和发送端的时钟同步，也就是“实现位同步”（位同步就是比特同步的意思）。第二个字段是帧开始定界符，定义为10101011.它的前六位的作用和前同步码一样，最后的两个连续的1就是告诉接收端适配器：“MAC帧的信息马上就要来了，请适配器注意接收”。MAC帧的FCS字段的检验范围不包括前同步码和帧开始定界符。顺便指出，在使用SONET/SDH进行同步传输时则不需要用前同步码，因为在同步传输时收发双方的位同步总是一直保持着的。
            顺便指出，在以太网上传输数据时是以帧为单位传送。以太网在传送帧是，各帧之间好必须有一定的间隙。因此接收端只要找到帧开始定界符，其后面的联系到达的比特流就都属于同一个MAC帧。可见以太网不需要使用帧结束定界符，也不需要使用字节插入来保证透明传输。
                IEEE802.3标准规定凡出现下列情况之一的即为无效MAC帧：
                    1）帧的长度不是整数个字节
                    2）用收到的帧检验序列FCS查出有差错
                    3）收到的帧的MAC客户数据字段的长度不在46~1500字节之间。考虑到MAC帧首部和尾部的长度共有18字节，可以的出有效的MAC帧长度为64~1518字节之间。
                对于检查出的无效MAC帧就简单地丢弃。以太网不负责重传丢弃的帧。
                最后要提一下，IEEE 802.3标准规定的MAC帧格式与上面所讲的以太网V2MAC帧格式的区别就是两个地方。
                    第一，IEEE 802.3规定的MAC帧的第三个字段是“长度/类型”。当这个字段值大于0x0600时（相当于十进制的1536），就表示“类型”。这样的帧和以太网 V2 MAC帧完全一样。只有当这个字段值小于0x0600时才表示“长度”，即MAC帧的数据部分长度。显然，在这种情况下，若数据字段的长度与长度字段的值不一致时，则该帧为无效的MAC帧。实际上，前面我们已经讲过，由于以太网采用了曼彻斯特编码，长度字段并无实际意义。
                    第二，当“长度/类型”字段值小于0x0600时，数据字段必须装入上面的LLC子层的LLC帧。
                    由于现在广泛使用的局域网只有以太网，因此LLC帧已经失去了原来的意义。现在市场上流行的都是以太网V2的MAC帧，但大家也常常把它称为IEEE 802.3标准的MAC帧。
3.5扩展的以太网
    在许多情况下，我们希望把以太网的覆盖范围扩展。本节先讨论在物理层把以太网扩展，然后讨论在数据链路层把以太网扩展。这种扩展的以太网在网路层看来仍然是一个网络。
    3.5.1在物理层扩展以太网
        以太网上的主机之间的距离不能太远（例如，10BASE-T以太网的两个主机之间的距离不超过200米），否则主机发送的信号经过铜线的传输就会衰减到使CSMA/CD协议无法正常工作。在过去广泛使用粗揽或细揽以太网时，常使用工作在物理层的转发器来扩展以太网的地理覆盖范围。那时，两个网段可用一个转发器连接起来（单个的网段被限制为不超过500米长）。IEEE 802.3标准还规定，任意两个站之间最多可以经过三个电缆网段。但随着双绞线以太网成为以太网的主流类型，扩展以太网的覆盖范围已很少使用转发器了。
        现在，扩展主机和集线器之间的距离的一种简单方法就是使用光纤（通常是一对光纤）和一对光纤调制解调器。
        光纤调制解调器的作用就是进行电信号和光信号的转换。由于光纤带来的时延很小，并且带宽很高，因此使用这种方法可以很容易地使主机和几公里以外的集线器相连接。
        如果使用多个集线器，就可以连接成覆盖更大范围的多级星型结构的以太网。例如，一个学院的三个系各有一个10BASE-T以太网，可通过一个主干集线器把各系的以太网连接起来，成为一个更大的以太网。
        这样做可以有以下两个好处。第一，使这个学院不同系的以太网的计算机能够进行跨系的通信。第二，扩大了以太网覆盖的地理范围。例如，在一个系的10BASE-T以太网中，主机与集线器的最大距离是100m，因而两个主机之间的最大距离是200m。但在通过主干集线器相连接后，不同系的主机之间的距离就可扩展了，因为集线器之间的距离可以是100m（使用双绞线）或甚至更远（如使用光纤）。
            但这种多级结构的集线器以太网也带来了一些缺点。
            1）在三个系的以太网互连起来之前，每一个系的10BASE-T以太网是一个独立的碰撞域（collision domain，又称为冲突域），即在任一时刻，在每一个碰撞域中只能有一个站在发送数据。每一个系的以太网的最大吞吐量是10Mb/s，因此三个系总的最大吞吐量共有30Mb/s。在三个系的以太网通过集线器互连起来后就把三个碰撞域变成一个碰撞域（范围扩大到三个系），而这时的最大吞吐量仍然是一个系的吞吐量10Mb/s。这就是说，当某个系的两个站在通信时所传送的数据会通过所有的集线器进行转发，使得其他系的内部在这时都不能通信（一发送数据就会碰撞）。
            2）如果不同的系使用不同的以太网技术（如数据率不同），那么就不可能用集线器将它们互连起来。一个系使用10Mb/s的适配器，而另外两个系使用10/100Mb/s的适配器，那么用集线器连接起来后，大家都只能工作在10Mb/s的速率。集线器基本上是个多接口（即多端口）的转发器，它并不能把帧进行缓存。
    3.5.2在数据链路层扩展以太网
        在数据链路层扩展以太网要使用网桥。网桥工作在数据链路层，它根据MAC帧的目的地址对收到的帧进行转发和过滤。当网桥收到一个帧时，并不是向所有的接口转发此帧，而是先检查此帧的目的MAC地址，然后再确定将该帧转发到哪一个接口，或者是把它丢弃（即过滤）。
        1.网桥的内部结构
            一个网桥的内部结构要点。最简单的网桥有两个接口。复杂些的网桥可以有更多的接口。两个以太网通过网桥连接起来后，就成为一个覆盖范围更大的以太网，而原来的每个以太网就可以称为一个网段（segment）。网桥，其接口1和接口2各连接到一个网段。
            网桥依靠转发表来转发帧。转发表也叫做转发数据库或路由目录。至于转发表如何得出，我们将在后面第2小节“透明网桥”中讨论。若网桥从接口1收到A发给E的帧，则在查找转发表后，把这个帧送到接口2转发到另一个网段，使E能够收到这个帧。若网桥从接口1收到A发给B的帧，就丢弃这个帧，因为转发表指出，转发给B的帧应当从接口1转发出去，而现在正是从接口1收到这个帧，这说明B和A处在同一网段上，B能够直接收到这个帧而不需要借助于网桥的转发。
            网桥是通过内部的接口管理软件和网桥协议实体来完成上述操作的。
            使用网桥可以带来以下好处：
                1）过滤通信量，增大吞吐量。网桥工作在链路层的MAC子层，可以使以太网各网段成为隔离开的碰撞域。如果把网桥换成工作在物理层的转发器，那就没有这种过滤通信量的功能。网桥B1和B2把三个网段连接成一个以太网。但它具有三个隔离开的碰撞域。
                    我们可以看到，不同网段上的通信不会相互干扰。例如，A和B正在通信，但其他网段上的C和D以及E和F也都可以同时通信。但如果A要和两一个网段上的C通信，就必须经过网桥B1的转发，那么这两个网段上就不能再有其他的站点进行通信（但这是E和F仍然可以通信）。因此，若每一个网段的数据率都是10Mb/s，那么三各网段合起来的最大吞吐量就变成30Mb/s。如果把两个网桥换成集线器或转发器，那么整个网络仍然是一个碰撞域，当A和B通信时，所有其他站点都不能够通信。整个碰撞域的最大吞吐量仍然是10Mb/s。
                2）扩大了物理范围，因而也增加了整个以太网上工作站的最大数目。
                3）提高了可靠性。当网络出现故障时，一般只影响个别网段。
                4）可互连不同物理层、不同MAC子层和不同速率（如10Mb/s和100Mb/s以太网）的以太网。
            当然，网桥也有一些缺点，例如：
                1）由于网桥对接收的帧要先存储和查找转发表，然后才转发，而转发之前，还必须执行CSMA/CD算法（发生碰撞使要退避），这就增加了时延。
                2）在MAC子层并没有流量控制功能。当网络上的符合很重时，网桥中的缓存的存储空间可能不够而发生溢出，以致产生帧丢失的现象。
                3）网桥只适合于用户数不太多（不超过几百个）和通信量不太大的以太网，否则有时还会因传播过多的广播信息而产生网络拥塞。这就是所谓的广播风暴。
            尽管如此，网桥仍获得了很广泛的应用，因为它的优点还是主要的。
            有时在两个网桥之间，还可使用一段点到点链路。
            以太网LAN1和LAN2通过网桥B1和B2以及一段点到点链路相连。为简单起见，我们把IP层以上看成是用户层。用户数据从站点A传到B经过各层次时，相应的数据单元首部的变化。这里只需要指出以下几点。
            当A向B发送数据帧时，其MAC帧首部中的源地址和目的地址分别是A和B的硬件地址。当网桥B1通过点对点链路转发数据帧时，若链路采用PPP协议，则要在数据帧的头尾分别加上首部PPP-H和尾部PPP-T。在数据帧离开B2时，还要剥去这个首部PPP-H和尾部PPP-T，然后经过以太网LAN2到达B。
            请注意，网桥在转发帧时，不改变帧的源地址。
        2.透明网桥
            目前使用得最多的网桥是透明网桥（transparent bridge），其标准是IEEE 802.1D。“透明”是指以太网上的站点并不知道所发送的帧将经过那几个网桥，以太网上的站点都看不见以太网上的网桥。透明网桥还是一种即插即用设备（plug-and-play device），意思是只要把网桥接入局域网，不用人工配置转发表网桥就能工作。这点很重要，吟哦日虽然从理论上讲，网桥中的转发表可以用手工配置，但若以太网上的站点数很多，并且站点位置或网络拓扑也经常变化，那么人工配置转发表既耗时又很容易出错。
            当网桥刚刚连接到以太网时，其转发表是空的。这是若网桥收到一个帧，它将怎样处理呢？网桥就按照以下自学习（self-learning）算法处理收到的帧（这样就逐步建立起转发表），并且按照转发表把帧转发出去。这种自学习算法的原理并不复杂，因为：若从某个站A发出的帧从接口x进入了某网桥，那么从这个接口出发沿相反方向一定可把一个帧传送到A。所以网桥只要每收到一个帧，就记下其源地址和进入网桥的接口，作为转发表中的一个项目。请注意，转发表中并没有“源地址”这一栏，而只有“地址”这一栏。在建立转发表时是把帧首部中的源地址写在“地址”这一栏的下面。在转发帧时，则是根据收到的帧首部中的目的地址来转发的。这时就把在“地址”栏下面已经记下的源地址当做目的地址，而把记下的进入接口当做转发接口。具体例子说明转发表的建立过程。但首先我们要再强调一下网桥和集线器（或转发器）的一个重要区别：网桥是按存储转发方式工作的，一定是先把整个帧收下来（但集线器或转发器是逐比特转发）再进行处理，而不管其目的地址是什么。此外，网桥丢弃CRC检验有差错的帧以及帧长过短和过长的无效帧，然后按照以下步骤进行处理。
                1）A向B发送帧    连接在同一个局域网上的站点B和网桥B1都能收到A发送的帧。网桥B1先按源地址A查找转发表。B1的转发表中没有A的地址，于是把地址A和收到此帧的接口1写入转发表中。这就表示，以后若收到要发给A的帧，就应当从这个接口1转发出去。接着再按目的地址B查找转发表。转发表中没有B的地址，于是就通过除收到此帧的接口1以外的所有接口（现在就是接口2）转发该帧。网桥B2从其接口1收到这个转发过来的帧。
                    网桥B2按同样方式处理收到的帧。B2的转发表中没有A的地址，因此在转发表中写入地址A和接口1。B2的转发表中没有B的地址，因此B2通过除接收此帧的接口1以外的所有接口（现在就是接口2）转发这个帧。
                    请注意，现在两个转发表中已经各有一个项目了。读者可能会问，B本来就可以直接收到A发送的帧，为什么还要让网桥B1和B2盲目地转发这个帧呢？答案是：这两个网桥当时并不知道网络拓扑，因此要通过自学习过程（不得不使用这种方式进行盲目转发）才能逐步弄清所连接的网络拓扑，建立起自己的转发表。
                2）F向C发送帧    网桥B2从其接口2收到这个帧。B2的转发表中没有F，因此在转发表写入地址F和接口2.B2的转发表中没有C，因此要通过B2的接口1把帧转发出去。现在C和网桥B1都能收到这个帧。在网桥B1的转发表中没有F，因此要把地址F和接口2写入转发表，并且还要从B1的接口1转发这个帧。
                3）B向A发送帧    网桥B1从其接口1收到这个帧。B1的转发表中没有B，因此在转发表写入地址B和接口1。在查找目的地址A。现在B1的转发表中可以查到A，其转发接口是1，和这个帧进入网桥B1的接口一样。于是网桥B1知道，不用自己转发这个帧，A也能收到B发送的帧。于是网桥B1把这个帧丢弃，不再继续转发了。这次网桥B1的转发表增加了一个项目，网桥B2的转发表没有变化。
            显然，如果网络上的每一个站都发送过帧，那么每一个站的地址最终都会记录在两个网桥的转发表上。
            实际上，在网桥的转发表中写入的信息除了地址和接口外，还有帧进入该网桥的时间。为什么要登记进入网桥的时间呢？这是因为以太网的拓扑可能经常会发生变化，站点也可能会更换适配器（这样就改变了站点的地址）。另外，以太网上的工作站并非总是接通电源的。吧每个帧到达网桥的时间登记下来，既可以在转发表中只保留网络拓扑的最新状态信息。具体的方法是，网桥中的接口管理软件周期性地扫描转发表中的项目。只要是在一定时间（例如几分钟）以前登记的都要删除。这样就使得网桥中的转发表能反映当前网络的最新拓扑状态。
            由此可见，网桥中的转发表并非总是包含所有站点的信息。只要某个站点从来都不发送数据，那么在网桥的转发表中就没有这个站点的项目。如果站点A在一段时间内不发送数据，那么在转发表中地址为A的项目就被删除了。
            下面我们给出网桥的自学习和转发帧的一般步骤。
                1）网桥收到一帧后先进行自学习。查找转发表中与收到帧的源地址有无相匹配的项目。如没有，就在转发表中增加一个项目（源地址、进入的接口和时间）。如有，则把原有的项目进行更新。
                2）转发帧。查找转发表中与收到帧的目的地址有无相匹配的项目。如没有，则通过所有其他接口（但进入网桥的接口除外）进行转发。如有，则按转发表中给出的接口进行转发。但应注意，若转发表中给出的接口就是该帧进入网桥的接口，则应丢弃这个帧（因为这时不需要经过网桥进行转发）。
            透明网桥还是用了一个生成树（spanning  tree）算法，即互连在一起的网桥在进行彼此通信后，就能找出网络拓扑的一个子集。在这个子集里，整个连通的网络中不存在回路，即在任何两个站之间只有一条路径。
            为什么要找出一个生成树呢？就是为了避免产生转发的帧在网络中不断地兜圈子。这里用网桥B1和B2把以太网LAN1和LAN2互连起来。设站A发送一个帧F，它经过B1和B2.假定帧F的目的地址都不在B1和B2的转发表中，因此B1和B2都转发帧F。我们把经过B1和B2转发的帧F在到达LAN2以后，分别记为F1和F2后，又将其转发到LAN1.结果引起一个帧在网络中不停地兜圈子，从而使网络资源不断地白白消耗了。
            为了得出能够反映网络拓扑发生时的生成树，在生成树上的跟网桥每隔一段时间还要对生成树的拓普进行更新。
        3.源路由网桥
            透明网桥的最大优点就是容易安装，一接上就能工作。但是，网络资源的利用还不充分。因此，另一种由发送帧的源站负责路由选择的网桥就问世了，这就是源路由（source route）网桥。
            源路由网桥是在发送帧时，吧详细的路由信息放在帧的首部中。
            这里的关键是元稹用什么方法才能知道应当选择什么样的路由。
            为了发现合适的路由，源站以广播方式向欲通信的目的站发送一个发现帧（discovery frame）作为探测之用。发现帧将在整个扩展的以太网中沿着所有可能的路由传送。在传送过程中，每个发现帧都记录所经过的路由。当这些发现帧到达目的站时，就沿着各自的路由返回源站。源站在得知这些路由后，从所有可能的路由中选择出一个最佳路由。以后，凡从这个源站向该目的站发送的帧的首部，都必须携带源站所确定的这一路由信息。
            发现帧还有另一个作用，就是帮助源站确定整个网络可以通过的帧的最大长度。
            源路由网桥对主机不是透明的，主机必须知道网桥的标识以及连接到哪一个网段上。使用源路由网桥可以利用最佳路由。若在两个以太网之间使用并联的源路由网桥，则可使通信量较平均地分配给每一个网桥。用透明网桥则只能使用生成树，而使用生成树一般并不能保证所使用的路由是最佳的，也不能再不同的链路中进行负载均衡。
        4.多接口网桥--以太网交换机
            1990年问世的交换式集线器（switching hub），可明显地提高以太网的性能。交换式集线器常称为以太网交换机（switch）或第二层交换机，表明这种交换机工作在数据链路层。
            “交换机”并无准确的定义和明确的概念，而现在的很多交换机已混杂了网桥和路由器的功能。著名网络专家Perlman认为：“交换机”应当是一个市场名词，而交换机的出现的确使数据的转发更加快速了。由于交换机这一名词已经广泛地使用了，因此我们也使用这个名词。下面简单地介绍其特点。
            从技术上讲，网桥的接口很少，一般只有2~4个，而以太网交换机通常都有十几个接口。因此，以太网交换机实质上就是一个多接口的网桥，和工作在物理层的转发器和集线器有很大的差别。此外，以太网交换机的每个接口都直接与一个单个主机或另一个集线器相连（注意：普通网桥的接口往往是连接到以太网的一个网段），并且一般都工作在全双工方式。当主机需要通信时，交换机能同时连通许多对的接口，使每一对相互通信的主机都能像独占通新媒体那样，无碰撞地传输数据。以太网交换机和透明网桥一样，也是一种即插即用设备，其内部的帧转发表也是通过自学习算法自动地逐渐建立起来的。当两个站通信完成后就断开连接。以太网交换机由于使用了专用的交换结构芯片，其交换速率就较高。
            对于普通10mb/s的共享式以太网，若共有N个用户，则每个用户占有的平均贷款只有总带宽（10Mb/s）的N分之一。在使用以太网交换机时，虽然在每个接口道主机的带宽还是10Mb/s，但由于一个用户在通信时是独占而不是和其他网络用户共享传输媒体的带宽，因此对于拥有N对接口的交换机的总容量为Nx10Mb/s。这正是交换机的最大优点。
            从共享总线以太网或10BASE-T以太网转到交换是以太网，所有接入设备的软件和硬件、适配器等都不需要作任何改动。也就是说，所有接入的设备继续使用CSMA/CD协议。此外，只要增加集线器的容量，整个系统的容量是很容易扩充的。
            以太网交换机一般都具有多种速率的接口，例如，可以具有10MB/s，100Mb/s和1Gb/s的接口的各种组合，这就大大方便了各种不同情况的用户。
            例子，以太网交换机有三个10Mb/s接口分别和学院三个系的10BASE-T以太网相连，还有三个100Mb/s的接口分别和电子邮件服务器、万维网服务器以及一个连接因特网的路由器相连。
            虽然许多以太网交换机对收到的帧采用存储转发方式进行转发，但也有一些交换机采用直通（cut-through）的交换方式。直通交换不必把整个数据帧先缓存后再进行处理，而是在接收数据帧的同时就立即按数据帧的目的MAC地址决定该帧的转发接口，因而提高了帧的转发速度。如果在这种交换机的背部采用基于硬件的交叉矩阵，交换时延就非常小。直通交换的一个缺点是它不检查差错就直接将帧转发出去，因此有可能也将一些无效帧转发给其他的站。在某些情况下，仍需要采用基于软件的存储转发方式进行交换，例如，当需要进行线路速率匹配、协议转换或差错检测时。现在有的厂商已生产出能支持两种交换方式的以太网交换机。以太网交换机的发展与建筑物结构化布线系统的普及应用密切相关。在结构化布线系统中，广泛地使用了以太网交换机。
            顺便指出，利用以太网交换机可以很方便地实现虚拟局域网VLAN（Virtual LAN）。在IEEE 802.1Q标准中，对虚拟局域网VLAN是这样定义的：
                虚拟局域网VLAN是由一些局域网网段构成的与物理位置无关的逻辑组，而这些网段具有某些共同的需求。每一个VLAN的帧都有一个明确的标识符，指明发送这个帧的工作站是属于哪一个VLAN。
                虚拟局域网其实只是局域网给用户提供的一种服务，而并不是一种新型局域网。
                使用了四个交换机的网络拓扑。设有10个工作站分配在三个楼层中，构成了三个局域网，即：
                LAN1：（A1，A2，B1，C1），LAN2：（A3，B2，C2），LAN3：（A4，B3，C3）
                但这10个用户划分为三个工作组，也就是说划分为三个虚拟局域网VLAN。即：
                VLAN1：（A1，A2，A3，A4），VLAN2：（B1，B2，B3）VLAN3：（C1，C2，C3）
                每一个VLAN的工作站可处在不同的局域网中，也可以不再同一层楼中。
                利用以太网交换机可以很方便地将这10个工作站划分为3个虚拟局域网：VLAN1，VLAN2和VLAN3.在虚拟局域网上的每一个站都可以听到同一个虚拟局域网上的其他成员所发出的广播。例如，工作站B1~B3同属于虚拟局域网VLAN2.当B1向工作组内成员发送数据时，工作站B2和B3将会收到广播的信息，芮然它们没有和B1连在同一个以太网交换机上。相反，B1向工作组内成员发送数据时，工作站A1，A2和C1都不会收到B1发出的广播信息，虽然它们都与B1连接在同一个以太网交换机上。以太网交换机不向虚拟局域网以外的工作站传送B1的广播信息。这样，虚拟局域网限制了接收广播信息的工作站数，使得网络不会因传播过多的广播信息（即所谓的“广播风暴”）而引起性能恶化。
            由于虚拟局域网是用户和网络资源的逻辑组合，因此可按照需要将有关设备和资源非常方便地重新组合，使用户从不同的服务器或数据库中存取所需的资源。
            以太网交换机的种类很多。例如，"具有第三层特性的第二层交换机"和“多层交换机”。前者具有某些第三层的功能，如数据报的分片和对多播通信量的管理，而后者可根据第三层的IP地址对分组进行过滤。
            1988年IEEE 批准了802.3ac标准，这个标准定义了以太网的帧格式的扩展，以便支持虚拟局域网。虚拟局域网协议允许在以太网的帧格式中插入一个4字节的标识符，称为VLAN标记（tag），用来指明发送该帧的工作站属于哪一个虚拟局域网。如果还使用原来的以太网帧格式，那么就无法划分虚拟局域网。
            VLAN标记字段的长度是4字节，插入在以太网 MAC帧的源地址字段和类型字段之间。VLAN标记的前两个字节总是设置为0x8100（即二进制的100000001 00000000），称为IEEE 802.1Q标记类型。当数据链路层检测到MAC帧的源地址字段后面的两个字节的值是0x8100时，就知道现在插入了4字节的VLAN标记。于是就接着检查后面两个字节的内容。在后面的两个字节中，前3位是用户优先级字段，接着的一位是规范格式指示符CFI（Canonical Format Indicator），最后的12位是该虚拟局域网VLAN标识符VID（VLAN ID），它唯一地标志了这个以太网帧是属于哪一个VLAN。
            由于用于VLAN的以太网帧的首部层架了4个字节，因此以太网的最大长度从原来的1518字节（1500字节的数据加上18自己的首部）变为1522字节。
3.6高速以太网
    速率达到或超过100Mb/s的以太网成为高速以太网。下面简单介绍集中高速以太网技术。
    3.6.1  100BASE-T以太网
        在20世纪80年代，很少有人想到以太网还会升级。然而在1992年9月100Mb/s以太网的设想提出后仅过了13个月，100MB/s以太网的产品就问世了。
        100BASE-T是在双绞线上传送100Mb/s基带信号的星型拓扑以太网，扔使用IEEE 802.3 的CSMA/CD协议，它又称为快速以太网（Fast Ethernet）。用户只要更换一张适配器，再配上一个100Mb/s的集线器，就可很方便地由10BASE-T以太网直接升级到100Mb/s，而不必改变网络的拓扑结构。所有在10BASE-T上的应用软件和网络软件都可保持不变。100BASE-T的适配器有很强的自适应性，能够自动识别10Mb/s和100Mb/s。
        1995年IEEE已把100BASE-T的快速以太网定位正式标准，其代号为IEEE 802.3u，是对现行的IEEE 802.3标准的补充。快速以太网的标准得到了所有的主流网络厂商的支持。
        100BASE-T可使用交换式集线器提供很好的服务质量，可在全双工方式下工作而无冲突发生。因此，CSMA/CD协议对全双工方式工作的快速以太网是不起作用的（但在半双工方式工作时则一定要使用CSMA/CD协议）。可能读者会问，不实用CSMA/CD协议为什么还能够叫作以太网呢？这是因为快速以太网使用的MAC帧格式仍然是IEEE 802.3标准规定的帧格式。
        然而IEEE 802.3u的标准未包括对同轴电缆的支持。这意味着想从细揽以太网升级到快速以太网的用户必须重新布线。因此，现在10/100Mb/s以太网都是使用无屏蔽双绞线布线。
        100Mb/s以太网的新标准改动了原10Mb/s以太网的某些规定。这里最主要的原因是要在数据发送速率提高时使参数a仍保持不变（或保持为较小的数值）。
        可以看出，当数据率C（Mb/s）提高到10倍，为了保持参数a不变，可以将帧长L（bit）也增长到10倍，也可以将网络电缆长度（因而使τ）减小到院友数值的十分之一。
        在100Mb/s的以太网中采用的方法是保持最短帧长不变，但把一个网段的最大电缆长度减小的100m。但最短帧长扔为64字节，即512比特。因此100Mb/s以太网的争用期是5.12μs，帧间最小间隔现在是0.96μs，都是10Mb/s以太网的1/10。
        100Mb/s以太网的新标准还规定了以下三种不同的物理层标准：
            1）100BASE-TX    使用两对UTP  5类线或屏蔽双绞线STP，其中一对用于发送，另一对用于接收。
            2）100BASE-FX    使用两根光纤，其中一根用于发送，另一根用于接收。在标准中把上述的100BASE-TX和100BASE-FX合在一起称为100BASE-X。
            3）100BASE-T4    使用4对UTP3类线或5类线，这是为已使用UTP3类线的大量用户而设计的。它使用3对线同时传送数据（每一对线以33·1/3Mb/s的速率传送数据），用1对线作为碰撞检测的接收信道。
    3.6.2吉比特以太网
        1996年夏季吉比特以太网（又称为千兆以太网）的产品已经问市。IEEE 在1997年通过了吉比特以太网的标准802.3z，它在1998年成为了正式标准。
            吉比特以太网的标准IEEE 802.3z有以下几个特点：
            1）允许在1Gb/s下全双工和半双工两种方式工作。
            2）使用IEEE 802.3协议规定的帧格式。
            3）在半双工方式下使用CSMA/CD协议（全双工方式不需要使用CSMA/CD协议）。
            4）与10BASE-T和100BASE-T技术向后兼容。
        吉比特以太网可用作现有网络的主干网，也可在高带宽（高速率）的应用场合中（如医疗图像或CAD的图形等）用来连接工作站和服务器。
            吉比特以太网的物理层使用两种成熟的技术：一种来自现有的以太网，另一种则是ANSI是定的光纤通道FC（Fiber Channel）。采用成熟技术就能大大缩短吉比特以太网标准的开发时间。
        吉比特以太网的物理层共有以下两个标准：
            1）1000BASE-X（IEEE 802.3z标准）
                1000BASE-X标准是基于光纤通道的物理层，即FC-0和FC-1。使用的媒体有三种：
                    1.1000BASE-SX   SX表示段波长（使用850nm激光器）。使用纤芯直径为62.5μm和50μm的多模光纤时，传输距离分别为275m和550m。
                    2.1000BASE-LX   LX表示长波长（使用1300nm激光器）。使用纤芯直径为62.5μm和50μm的多模光纤时，传输距离为550m。使用纤芯直径为10μm的单模光纤时，传输距离为5km。
                    3.1000BASE-CX   CX表示铜线。使用两对短距离的屏蔽双绞线电缆，传输距离为25m。
            2）1000BASE-T（802.3ab标准）
                1000BASE-T是使用4对UTP5类线，传送距离为100m。
                吉比特以太网工作在半双工方式时，就必须进行碰撞检测。由于数据率提高了，因此只有减小最大电缆长度或增大帧的最小长度，才能使参数a保持为较小的数值。若将吉比特以太网最大电缆长度减小到10m，那么网络的实际价值就大大减小。而若将最短帧长提高到640字节，则发送短数据时开销又嫌太大。因此吉比特以太网仍然保持一个网段的最大长度为100m，但采用了“载波延伸”（carrier extension）的办法，使最短帧长仍为64字节（这样可以保持兼容性），同时将争用期增大为512字节。凡发送的MAC帧长不足512字节时，就用一些特殊字符填充在帧的后面，使MAC帧的发送长度增大到512字节，这对有效载荷并无影响。接收端在收到以太网的MAC帧后，要把所填充的特殊字符删除后才向高层交付。当原来仅64字节长的短帧填充到512字节时，所填充的448字节就造成了很大的开销。
                为此，吉比特以太网还增加一种功能称为分组突发（packet bursting）。这就是当很多短帧要发送时，第一个短帧要采用上面所说的载波延伸的方法进行填充。但随后的一些短帧则可一个接一个地发送，它们之间只需留有必要的帧间最小间隔即可。这样就形成一串分组的突发，直到达到1500字节或稍多一些为止。当吉比特以太网工作在全双工方式时（即通信双方可同时进行发送和接收数据），不使用载波延伸和分组突发。
                吉比特以太网交换网可以直接与多个图形工作站相连。也可用作百兆以太网的主干网，与百兆比特或吉比特集线器相连，然后再和大型服务器连接在一起。
    3.6.3  10吉比特以太网
        就在吉比特以太网标准IEEE 802.3z通过后不久，在1999年3月，IEEE成立了高速研究组HSSG（HighSpeedStudyGroup），其任务是致力于10吉比特以太网（10GE）的研究。10GE的标准由IEEE 802.3ae委员会进行制定，10GE的正式标准已在2002年6月完成。10GE也就是万兆以太网。
        10GE并非将吉比特以太网的速率简单地提高到10倍。这里有许多技术上的问题要解决。下面是10GE的主要特点。
        10GE的帧格式与10Mb/s，100Mb/s和1Gb/s以太网的帧格式完全相同。10GE还保留了802.3标准规定的以太网最小和最大帧长。这就使用户在将其已有的以太网进行升级时，仍然和较低速率的以太网很方便地通信。
        由于数据率很高，10GE不再使用铜线而只使用光纤作为传输媒体。它使用长距离（超过40km）的光收发器与单模光纤接口，以便能够工作在广域网和城域网的范围。10GE也可使用较便宜的多模光纤，但传输距离为65~300m。
        10GE只工作在全双工方式，因此不存在争用问题，也不实用CSMA/CD协议。这就使得10GE的传输距离不再受进行碰撞检测的限制而大大提高了。
        吉比特以太网的物理层可以使用已有的光纤通道的技术，而10GE的物理层则是新开发的。10GE有两种不同的物理层：
            1）局域网物理层LAN PHY。局域网物理层的数据率时10.000Gb/s（这表示是精确的10Gb/s），因此一个10GE交换机可以支持正好10个吉比特以太网接口。
            2）可选的广域网物理层WAN PHY。广域网物理层具有另一种数据率，这是为了和所谓的“10Gb/s”的SONET/SDH（即OC-192/STM-64）相连接。我们知道，OC-192/STM-64的数据率时9.58464Gb/s。因此，为了使10GE的帧能够插入到OC-192/STM-64帧的有效载荷中，就要使用可选的广域网物理层，其数据率为9.95328Gb/s。反之，SONET/SDH的“10Gb/s”速率不可能支持10GE以太网的接口，而只是能够与SONET/SDH相连接。
        需要注意的是，10GE并没有SONET/SDH的同步接口而只有异步的以太网接口。因此，10GE在和SONET/SDH连接时，处于经济上的考虑它只是具有SONET/SDH的某些特性，如OC-192的链路速率、SONET/SDH的组帧格式等，但WAN PHY与SONET/SDH并不是全部都兼容的。例如，10GE没有TDM的支持，没有使用分层的精确时钟，也没有完整的网络管理功能。
        由于10GE的出现，以太网的工作范围已经从局域网（校园网。企业网）扩大到城域网和广域网，从而实现了端到端的以太网传输。这种工作方式的好处是：
            1）以太网是一种经过实践证明的成熟技术，无论是因特网服务提供者ISP还是端用户都很愿意使用以太网。当然对ISP来说，使用以太网还需要在更大的范围进行试验。
            2）以太网的互操作性也很好，不同厂商生产的以太网都能可靠地进行互操作。
            3）在广域网中使用以太网时，其价格大约只有SONET的五分之一和ATM的十分之一。以太网还能够适应多种的传输媒体，如铜缆、双绞线以及各种光缆。这就使具有不同传输媒体的用户在进行通信时不必重新布线。
            4）端到端的以太网连接使帧的格式全都是以太网的格式，而不需要再进行帧的格式转换，这就简化了操作和管理。但是，以太网和现有的其他网络，如帧中继或ATM网络，仍然需要有相应的接口才能进行互连。
        回顾过去的历史，我们看到10Mb/s以太网最终淘汰了速率比它快60%的16Mb/s的令牌环，100Mb/s的快速以太网也使得曾经是最快的局域网/城域网的FDDI变成历史。吉比特以太网和10GE的问世，使以太网的市场占有率进一步地得到提高，使得ATM在城域网和广域网中的地位受到更加严峻的挑战。10GE是IEEE 802.3标准在速率和距离方面的自然演进。以太网从10Mb/s到10Gb/s的演进证明了以太网是：
            1）可扩展的（从10Mb/s到10Gb/s）。
            2）灵活的（多种媒体、全/半双工、共享/交换）。
            3）易于安装。
            4）稳健性好。
    3.6.4  使用高速以太网进行宽带接入
        由于以太网已经成功地从10Mb/s的速率提高到100Mb/s、1Gb/s和10Gb/s，并且所覆盖的地理范围也从局域网扩展到了城域网和广域网，因此现在人们正在尝试使用宽带以太网进行宽带接入因特网。为此，IEEE在2001年初成立了802.3EFM工作组，专门研究高速以太网的宽带接入技术问题。
        高速以太网接入的一个重要特点是它可以提供双向的宽带通信，并且可以根据用户对带宽的需求灵活地进行带宽升级。当城域网和广域网都采用吉比特以太网或10GE时，采用高速以太网接入可以实现端到端的以太网传输，中间不需要再进行帧格式的转换。这就提高了数据的传输效率和降低了传输的成本。
        高速以太网接入可以采用多种方案。一个例子--在光纤到大楼FTTB。每个大楼的楼口都安装一个100Mb/s的以太网交换机（对于通信量不大的楼房也可以使用10Mb/s的以太网交换机），然后根据情况在每一个楼层安装一个10Mb/s或100Mb/s的以太网交换机。各大楼的以太网交换机通过光纤汇接到光节点汇接点。若干个光结点汇接点再通过吉比特以太网汇接到一个高速汇接点（称为GigaPoP），然后通过城域网连接到因特网的主干网。
        当采用以太网接入时，如果大楼中使用电脑上网的用户数很少，那么这种接入方式就很难获得经济效益。对于上网用户非常密集的办公楼或居民小区，以太网接入是一个可供选择的宽带接入方法。
3.7   其他类型的高速局域网或接口
    除了上述的高速以太网外，也还有一些其他类型的高速局域网。例如，在1988年问世的光纤分布式数据接口FDDI（Fiber Distributed Data Interface）是一个使用光纤作为传输媒体的令牌环型网。
    拥有速率为100Mb/s的FDDI在20世纪90年代初期曾获得了较快的发展，也曾被预测为“下一代的局域网”。然而FDDI从未拥有过很大市场。这是因为FDDI的芯片过于复杂因而价格昂贵。自从快速以太网大量进入市场后，就很少有人愿意再使用FDDI了。
    还有一种短距离的高速接口，叫做高性能并行接口HIPPI（High-Performance Parallel Interface），主要用于超级计算机与一些外围设备（如海量存储器。图形工作站等）的高速接口。1987年设计的HIPPI的数据传送标准是800Mb/s。以后，又制订了1600Mb/s和6.4Gb/s的数据率标准。HIPPI是一个美国国家标准化局ANSI的标准。
    在1987年设计HIPPI时，光纤还很贵，因此只好用廉价的双绞线进行数据的传输。现在光纤技术已很成熟，因此出现了光纤通道（Fiber Channel）。这里的“光纤通道”已是一个专用名词（并非任何使用光纤的连接都可称为“光纤通道”），很多英文资料在提到这一名词时是用大写的F和C。
    光纤通道可处理数据通道和网络的连接。他可用来传送数据通道，包括HIPPI，SCSI以及IBM主机所用的复用器通道，也可用来传送网络的分组，如IEEE 802、IP以及ATM的分组。光纤通道的基本结构是与输入和输出接口连接的一个交叉式交换机。光纤通道支持三种服务类：第一类服务是纯电路交换，保证按序交付；第二类服务是保证交付的分组交换；第三类服务是不保证交付的分组交换。


习题

3-01    数据链路（即逻辑链路）与链路（即物理链路）有何区别？“电路接通了”与“数据链路接通了”的区别何在？
3-02    数据链路层中的链路控制包括哪些功能？试讨论数据链路层做成可靠的链路层有哪些优点和缺点。
3-03    网络适配器的作用是什么？网络适配器工作在哪一层？
3-04    数据链路层的三个基本问题（帧定界、透明传输和差错检测）为什么都必须加以解决？
3-05    如果在数据链路层不进行帧定界，会发生什么问题？
3-06    PPP协议的主要特点是什么？为什么PPP不实用帧的编号？PPP适用于什么情况？为什么PPP协议协议不能使数据链路层实现可靠传输？
3-07    要发送的数据为1101011011.采用CRC的生成多项式是P（X）=X^4+X+1.试求应添加在数据后面的余数。
            数据在传输过程中最后一个1变成了0，问接收端能否发现？
            若数据在传输过程中最后两个1都变成了0，问接收端能否发现？
            采用CRC检验后，数据链路层的传输时否就变成了可靠的传输？
3-08    要发送的数据为101110.采用CRC的生成多项式是P（X）=X^3+1试求应添加在数据后面的余数。
3-09    一个PPP帧的数据部分（用十六进制写出）是  7D 5E FE 27 7D 5D 7D 5D 65 7D 5E 。试问真正的数据是什么（用十六进制写出）？
3-10    PPP协议使用同步传输技术传送比特串0110 1111 1111 1100。试问经过零比特填充后变成怎样额比特串？若接收端收到的PPP帧的数据部分是0001 1101 1111 0111 1101 10，问删除发送端加入的零比特后变成怎样的比特串？
3-11    试分别讨论以下各种情况在什么条件下是透明传输，在什么条件下不是透明传输。
            （提示：请弄清什么是“透明传输”，然后考虑能否满足其条件。）
            1）普通的电话通信。
            2）电信局提供的公用电报通信。
            3）因特网提供的电子邮件服务。
3-12    PPP协议的工作状态有哪几种？当用户要使用PPP协议和ISP建立连接进行通信需要建立哪几种连接？每一种连接解决什么问题？
3-13    局域网的主要特点是什么？为什么局域网采用广播通信方式而广域网不采用呢？
3-14    常用的局域网的网络拓扑有哪些种类？现在最流行的是哪种结构？为什么早起的以太网选择总线拓扑结构而不使用星星拓扑结构，但现在缺改为使用星星拓扑结构？
3-15    什么叫做传统以太网？以太网有哪两个主要标准？
3-16    数据率为10Mb/s的以太网在物理媒体上的码元传输速率是多少码元/秒？
3-17    为什么LLC子层的标准已制定出来了但现在缺很少使用？
3-18    试说明10BASE-T中的“10”、“BASE”和“T”所代表的意思。
3-19    以太网使用的CSMA/CD协议是以争用方式接入到共享信道。这与传统的时分复用TDM相比优缺点如何？
3-20    假定1km长的CSMA/CD网络的数据率为1Gb/s。设信号在网络上传播速率为200000km/s。求能够使用此协议的最短帧长。
3-21    什么叫做比特时间？使用这种时间单位有什么好处？100比特时间是多少微秒？
3-22    假定在使用CSMA/CD协议的10Mb/s以太网中某个站在发送数据时检测到碰撞，执行退避算法时选择了随机数r=100.试问这个站需要等待多长时间后才能再次发送数据？如果是100Mb/s的以太网呢？
3-23    公式（3-3）表示，以太网的极限信道利用率与连接在以太网上的站点数无关。能否由此推论出：以太网的利用率也与连接在以太网的站点数无关？请说明你的理由。
3-24    假定站点A和B在同一个10Mb/s以太网网段上。这两个站点之间的传播时延为255比特时间。现假定A开始发送一帧，并且在A发送结束之前B也发送一帧。如果A发送的是以太网所容许的最短的帧，那么A在检测到和B发送碰撞之前能否把自己的数据发送完毕？换言之，如果A在发送完毕之前并没有检测到碰撞，那么能否肯定A所发送的帧不会和B发送的帧发生碰撞？（提示：在计算时应当考虑到每一个以太网帧在发送到信道上时，在MAC帧前面还要增加若干字节的前同步码和帧定界符）
3-25    在上题中的站点A和B在t=0时同时发送了数据帧。当t=255比特时间，A和B同时检测到发生了碰撞，并且在t=225+48=273比特时间完成了干扰信号的传输。A和B在CSMA/CD算法中选择不同的r值退避。假定A和B选择的随机数分别是rA=0和rB=1.试问A和B各在什么时间开始重传其数据帧？A重传的数据帧在时间到达B？A重传的数据会不会和B重传的数据再次发送碰撞？B会不会在预定的重传时间停止发送数据？
3-26    以太网上只有两个站，它们同时发送数据，产生了碰撞。于是按截断二进制指数退避算法进行重传。重传次数记为i，i=1，2，3，...。试计算第1次重传失败的概率、第2次重传失败的概率、第3次重传失败的概率，以及一个站成功发送数据之前的平均重传次数I。
3-27    假定一个以太网上的通信量中的80%是在本局域网上进行的，而其余的20%的通信量是在本局域网和因特网之间进行的。另一个以太网的情况反过来。这两个以太网一个使用以太网集线器，而另一个使用以太网交换机。你认为以太网交换机应当用在哪一个网络上？
3-28    有10个站连接到以太网上。试计算以下三种情况下每一个站所能得到的带宽。
            1）10个站都连接到一个10Mb/s以太网集线器；
            2）10个站都连接到一个100Mb/s的以太网集线器；
            3）10个站都连接到一个10Mb/s以太网交换机。
3-29    10MB/s以太网升级到100Mb/s、1Gb/s和10Gb/s时，都需要解决哪些技术问题？为什么以太网能够在发展的过程中淘汰掉自己的竞争对手，并使自己的应用范围从局域网一直扩展到城域网和广域网？
3-30    以太网交换机有何特点？用它怎样组成虚拟局域网？
3-31    网桥的工作原理和特点是什么？网桥与转发器以及以太网交换机有何异同？
3-32    略
3-33    网桥中的转发表时自学算法建立的。如果有的站点总是不发送数据而仅仅接收数据，那么在转发表中是否就没有与这样的站点相对应的项目？如果要向这个站点发送数据帧，那么网桥能够把数据帧正确转发到目的地址吗？
